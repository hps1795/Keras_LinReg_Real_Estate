{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors waterfront  view  ...          grade sqft_above  \\\n",
       "0      5650     1.0        NaN  NONE  ...      7 Average       1180   \n",
       "1      7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2     10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3      5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4      8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop irrelevant column 'id'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are planning to use MinMaxScaler for scaling. This scaling converts maximum value to 1 and minimum to 0 and distribute the values. Column 'zipcode' is not suitable to be applied to this scaler so we will drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('zipcode', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     19075\n",
       "YES      146\n",
       "Name: waterfront, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.waterfront.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NONE         19422\n",
       "AVERAGE        957\n",
       "GOOD           508\n",
       "FAIR           330\n",
       "EXCELLENT      317\n",
       "Name: view, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       17011\n",
       "2014.0       73\n",
       "2003.0       31\n",
       "2013.0       31\n",
       "2007.0       30\n",
       "          ...  \n",
       "1946.0        1\n",
       "1959.0        1\n",
       "1971.0        1\n",
       "1951.0        1\n",
       "1954.0        1\n",
       "Name: yr_renovated, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr_renovated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot find the strong correlation with the price for those columns because they have more than 80% of the rows with same value. Therefore, we will drop the columns above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['waterfront', 'view', 'yr_renovated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0  10/13/2014  221900.0         3       1.00         1180      5650     1.0   \n",
       "1   12/9/2014  538000.0         3       2.25         2570      7242     2.0   \n",
       "2   2/25/2015  180000.0         2       1.00          770     10000     1.0   \n",
       "3   12/9/2014  604000.0         4       3.00         1960      5000     1.0   \n",
       "4   2/18/2015  510000.0         3       2.00         1680      8080     1.0   \n",
       "\n",
       "   condition          grade  sqft_above sqft_basement  yr_built      lat  \\\n",
       "0    Average      7 Average        1180           0.0      1955  47.5112   \n",
       "1    Average      7 Average        2170         400.0      1951  47.7210   \n",
       "2    Average  6 Low Average         770           0.0      1933  47.7379   \n",
       "3  Very Good      7 Average        1050         910.0      1965  47.5208   \n",
       "4    Average         8 Good        1680           0.0      1987  47.6168   \n",
       "\n",
       "      long  sqft_living15  sqft_lot15  \n",
       "0 -122.257           1340        5650  \n",
       "1 -122.319           1690        7639  \n",
       "2 -122.233           2720        8062  \n",
       "3 -122.393           1360        5000  \n",
       "4 -122.045           1800        7503  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           21597 non-null  object \n",
      " 1   price          21597 non-null  float64\n",
      " 2   bedrooms       21597 non-null  int64  \n",
      " 3   bathrooms      21597 non-null  float64\n",
      " 4   sqft_living    21597 non-null  int64  \n",
      " 5   sqft_lot       21597 non-null  int64  \n",
      " 6   floors         21597 non-null  float64\n",
      " 7   condition      21597 non-null  object \n",
      " 8   grade          21597 non-null  object \n",
      " 9   sqft_above     21597 non-null  int64  \n",
      " 10  sqft_basement  21597 non-null  object \n",
      " 11  yr_built       21597 non-null  int64  \n",
      " 12  lat            21597 non-null  float64\n",
      " 13  long           21597 non-null  float64\n",
      " 14  sqft_living15  21597 non-null  int64  \n",
      " 15  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(5), int64(7), object(4)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets deal with the columns with object data type and convert them into int64 or float64 to pass it into keras model. Columns we will make a change are:\n",
    "- date\n",
    "- condition\n",
    "- grade\n",
    "- sqft_basement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert column 'date' into new columns 'month' and 'year'. After creating new columns, 'date' column is not needed so it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].apply(lambda date:date.month)\n",
    "df['year'] = df['date'].apply(lambda date:date.year)\n",
    "df = df.drop('date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'condition' and 'grade' has object entries. We will create the dictionary listing the original entries and the number entries that corresponds to the original entries. Then, we will replace the values in that column using the dictionary we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average      14020\n",
       "Good          5677\n",
       "Very Good     1701\n",
       "Fair           170\n",
       "Poor            29\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_replace = {'Poor': 1, 'Fair': 2, 'Average': 3, 'Good': 4, 'Very Good': 5}\n",
    "df[\"condition\"].replace(condition_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7 Average        8974\n",
       "8 Good           6065\n",
       "9 Better         2615\n",
       "6 Low Average    2038\n",
       "10 Very Good     1134\n",
       "11 Excellent      399\n",
       "5 Fair            242\n",
       "12 Luxury          89\n",
       "4 Low              27\n",
       "13 Mansion         13\n",
       "3 Poor              1\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_replace = {'3 Poor': 3, '4 Low': 4, '5 Fair': 5, '6 Low Average': 6, \n",
    "                 '7 Average': 7, '8 Good': 8, '9 Better': 9 ,'10 Very Good': 10, \n",
    "                 '11 Excellent':11, '12 Luxury': 12, '13 Mansion': 13}\n",
    "df[\"grade\"].replace(grade_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will convert the data type of 'sqft basement' into int64 or float64. Lets first check the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       12826\n",
       "?           454\n",
       "600.0       217\n",
       "500.0       209\n",
       "700.0       208\n",
       "          ...  \n",
       "2580.0        1\n",
       "862.0         1\n",
       "506.0         1\n",
       "1960.0        1\n",
       "2810.0        1\n",
       "Name: sqft_basement, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sqft_basement.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a value '?' which will prevent us from converting the data type. We will replace the '?' to 0 and then convert the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_basement'].replace({'?': 0},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['sqft_basement'] = df['sqft_basement'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if every change has been made properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  condition  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0          3   \n",
       "1  538000.0         3       2.25         2570      7242     2.0          3   \n",
       "2  180000.0         2       1.00          770     10000     1.0          3   \n",
       "3  604000.0         4       3.00         1960      5000     1.0          5   \n",
       "4  510000.0         3       2.00         1680      8080     1.0          3   \n",
       "\n",
       "   grade  sqft_above  sqft_basement  yr_built      lat     long  \\\n",
       "0      7        1180            0.0      1955  47.5112 -122.257   \n",
       "1      7        2170          400.0      1951  47.7210 -122.319   \n",
       "2      6         770            0.0      1933  47.7379 -122.233   \n",
       "3      7        1050          910.0      1965  47.5208 -122.393   \n",
       "4      8        1680            0.0      1987  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  month  year  \n",
       "0           1340        5650     10  2014  \n",
       "1           1690        7639     12  2014  \n",
       "2           2720        8062      2  2015  \n",
       "3           1360        5000     12  2014  \n",
       "4           1800        7503      2  2015  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          21597 non-null  float64\n",
      " 1   bedrooms       21597 non-null  int64  \n",
      " 2   bathrooms      21597 non-null  float64\n",
      " 3   sqft_living    21597 non-null  int64  \n",
      " 4   sqft_lot       21597 non-null  int64  \n",
      " 5   floors         21597 non-null  float64\n",
      " 6   condition      21597 non-null  int64  \n",
      " 7   grade          21597 non-null  int64  \n",
      " 8   sqft_above     21597 non-null  int64  \n",
      " 9   sqft_basement  21597 non-null  float64\n",
      " 10  yr_built       21597 non-null  int64  \n",
      " 11  lat            21597 non-null  float64\n",
      " 12  long           21597 non-null  float64\n",
      " 13  sqft_living15  21597 non-null  int64  \n",
      " 14  sqft_lot15     21597 non-null  int64  \n",
      " 15  month          21597 non-null  int64  \n",
      " 16  year           21597 non-null  int64  \n",
      "dtypes: float64(6), int64(11)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD! Now we have everything set. We will move on to next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first set the X and y. y will be our target variable and the X will be the rest. In my phase 2 project from flatiron school, 'price' was our target object. Therefore, we will set 'price' as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the train test split from the scikit learn library. to split the X and y into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use MinMaxScaler from sklearn library to scale the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scaling, fit applies only for train set while transform applies to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11337, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6480, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3780, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a model using keras from tensorflow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (16,))) \n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(1))             \n",
    "    model.compile(optimizer='adam',loss='mean_squared_error') \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 430355513344.0000 - val_loss: 427944312832.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 430335590400.0000 - val_loss: 427904073728.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430263140352.0000 - val_loss: 427792203776.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 430102872064.0000 - val_loss: 427575541760.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429820674048.0000 - val_loss: 427215781888.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429375225856.0000 - val_loss: 426677141504.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 428739330048.0000 - val_loss: 425936977920.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 427894439936.0000 - val_loss: 424974483456.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 426823188480.0000 - val_loss: 423778025472.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 425509289984.0000 - val_loss: 422329778176.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 423935279104.0000 - val_loss: 420620075008.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 422089916416.0000 - val_loss: 418628468736.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 419967107072.0000 - val_loss: 416357875712.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 417563738112.0000 - val_loss: 413795647488.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 909us/step - loss: 414870044672.0000 - val_loss: 410952138752.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 411885305856.0000 - val_loss: 407807787008.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 408607490048.0000 - val_loss: 404369211392.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 405031092224.0000 - val_loss: 400636051456.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 401164566528.0000 - val_loss: 396603162624.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 397012336640.0000 - val_loss: 392305278976.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 392565555200.0000 - val_loss: 387703013376.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 387850862592.0000 - val_loss: 382826283008.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 382860754944.0000 - val_loss: 377693274112.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 377594478592.0000 - val_loss: 372281475072.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 372087783424.0000 - val_loss: 366642790400.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 366333067264.0000 - val_loss: 360744222720.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 360344551424.0000 - val_loss: 354608316416.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 354125119488.0000 - val_loss: 348263022592.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 347695841280.0000 - val_loss: 341723938816.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 341071724544.0000 - val_loss: 334955806720.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 334250377216.0000 - val_loss: 328056635392.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 327256014848.0000 - val_loss: 320940900352.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 320109871104.0000 - val_loss: 313697992704.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 312822562816.0000 - val_loss: 306321817600.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 305417486336.0000 - val_loss: 298853433344.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 297905356800.0000 - val_loss: 291269246976.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 290293350400.0000 - val_loss: 283615854592.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 282626457600.0000 - val_loss: 275911344128.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 274914607104.0000 - val_loss: 268125732864.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 267180703744.0000 - val_loss: 260356980736.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 259437002752.0000 - val_loss: 252595453952.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 251704524800.0000 - val_loss: 244850753536.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243996491776.0000 - val_loss: 237154140160.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 236336381952.0000 - val_loss: 229505515520.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 228751802368.0000 - val_loss: 221956128768.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 221271228416.0000 - val_loss: 214480420864.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 213904801792.0000 - val_loss: 207151382528.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 206667071488.0000 - val_loss: 199997702144.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 199584727040.0000 - val_loss: 192983171072.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 192684376064.0000 - val_loss: 186108395520.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 185969934336.0000 - val_loss: 179541983232.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 179479609344.0000 - val_loss: 173101105152.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 173195689984.0000 - val_loss: 166936756224.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 167178502144.0000 - val_loss: 161035124736.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 161420787712.0000 - val_loss: 155353710592.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 155932655616.0000 - val_loss: 150020997120.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 150746038272.0000 - val_loss: 144979132416.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 145846992896.0000 - val_loss: 140217466880.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 141250740224.0000 - val_loss: 135790321664.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 136954896384.0000 - val_loss: 131637231616.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 132988698624.0000 - val_loss: 127797600256.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 129352957952.0000 - val_loss: 124314984448.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 126038458368.0000 - val_loss: 121144942592.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 123027709952.0000 - val_loss: 118275235840.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 120320401408.0000 - val_loss: 115711057920.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 117922603008.0000 - val_loss: 113445527552.0000\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 115809820672.0000 - val_loss: 111482232832.0000\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 113942929408.0000 - val_loss: 109744078848.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 112341991424.0000 - val_loss: 108239372288.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 110975803392.0000 - val_loss: 106972995584.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 109812539392.0000 - val_loss: 105931259904.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 108837519360.0000 - val_loss: 105033162752.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 108037562368.0000 - val_loss: 104307957760.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 107380170752.0000 - val_loss: 103707631616.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 106838458368.0000 - val_loss: 103217463296.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 106393255936.0000 - val_loss: 102813843456.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 106026852352.0000 - val_loss: 102484213760.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 105721315328.0000 - val_loss: 102198124544.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 105468239872.0000 - val_loss: 101959098368.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 105248694272.0000 - val_loss: 101752840192.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 105053208576.0000 - val_loss: 101571239936.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 104874369024.0000 - val_loss: 101403467776.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 746us/step - loss: 104702304256.0000 - val_loss: 101234204672.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 104539275264.0000 - val_loss: 101070561280.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 104375754752.0000 - val_loss: 100912046080.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 104217640960.0000 - val_loss: 100748869632.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 104057372672.0000 - val_loss: 100588716032.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 103896309760.0000 - val_loss: 100427866112.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 103732174848.0000 - val_loss: 100259971072.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 103563370496.0000 - val_loss: 100092387328.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 103392665600.0000 - val_loss: 99920961536.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 103219306496.0000 - val_loss: 99744858112.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 103044857856.0000 - val_loss: 99570974720.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 102868983808.0000 - val_loss: 99390685184.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 102686613504.0000 - val_loss: 99213877248.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 102506381312.0000 - val_loss: 99029565440.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 102325600256.0000 - val_loss: 98845704192.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 102138994688.0000 - val_loss: 98661679104.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 101953830912.0000 - val_loss: 98476204032.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 101766127616.0000 - val_loss: 98286911488.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 101580087296.0000 - val_loss: 98103590912.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 101378842624.0000 - val_loss: 97905025024.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 101191942144.0000 - val_loss: 97712996352.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 101001027584.0000 - val_loss: 97524514816.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 100808900608.0000 - val_loss: 97332469760.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 100614922240.0000 - val_loss: 97135493120.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 100424507392.0000 - val_loss: 96940892160.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 100222025728.0000 - val_loss: 96745291776.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 100025032704.0000 - val_loss: 96547315712.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99829006336.0000 - val_loss: 96348225536.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99629293568.0000 - val_loss: 96148733952.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99430498304.0000 - val_loss: 95949316096.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 99229622272.0000 - val_loss: 95748808704.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99025911808.0000 - val_loss: 95547064320.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 98825814016.0000 - val_loss: 95341019136.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 98622095360.0000 - val_loss: 95141101568.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 98420121600.0000 - val_loss: 94939226112.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 98217836544.0000 - val_loss: 94736752640.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 98016059392.0000 - val_loss: 94536368128.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 97821286400.0000 - val_loss: 94335066112.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 97614323712.0000 - val_loss: 94129520640.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 97412161536.0000 - val_loss: 93931143168.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 97206648832.0000 - val_loss: 93726621696.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 96998137856.0000 - val_loss: 93520945152.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 96795729920.0000 - val_loss: 93313753088.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 96588324864.0000 - val_loss: 93104644096.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 96378380288.0000 - val_loss: 92895887360.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 96169771008.0000 - val_loss: 92688187392.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 95962226688.0000 - val_loss: 92478291968.0000\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 95752683520.0000 - val_loss: 92269223936.0000\n",
      "Epoch 131/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 825us/step - loss: 95544385536.0000 - val_loss: 92061286400.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 95332573184.0000 - val_loss: 91849187328.0000\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 95120711680.0000 - val_loss: 91639111680.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 94914863104.0000 - val_loss: 91431026688.0000\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 94700773376.0000 - val_loss: 91218386944.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 94489354240.0000 - val_loss: 91004764160.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 94275125248.0000 - val_loss: 90790674432.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 94063443968.0000 - val_loss: 90576297984.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 93845856256.0000 - val_loss: 90364461056.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 777us/step - loss: 93636239360.0000 - val_loss: 90146119680.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 93417472000.0000 - val_loss: 89934372864.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 93206224896.0000 - val_loss: 89718071296.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 92985942016.0000 - val_loss: 89500712960.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 92770746368.0000 - val_loss: 89282928640.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 92554878976.0000 - val_loss: 89068519424.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 92335226880.0000 - val_loss: 88850939904.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 92115812352.0000 - val_loss: 88631386112.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 91897626624.0000 - val_loss: 88413732864.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 91681644544.0000 - val_loss: 88192180224.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 91461910528.0000 - val_loss: 87974199296.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 91241332736.0000 - val_loss: 87753900032.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 91022401536.0000 - val_loss: 87535730688.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 90801954816.0000 - val_loss: 87313645568.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 90580697088.0000 - val_loss: 87091576832.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 90358702080.0000 - val_loss: 86871744512.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 90140000256.0000 - val_loss: 86650429440.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 89919373312.0000 - val_loss: 86430081024.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 87591485440.000 - 0s 799us/step - loss: 89696780288.0000 - val_loss: 86210650112.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 89479602176.0000 - val_loss: 85988548608.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 89252151296.0000 - val_loss: 85763899392.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 89031090176.0000 - val_loss: 85545312256.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 88809832448.0000 - val_loss: 85318811648.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 88583364608.0000 - val_loss: 85094162432.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 88360108032.0000 - val_loss: 84869259264.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 88134221824.0000 - val_loss: 84643512320.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 87910064128.0000 - val_loss: 84418387968.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 87688470528.0000 - val_loss: 84193304576.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 87458750464.0000 - val_loss: 83968827392.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 87232413696.0000 - val_loss: 83739820032.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 87004864512.0000 - val_loss: 83512279040.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 86779215872.0000 - val_loss: 83281379328.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 86552657920.0000 - val_loss: 83053608960.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 86323265536.0000 - val_loss: 82825306112.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 86090612736.0000 - val_loss: 82591891456.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 85855690752.0000 - val_loss: 82359042048.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 85624143872.0000 - val_loss: 82126880768.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 85393399808.0000 - val_loss: 81890992128.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 85159493632.0000 - val_loss: 81660354560.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 84925087744.0000 - val_loss: 81427939328.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 84693311488.0000 - val_loss: 81194786816.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 84456955904.0000 - val_loss: 80965353472.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 84225007616.0000 - val_loss: 80726376448.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 83992059904.0000 - val_loss: 80495140864.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83758268416.0000 - val_loss: 80256540672.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83523788800.0000 - val_loss: 80021553152.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83286016000.0000 - val_loss: 79786246144.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83047317504.0000 - val_loss: 79546122240.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 82809331712.0000 - val_loss: 79306334208.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 82570469376.0000 - val_loss: 79070093312.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 82331410432.0000 - val_loss: 78829207552.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 82091696128.0000 - val_loss: 78588239872.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 81858527232.0000 - val_loss: 78347296768.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 81612840960.0000 - val_loss: 78110556160.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 81376796672.0000 - val_loss: 77868064768.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 81135648768.0000 - val_loss: 77630062592.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 80895148032.0000 - val_loss: 77389725696.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 80657121280.0000 - val_loss: 77152706560.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 80417980416.0000 - val_loss: 76911353856.0000\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 80181256192.0000 - val_loss: 76671959040.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 79940960256.0000 - val_loss: 76432941056.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 79698681856.0000 - val_loss: 76192989184.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 79460679680.0000 - val_loss: 75951333376.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 79218401280.0000 - val_loss: 75711717376.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 78972690432.0000 - val_loss: 75466448896.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 78729936896.0000 - val_loss: 75224915968.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 78485700608.0000 - val_loss: 74979205120.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 78242365440.0000 - val_loss: 74738589696.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 77988429824.0000 - val_loss: 74482737152.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 77747019776.0000 - val_loss: 74243334144.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 77504241664.0000 - val_loss: 73998508032.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 77260611584.0000 - val_loss: 73756368896.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 77019693056.0000 - val_loss: 73513230336.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 76777185280.0000 - val_loss: 73267331072.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 76532523008.0000 - val_loss: 73026568192.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 76287131648.0000 - val_loss: 72780251136.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 76042682368.0000 - val_loss: 72534810624.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 75795218432.0000 - val_loss: 72285274112.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 75551916032.0000 - val_loss: 72042856448.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 75303190528.0000 - val_loss: 71794237440.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 75058733056.0000 - val_loss: 71549894656.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 74810703872.0000 - val_loss: 71298965504.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 74557603840.0000 - val_loss: 71049576448.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 74307944448.0000 - val_loss: 70800105472.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 74059300864.0000 - val_loss: 70547636224.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 73809674240.0000 - val_loss: 70300295168.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 73560121344.0000 - val_loss: 70051184640.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 73314828288.0000 - val_loss: 69803163648.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 73063620608.0000 - val_loss: 69553258496.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 72813936640.0000 - val_loss: 69308301312.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 72566054912.0000 - val_loss: 69059387392.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 72315445248.0000 - val_loss: 68808638464.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 72066113536.0000 - val_loss: 68560220160.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 71821598720.0000 - val_loss: 68315721728.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 71574577152.0000 - val_loss: 68065898496.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 71325220864.0000 - val_loss: 67819802624.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 71076708352.0000 - val_loss: 67575808000.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 70830850048.0000 - val_loss: 67322060800.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 70581075968.0000 - val_loss: 67077177344.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 70332882944.0000 - val_loss: 66825891840.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 70085263360.0000 - val_loss: 66580000768.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 69836734464.0000 - val_loss: 66333663232.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 69589753856.0000 - val_loss: 66084990976.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 69344215040.0000 - val_loss: 65835855872.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 69096898560.0000 - val_loss: 65594421248.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 68856233984.0000 - val_loss: 65349005312.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 816us/step - loss: 68610732032.0000 - val_loss: 65107968000.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 68372897792.0000 - val_loss: 64870182912.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 68130361344.0000 - val_loss: 64631635968.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 67892908032.0000 - val_loss: 64393998336.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 67653537792.0000 - val_loss: 64156000256.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 67415404544.0000 - val_loss: 63915786240.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 67173588992.0000 - val_loss: 63682719744.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 66936602624.0000 - val_loss: 63444492288.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 66695667712.0000 - val_loss: 63206809600.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 66462810112.0000 - val_loss: 62970716160.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 66231009280.0000 - val_loss: 62737477632.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 65998278656.0000 - val_loss: 62508261376.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 65766100992.0000 - val_loss: 62278242304.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 65540431872.0000 - val_loss: 62047203328.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 65308479488.0000 - val_loss: 61825257472.0000\n",
      "Epoch 261/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 817us/step - loss: 65078886400.0000 - val_loss: 61596262400.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 64856944640.0000 - val_loss: 61369565184.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 64625385472.0000 - val_loss: 61146046464.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 64403709952.0000 - val_loss: 60923527168.0000\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 64178954240.0000 - val_loss: 60703055872.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 63958740992.0000 - val_loss: 60485079040.0000\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 63739899904.0000 - val_loss: 60268576768.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 777us/step - loss: 63522402304.0000 - val_loss: 60052144128.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 63303393280.0000 - val_loss: 59835731968.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 63088570368.0000 - val_loss: 59621707776.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 62876295168.0000 - val_loss: 59410706432.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 62657765376.0000 - val_loss: 59203858432.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 62447738880.0000 - val_loss: 58990686208.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 62246125568.0000 - val_loss: 58785910784.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 62035050496.0000 - val_loss: 58583588864.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 61832962048.0000 - val_loss: 58383282176.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 61632438272.0000 - val_loss: 58184491008.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 61439516672.0000 - val_loss: 57994579968.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 61246111744.0000 - val_loss: 57807032320.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 61056557056.0000 - val_loss: 57620541440.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 60873003008.0000 - val_loss: 57439174656.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 60686528512.0000 - val_loss: 57259200512.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 60503597056.0000 - val_loss: 57079738368.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 60329189376.0000 - val_loss: 56898027520.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 60144951296.0000 - val_loss: 56725561344.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 59969638400.0000 - val_loss: 56551481344.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 59799248896.0000 - val_loss: 56381812736.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 59631001600.0000 - val_loss: 56217063424.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 59459530752.0000 - val_loss: 56051200000.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 59296768000.0000 - val_loss: 55889543168.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 59127226368.0000 - val_loss: 55728881664.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 58962935808.0000 - val_loss: 55566249984.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 58801696768.0000 - val_loss: 55408447488.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 58640007168.0000 - val_loss: 55254134784.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 58483638272.0000 - val_loss: 55097528320.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 58325049344.0000 - val_loss: 54946295808.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 58177269760.0000 - val_loss: 54795694080.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 58022928384.0000 - val_loss: 54649171968.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 57879511040.0000 - val_loss: 54509813760.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 57727852544.0000 - val_loss: 54366781440.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 57585291264.0000 - val_loss: 54225612800.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 57445625856.0000 - val_loss: 54093426688.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 57313878016.0000 - val_loss: 53959888896.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 57174265856.0000 - val_loss: 53826863104.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 57042870272.0000 - val_loss: 53700169728.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 56915685376.0000 - val_loss: 53570715648.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 56781389824.0000 - val_loss: 53447426048.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 56665419776.0000 - val_loss: 53326123008.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 56534626304.0000 - val_loss: 53211013120.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 56413569024.0000 - val_loss: 53090447360.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 56295645184.0000 - val_loss: 52977991680.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 56181542912.0000 - val_loss: 52865679360.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 56067334144.0000 - val_loss: 52757483520.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 55956303872.0000 - val_loss: 52652490752.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 55850967040.0000 - val_loss: 52546990080.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 55744823296.0000 - val_loss: 52446355456.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 55641149440.0000 - val_loss: 52345581568.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 55538565120.0000 - val_loss: 52245561344.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 55438925824.0000 - val_loss: 52150341632.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 55343095808.0000 - val_loss: 52057026560.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 55246073856.0000 - val_loss: 51965378560.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 55151693824.0000 - val_loss: 51877953536.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 55059148800.0000 - val_loss: 51792695296.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54968274944.0000 - val_loss: 51705937920.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 54879240192.0000 - val_loss: 51622715392.0000\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 54794817536.0000 - val_loss: 51541721088.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 54711590912.0000 - val_loss: 51461595136.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 54630268928.0000 - val_loss: 51382390784.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54547628032.0000 - val_loss: 51304386560.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 54472581120.0000 - val_loss: 51228995584.0000\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54392487936.0000 - val_loss: 51152035840.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54317416448.0000 - val_loss: 51078295552.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 54241263616.0000 - val_loss: 51006582784.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 54170238976.0000 - val_loss: 50941595648.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54095564800.0000 - val_loss: 50874167296.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 54026981376.0000 - val_loss: 50805972992.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 53956444160.0000 - val_loss: 50739814400.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 55305449472.000 - 0s 773us/step - loss: 53891473408.0000 - val_loss: 50678063104.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53820280832.0000 - val_loss: 50612920320.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 53761327104.0000 - val_loss: 50550079488.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 53692596224.0000 - val_loss: 50492391424.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53632450560.0000 - val_loss: 50428059648.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53567299584.0000 - val_loss: 50375106560.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 53509324800.0000 - val_loss: 50316345344.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 53448429568.0000 - val_loss: 50262790144.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53391544320.0000 - val_loss: 50210430976.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53334704128.0000 - val_loss: 50158882816.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53283160064.0000 - val_loss: 50107260928.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 53225320448.0000 - val_loss: 50056716288.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 53173985280.0000 - val_loss: 50005565440.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53117124608.0000 - val_loss: 49958727680.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 53068738560.0000 - val_loss: 49910636544.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53016465408.0000 - val_loss: 49862787072.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52969107456.0000 - val_loss: 49818492928.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52920688640.0000 - val_loss: 49773096960.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52870098944.0000 - val_loss: 49726709760.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52823478272.0000 - val_loss: 49683775488.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52778172416.0000 - val_loss: 49642119168.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52734312448.0000 - val_loss: 49601425408.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 52700188672.0000 - val_loss: 49562763264.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52650405888.0000 - val_loss: 49523277824.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 52608618496.0000 - val_loss: 49485406208.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 52563197952.0000 - val_loss: 49451200512.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52523380736.0000 - val_loss: 49405235200.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52483637248.0000 - val_loss: 49374052352.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 52444631040.0000 - val_loss: 49335365632.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 52409946112.0000 - val_loss: 49299435520.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 52364296192.0000 - val_loss: 49262997504.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52330389504.0000 - val_loss: 49226723328.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 52294176768.0000 - val_loss: 49197850624.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 52257890304.0000 - val_loss: 49165774848.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52217159680.0000 - val_loss: 49130381312.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 52181467136.0000 - val_loss: 49094209536.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52146446336.0000 - val_loss: 49062461440.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 52118433792.0000 - val_loss: 49033265152.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 52081704960.0000 - val_loss: 49001185280.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 52044673024.0000 - val_loss: 48975282176.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 52012228608.0000 - val_loss: 48945623040.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 51979083776.0000 - val_loss: 48914206720.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51947536384.0000 - val_loss: 48882724864.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 51914620928.0000 - val_loss: 48855441408.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51885793280.0000 - val_loss: 48826195968.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 51852312576.0000 - val_loss: 48797523968.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 51823202304.0000 - val_loss: 48770752512.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51797671936.0000 - val_loss: 48739913728.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51762458624.0000 - val_loss: 48718012416.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 51734126592.0000 - val_loss: 48689680384.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 51706564608.0000 - val_loss: 48667336704.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51675217920.0000 - val_loss: 48640421888.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 51643625472.0000 - val_loss: 48617242624.0000\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 817us/step - loss: 51617869824.0000 - val_loss: 48590127104.0000\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51589140480.0000 - val_loss: 48562147328.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 786us/step - loss: 51562971136.0000 - val_loss: 48537579520.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51535843328.0000 - val_loss: 48515764224.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51510579200.0000 - val_loss: 48491929600.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51481337856.0000 - val_loss: 48467648512.0000\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 51454988288.0000 - val_loss: 48439185408.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 51430985728.0000 - val_loss: 48421593088.0000\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51399221248.0000 - val_loss: 48392531968.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 51381829632.0000 - val_loss: 48368578560.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 51354398720.0000 - val_loss: 48344137728.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 51324547072.0000 - val_loss: 48328908800.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 51298734080.0000 - val_loss: 48307109888.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 51274936320.0000 - val_loss: 48284123136.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51249500160.0000 - val_loss: 48263712768.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 51224936448.0000 - val_loss: 48239534080.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 51203227648.0000 - val_loss: 48214728704.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51180912640.0000 - val_loss: 48198094848.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51150852096.0000 - val_loss: 48179560448.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 51127914496.0000 - val_loss: 48157872128.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51104567296.0000 - val_loss: 48131567616.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 51082801152.0000 - val_loss: 48112074752.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51056812032.0000 - val_loss: 48091344896.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 816us/step - loss: 51035541504.0000 - val_loss: 48072155136.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51017244672.0000 - val_loss: 48053026816.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50990809088.0000 - val_loss: 48034381824.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50966552576.0000 - val_loss: 48014397440.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 50944495616.0000 - val_loss: 47993663488.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50923343872.0000 - val_loss: 47972892672.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 50901618688.0000 - val_loss: 47952683008.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50878042112.0000 - val_loss: 47929118720.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50860310528.0000 - val_loss: 47913779200.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50836168704.0000 - val_loss: 47896485888.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50810920960.0000 - val_loss: 47874805760.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50793635840.0000 - val_loss: 47854149632.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50769195008.0000 - val_loss: 47838195712.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50746150912.0000 - val_loss: 47816105984.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50725343232.0000 - val_loss: 47800504320.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50702680064.0000 - val_loss: 47776432128.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 50680434688.0000 - val_loss: 47759802368.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50659721216.0000 - val_loss: 47740112896.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50636214272.0000 - val_loss: 47717748736.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50615468032.0000 - val_loss: 47698190336.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50594250752.0000 - val_loss: 47682076672.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 50572763136.0000 - val_loss: 47665131520.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50549186560.0000 - val_loss: 47645413376.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 50525884416.0000 - val_loss: 47623397376.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50504302592.0000 - val_loss: 47606898688.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50485063680.0000 - val_loss: 47589851136.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50464055296.0000 - val_loss: 47564619776.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50444218368.0000 - val_loss: 47546089472.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50415124480.0000 - val_loss: 47522873344.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50393354240.0000 - val_loss: 47507562496.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50368729088.0000 - val_loss: 47481552896.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50346471424.0000 - val_loss: 47461171200.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50325639168.0000 - val_loss: 47448555520.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50306105344.0000 - val_loss: 47430602752.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50276741120.0000 - val_loss: 47402950656.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50256691200.0000 - val_loss: 47381118976.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50230112256.0000 - val_loss: 47357550592.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 50204180480.0000 - val_loss: 47343591424.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50182762496.0000 - val_loss: 47321452544.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50154905600.0000 - val_loss: 47303696384.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50130239488.0000 - val_loss: 47276404736.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50107904000.0000 - val_loss: 47252246528.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50080555008.0000 - val_loss: 47232798720.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50054459392.0000 - val_loss: 47211220992.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50031329280.0000 - val_loss: 47188979712.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50001338368.0000 - val_loss: 47163121664.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 49975984128.0000 - val_loss: 47139217408.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49950097408.0000 - val_loss: 47108526080.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49923141632.0000 - val_loss: 47088197632.0000\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 49890299904.0000 - val_loss: 47062769664.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 49862787072.0000 - val_loss: 47036682240.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 49833553920.0000 - val_loss: 47010123776.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49802317824.0000 - val_loss: 46982221824.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 49774432256.0000 - val_loss: 46958288896.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 49740181504.0000 - val_loss: 46934003712.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 746us/step - loss: 49707401216.0000 - val_loss: 46900899840.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 49676623872.0000 - val_loss: 46869520384.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49651281920.0000 - val_loss: 46839644160.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49614290944.0000 - val_loss: 46811226112.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49578758144.0000 - val_loss: 46776930304.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 49544081408.0000 - val_loss: 46748323840.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 49509916672.0000 - val_loss: 46721736704.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 49475985408.0000 - val_loss: 46688591872.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 49441443840.0000 - val_loss: 46650945536.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 49407016960.0000 - val_loss: 46615171072.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49369337856.0000 - val_loss: 46583181312.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 49335640064.0000 - val_loss: 46550491136.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 49302302720.0000 - val_loss: 46525362176.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 49263534080.0000 - val_loss: 46484844544.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49225666560.0000 - val_loss: 46451859456.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 49186381824.0000 - val_loss: 46427004928.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 49148256256.0000 - val_loss: 46390464512.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 49114124288.0000 - val_loss: 46360018944.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 49075425280.0000 - val_loss: 46324985856.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 49041031168.0000 - val_loss: 46295724032.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 49005309952.0000 - val_loss: 46260641792.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 48969322496.0000 - val_loss: 46229889024.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48928505856.0000 - val_loss: 46197534720.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48894926848.0000 - val_loss: 46161862656.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 48856915968.0000 - val_loss: 46129856512.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 48824922112.0000 - val_loss: 46099099648.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48789037056.0000 - val_loss: 46069481472.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 48754130944.0000 - val_loss: 46041772032.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48720326656.0000 - val_loss: 46009479168.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 48683991040.0000 - val_loss: 45978722304.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 48653815808.0000 - val_loss: 45945901056.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48622874624.0000 - val_loss: 45920649216.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23df5db64c0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are planning to conduct multiple training, defining a function for creating a model will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.303555e+11</td>\n",
       "      <td>4.279443e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.303356e+11</td>\n",
       "      <td>4.279041e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.302631e+11</td>\n",
       "      <td>4.277922e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.301029e+11</td>\n",
       "      <td>4.275755e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.298207e+11</td>\n",
       "      <td>4.272158e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4.875413e+10</td>\n",
       "      <td>4.604177e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4.872033e+10</td>\n",
       "      <td>4.600948e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4.868399e+10</td>\n",
       "      <td>4.597872e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4.865382e+10</td>\n",
       "      <td>4.594590e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4.862287e+10</td>\n",
       "      <td>4.592065e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss      val_loss\n",
       "0    4.303555e+11  4.279443e+11\n",
       "1    4.303356e+11  4.279041e+11\n",
       "2    4.302631e+11  4.277922e+11\n",
       "3    4.301029e+11  4.275755e+11\n",
       "4    4.298207e+11  4.272158e+11\n",
       "..            ...           ...\n",
       "495  4.875413e+10  4.604177e+10\n",
       "496  4.872033e+10  4.600948e+10\n",
       "497  4.868399e+10  4.597872e+10\n",
       "498  4.865382e+10  4.594590e+10\n",
       "499  4.862287e+10  4.592065e+10\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows that our loss stabilizes around epoch = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first find out the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the price using the model we created using a X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133171.32541578315"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE is the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight. This shows that our prediction has average difference of $ 133171.33 from the actual price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6291026515034247"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has fair r2 score of 0.629."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23df93d65e0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows that the there are outliers that does not follow the y_test line. Our scatter points are closely aligned with the linear line up to around 2e-6 to 3e-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just for fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is more unit better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I did not understand fully on choosing number of unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "  1/114 [..............................] - ETA: 0s - loss: 369385603072.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 430345355264.0000 - val_loss: 427899420672.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 430131871744.0000 - val_loss: 427424186368.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 429204406272.0000 - val_loss: 425921314816.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 953us/step - loss: 426976411648.0000 - val_loss: 422835650560.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 422918127616.0000 - val_loss: 417682325504.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416610680832.0000 - val_loss: 410109018112.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 407729602560.0000 - val_loss: 399820029952.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 396134678528.0000 - val_loss: 386787409920.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 381849698304.0000 - val_loss: 371142295552.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 364974637056.0000 - val_loss: 352964411392.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345765904384.0000 - val_loss: 332664864768.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 324641619968.0000 - val_loss: 310672293888.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 302088093696.0000 - val_loss: 287506890752.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278660153344.0000 - val_loss: 263798374400.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254962024448.0000 - val_loss: 240069378048.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 231735394304.0000 - val_loss: 217215582208.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 209552244736.0000 - val_loss: 195660185600.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 189015572480.0000 - val_loss: 176058793984.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 170548674560.0000 - val_loss: 158827511808.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 154518011904.0000 - val_loss: 144027860992.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 141129007104.0000 - val_loss: 131972464640.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 130405941248.0000 - val_loss: 122564952064.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 122242334720.0000 - val_loss: 115501105152.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 116213334016.0000 - val_loss: 110518247424.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 112031571968.0000 - val_loss: 107037302784.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 109266313216.0000 - val_loss: 104834228224.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 107486838784.0000 - val_loss: 103436632064.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 106353680384.0000 - val_loss: 102521659392.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 105631268864.0000 - val_loss: 101951823872.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 105133350912.0000 - val_loss: 101525544960.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 104740241408.0000 - val_loss: 101163868160.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 104416231424.0000 - val_loss: 100853235712.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 104096227328.0000 - val_loss: 100539244544.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 103788781568.0000 - val_loss: 100228882432.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103478829056.0000 - val_loss: 99912736768.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103159930880.0000 - val_loss: 99585728512.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102828441600.0000 - val_loss: 99254681600.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 102489186304.0000 - val_loss: 98909306880.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 102137077760.0000 - val_loss: 98553233408.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 101777752064.0000 - val_loss: 98180284416.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 101408481280.0000 - val_loss: 97809170432.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 101032542208.0000 - val_loss: 97429053440.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 100643168256.0000 - val_loss: 97043283968.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 100250992640.0000 - val_loss: 96639852544.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 99848658944.0000 - val_loss: 96235167744.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 99436617728.0000 - val_loss: 95816679424.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 99020136448.0000 - val_loss: 95395160064.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 98592382976.0000 - val_loss: 94968930304.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 98154176512.0000 - val_loss: 94520786944.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 97709834240.0000 - val_loss: 94070915072.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 97259126784.0000 - val_loss: 93619666944.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 96807854080.0000 - val_loss: 93160472576.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 96348930048.0000 - val_loss: 92704292864.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 95878897664.0000 - val_loss: 92229271552.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 95397502976.0000 - val_loss: 91755995136.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 94920957952.0000 - val_loss: 91276410880.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 94438416384.0000 - val_loss: 90778214400.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 93941170176.0000 - val_loss: 90286628864.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 93436141568.0000 - val_loss: 89775071232.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 92929499136.0000 - val_loss: 89267331072.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 92417728512.0000 - val_loss: 88754069504.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 91901550592.0000 - val_loss: 88235458560.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 91379867648.0000 - val_loss: 87701651456.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 90852204544.0000 - val_loss: 87183400960.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 90331209728.0000 - val_loss: 86647873536.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 89791545344.0000 - val_loss: 86114115584.0000\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 89255059456.0000 - val_loss: 85572386816.0000\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 88709038080.0000 - val_loss: 85030494208.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 88160894976.0000 - val_loss: 84472258560.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 87606411264.0000 - val_loss: 83918495744.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 87054229504.0000 - val_loss: 83360899072.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 86499328000.0000 - val_loss: 82810363904.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 85939871744.0000 - val_loss: 82244378624.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 85377376256.0000 - val_loss: 81671421952.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 84809015296.0000 - val_loss: 81097965568.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 84225728512.0000 - val_loss: 80523280384.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 83645243392.0000 - val_loss: 79934136320.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 83060547584.0000 - val_loss: 79352750080.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 82470035456.0000 - val_loss: 78759460864.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 81868783616.0000 - val_loss: 78164369408.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 81280286720.0000 - val_loss: 77557948416.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 80662552576.0000 - val_loss: 76942024704.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 80052969472.0000 - val_loss: 76330844160.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 79431049216.0000 - val_loss: 75700903936.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 78805794816.0000 - val_loss: 75085389824.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 78181277696.0000 - val_loss: 74458071040.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 77560463360.0000 - val_loss: 73823551488.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 76927533056.0000 - val_loss: 73189482496.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 76289212416.0000 - val_loss: 72555544576.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 75655233536.0000 - val_loss: 71935541248.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 75024482304.0000 - val_loss: 71300390912.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 74401824768.0000 - val_loss: 70664265728.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 73767444480.0000 - val_loss: 70040338432.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 73144164352.0000 - val_loss: 69425618944.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 72535613440.0000 - val_loss: 68795179008.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 71909842944.0000 - val_loss: 68184375296.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 71284785152.0000 - val_loss: 67555323904.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 70668034048.0000 - val_loss: 66949435392.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 70053240832.0000 - val_loss: 66331115520.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 69438464000.0000 - val_loss: 65728335872.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 68842864640.0000 - val_loss: 65134587904.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 68244316160.0000 - val_loss: 64537133056.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 67652526080.0000 - val_loss: 63966474240.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 67069612032.0000 - val_loss: 63382044672.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 66497503232.0000 - val_loss: 62813122560.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 65934598144.0000 - val_loss: 62253232128.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 65368018944.0000 - val_loss: 61707915264.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 64815656960.0000 - val_loss: 61152202752.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 64276742144.0000 - val_loss: 60609142784.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 63738458112.0000 - val_loss: 60081987584.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 63222145024.0000 - val_loss: 59577905152.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 62693330944.0000 - val_loss: 59071746048.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 62197071872.0000 - val_loss: 58581700608.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 61707231232.0000 - val_loss: 58104811520.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 882us/step - loss: 61233893376.0000 - val_loss: 57638830080.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 60766003200.0000 - val_loss: 57179152384.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 60314923008.0000 - val_loss: 56746057728.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 59877765120.0000 - val_loss: 56324722688.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 59443830784.0000 - val_loss: 55910936576.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 59041185792.0000 - val_loss: 55508922368.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 58633031680.0000 - val_loss: 55111942144.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 58243911680.0000 - val_loss: 54750633984.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 57876258816.0000 - val_loss: 54392356864.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 57529950208.0000 - val_loss: 54040457216.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 57180418048.0000 - val_loss: 53730938880.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56869130240.0000 - val_loss: 53414125568.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56559034368.0000 - val_loss: 53127897088.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56248401920.0000 - val_loss: 52843536384.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55974944768.0000 - val_loss: 52584001536.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 55729393664.0000 - val_loss: 52340076544.0000\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55460683776.0000 - val_loss: 52093005824.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 55228166144.0000 - val_loss: 51869245440.0000\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 54997409792.0000 - val_loss: 51651735552.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 54792609792.0000 - val_loss: 51471908864.0000\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54587039744.0000 - val_loss: 51269668864.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 54391476224.0000 - val_loss: 51084111872.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 54204719104.0000 - val_loss: 50915282944.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 54030098432.0000 - val_loss: 50756558848.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 53859536896.0000 - val_loss: 50607919104.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53708914688.0000 - val_loss: 50448564224.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 53554831360.0000 - val_loss: 50313019392.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53405036544.0000 - val_loss: 50179342336.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53266509824.0000 - val_loss: 50060279808.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53139140608.0000 - val_loss: 49949507584.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53009420288.0000 - val_loss: 49819111424.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52878700544.0000 - val_loss: 49694392320.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52766449664.0000 - val_loss: 49586925568.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52661706752.0000 - val_loss: 49491582976.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52546174976.0000 - val_loss: 49388228608.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 52443660288.0000 - val_loss: 49300357120.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 52343250944.0000 - val_loss: 49212411904.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 52242530304.0000 - val_loss: 49113616384.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 52148244480.0000 - val_loss: 49026904064.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 52045713408.0000 - val_loss: 48941187072.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 51950252032.0000 - val_loss: 48850509824.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 51861377024.0000 - val_loss: 48767881216.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 51771195392.0000 - val_loss: 48689545216.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 51681431552.0000 - val_loss: 48619806720.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51594153984.0000 - val_loss: 48535900160.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51505770496.0000 - val_loss: 48460701696.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51428233216.0000 - val_loss: 48382242816.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 51334995968.0000 - val_loss: 48304418816.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51264086016.0000 - val_loss: 48235339776.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51182977024.0000 - val_loss: 48168890368.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 51097767936.0000 - val_loss: 48098365440.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 51029049344.0000 - val_loss: 48037576704.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 50960105472.0000 - val_loss: 47955050496.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50888744960.0000 - val_loss: 47901294592.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 50809241600.0000 - val_loss: 47857287168.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 50742505472.0000 - val_loss: 47778062336.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 50674016256.0000 - val_loss: 47723429888.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50606669824.0000 - val_loss: 47656767488.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 50374524928.000 - 0s 1ms/step - loss: 50537279488.0000 - val_loss: 47594532864.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50462515200.0000 - val_loss: 47541809152.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50390523904.0000 - val_loss: 47462555648.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50323546112.0000 - val_loss: 47392931840.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 50252771328.0000 - val_loss: 47341178880.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 50180476928.0000 - val_loss: 47275696128.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 50100629504.0000 - val_loss: 47222349824.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50029694976.0000 - val_loss: 47129223168.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 49941176320.0000 - val_loss: 47069081600.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49866170368.0000 - val_loss: 46990716928.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 49783328768.0000 - val_loss: 46917349376.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 49714442240.0000 - val_loss: 46842900480.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49624760320.0000 - val_loss: 46787969024.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 49551691776.0000 - val_loss: 46717480960.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 49465032704.0000 - val_loss: 46645727232.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 49391788032.0000 - val_loss: 46580006912.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 49312993280.0000 - val_loss: 46496464896.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49238269952.0000 - val_loss: 46426464256.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 49168396288.0000 - val_loss: 46383288320.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 49097785344.0000 - val_loss: 46295203840.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49023029248.0000 - val_loss: 46239793152.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 48948445184.0000 - val_loss: 46195015680.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 48879321088.0000 - val_loss: 46105309184.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 48822214656.0000 - val_loss: 46039904256.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 48741167104.0000 - val_loss: 45984468992.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 48666341376.0000 - val_loss: 45906821120.0000\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 48585162752.0000 - val_loss: 45836673024.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48513363968.0000 - val_loss: 45782147072.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 48433246208.0000 - val_loss: 45720903680.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48366686208.0000 - val_loss: 45650853888.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 48285474816.0000 - val_loss: 45582471168.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48213831680.0000 - val_loss: 45515796480.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 48136085504.0000 - val_loss: 45441302528.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 48052719616.0000 - val_loss: 45373808640.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 47976943616.0000 - val_loss: 45318647808.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 47906553856.0000 - val_loss: 45237534720.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 47833321472.0000 - val_loss: 45220659200.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47770222592.0000 - val_loss: 45122441216.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47707471872.0000 - val_loss: 45063880704.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 47632494592.0000 - val_loss: 45004132352.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 47576535040.0000 - val_loss: 44938502144.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 47511207936.0000 - val_loss: 44886609920.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 47442632704.0000 - val_loss: 44854927360.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 47381827584.0000 - val_loss: 44788899840.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 47322251264.0000 - val_loss: 44731199488.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 47255494656.0000 - val_loss: 44667056128.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 47198822400.0000 - val_loss: 44621606912.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 47139536896.0000 - val_loss: 44563652608.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 47071019008.0000 - val_loss: 44515151872.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 917us/step - loss: 47011819520.0000 - val_loss: 44446806016.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 46946201600.0000 - val_loss: 44405829632.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 46875103232.0000 - val_loss: 44321906688.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 46811979776.0000 - val_loss: 44282200064.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 46754648064.0000 - val_loss: 44221358080.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 46686752768.0000 - val_loss: 44154249216.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 46621405184.0000 - val_loss: 44110143488.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 46558105600.0000 - val_loss: 44047925248.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 46494973952.0000 - val_loss: 43983798272.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 46435049472.0000 - val_loss: 43923644416.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 46378737664.0000 - val_loss: 43871043584.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 46307995648.0000 - val_loss: 43822231552.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46241931264.0000 - val_loss: 43773927424.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 46179360768.0000 - val_loss: 43714060288.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 46121943040.0000 - val_loss: 43647107072.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 46059274240.0000 - val_loss: 43595194368.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 45984415744.0000 - val_loss: 43530629120.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 45919133696.0000 - val_loss: 43492810752.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 45855531008.0000 - val_loss: 43412713472.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 45781336064.0000 - val_loss: 43344093184.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 45716713472.0000 - val_loss: 43288301568.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 45652357120.0000 - val_loss: 43223302144.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 45575376896.0000 - val_loss: 43165564928.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 45507817472.0000 - val_loss: 43104964608.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 45434925056.0000 - val_loss: 43053912064.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 45368651776.0000 - val_loss: 42970611712.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45309530112.0000 - val_loss: 42916712448.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45228376064.0000 - val_loss: 42854449152.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45146398720.0000 - val_loss: 42787557376.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 45081231360.0000 - val_loss: 42701029376.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 45012332544.0000 - val_loss: 42658156544.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 44928950272.0000 - val_loss: 42608254976.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 44859392000.0000 - val_loss: 42522775552.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 44788473856.0000 - val_loss: 42462109696.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44706226176.0000 - val_loss: 42403577856.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44636221440.0000 - val_loss: 42352427008.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 44559269888.0000 - val_loss: 42257309696.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 44488409088.0000 - val_loss: 42219802624.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 44415774720.0000 - val_loss: 42129235968.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 44343521280.0000 - val_loss: 42073690112.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 44272214016.0000 - val_loss: 42028572672.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44198744064.0000 - val_loss: 41950257152.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 44130336768.0000 - val_loss: 41890942976.0000\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 44071473152.0000 - val_loss: 41829466112.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 44011122688.0000 - val_loss: 41768103936.0000\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43937607680.0000 - val_loss: 41713156096.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43880300544.0000 - val_loss: 41660133376.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 43804913664.0000 - val_loss: 41619283968.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 43747549184.0000 - val_loss: 41568522240.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43691876352.0000 - val_loss: 41508110336.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43631931392.0000 - val_loss: 41467756544.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43574042624.0000 - val_loss: 41409093632.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43519623168.0000 - val_loss: 41365237760.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 43465154560.0000 - val_loss: 41332097024.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43407474688.0000 - val_loss: 41266286592.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 43353997312.0000 - val_loss: 41209643008.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 43304669184.0000 - val_loss: 41194262528.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43257409536.0000 - val_loss: 41131577344.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 43200524288.0000 - val_loss: 41076240384.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43145969664.0000 - val_loss: 41025994752.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 43106385920.0000 - val_loss: 40973299712.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 43050754048.0000 - val_loss: 40949911552.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 42992852992.0000 - val_loss: 40898859008.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 42943115264.0000 - val_loss: 40855957504.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42888896512.0000 - val_loss: 40798769152.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42852298752.0000 - val_loss: 40750948352.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42788007936.0000 - val_loss: 40717119488.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 42738774016.0000 - val_loss: 40674271232.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 42693828608.0000 - val_loss: 40631377920.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42638102528.0000 - val_loss: 40578330624.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 42591637504.0000 - val_loss: 40550588416.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42533507072.0000 - val_loss: 40506994688.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42491510784.0000 - val_loss: 40478343168.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42444144640.0000 - val_loss: 40425545728.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42377945088.0000 - val_loss: 40362008576.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 42332385280.0000 - val_loss: 40338915328.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42285981696.0000 - val_loss: 40272015360.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42239414272.0000 - val_loss: 40233549824.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42177949696.0000 - val_loss: 40209575936.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42131398656.0000 - val_loss: 40145350656.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42078388224.0000 - val_loss: 40114495488.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42032668672.0000 - val_loss: 40067985408.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41981210624.0000 - val_loss: 40032776192.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41928323072.0000 - val_loss: 39965351936.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 41875775488.0000 - val_loss: 39960379392.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 41830121472.0000 - val_loss: 39890698240.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41777852416.0000 - val_loss: 39828217856.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41734205440.0000 - val_loss: 39798259712.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 41685012480.0000 - val_loss: 39776837632.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41620705280.0000 - val_loss: 39715917824.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 41571151872.0000 - val_loss: 39661391872.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 41516740608.0000 - val_loss: 39638134784.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 41472684032.0000 - val_loss: 39608442880.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 38775971840.000 - 0s 983us/step - loss: 41423257600.0000 - val_loss: 39549325312.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 41364570112.0000 - val_loss: 39493156864.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41320968192.0000 - val_loss: 39452389376.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 41270472704.0000 - val_loss: 39417475072.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41229004800.0000 - val_loss: 39361560576.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41170509824.0000 - val_loss: 39330873344.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 41126645760.0000 - val_loss: 39291506688.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41069096960.0000 - val_loss: 39251357696.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 41026830336.0000 - val_loss: 39210692608.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 40979042304.0000 - val_loss: 39179153408.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 40937136128.0000 - val_loss: 39122472960.0000\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 40892284928.0000 - val_loss: 39086379008.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 40836816896.0000 - val_loss: 39054819328.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 40788451328.0000 - val_loss: 39033159680.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40735780864.0000 - val_loss: 38973788160.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 40686448640.0000 - val_loss: 38932373504.0000\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 40639483904.0000 - val_loss: 38881767424.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 900us/step - loss: 40595619840.0000 - val_loss: 38861778944.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40547454976.0000 - val_loss: 38827954176.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 40502861824.0000 - val_loss: 38778372096.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 40468901888.0000 - val_loss: 38742962176.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40423665664.0000 - val_loss: 38710652928.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40377802752.0000 - val_loss: 38686007296.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40336424960.0000 - val_loss: 38645399552.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40289144832.0000 - val_loss: 38611292160.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 40251129856.0000 - val_loss: 38583468032.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40206557184.0000 - val_loss: 38547673088.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40169578496.0000 - val_loss: 38542102528.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40129818624.0000 - val_loss: 38492053504.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 40080375808.0000 - val_loss: 38441529344.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 40049647616.0000 - val_loss: 38400237568.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 40008200192.0000 - val_loss: 38370721792.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39967301632.0000 - val_loss: 38334545920.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39926800384.0000 - val_loss: 38327287808.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39906123776.0000 - val_loss: 38289092608.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39849897984.0000 - val_loss: 38273650688.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 39810691072.0000 - val_loss: 38232813568.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39780933632.0000 - val_loss: 38200283136.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 39739568128.0000 - val_loss: 38181347328.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 39712538624.0000 - val_loss: 38140235776.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 39666524160.0000 - val_loss: 38150856704.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39643901952.0000 - val_loss: 38115037184.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 39600943104.0000 - val_loss: 38074400768.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39560163328.0000 - val_loss: 38041874432.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39537786880.0000 - val_loss: 38018293760.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 39495610368.0000 - val_loss: 37982666752.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 39468105728.0000 - val_loss: 37975343104.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39431405568.0000 - val_loss: 37948170240.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39401869312.0000 - val_loss: 37933371392.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39369670656.0000 - val_loss: 37906518016.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39341182976.0000 - val_loss: 37886017536.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39312912384.0000 - val_loss: 37862735872.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 39272325120.0000 - val_loss: 37842669568.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39246065664.0000 - val_loss: 37823332352.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 39216107520.0000 - val_loss: 37788708864.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39189544960.0000 - val_loss: 37761114112.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39154450432.0000 - val_loss: 37756456960.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 39137300480.0000 - val_loss: 37717262336.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 39109890048.0000 - val_loss: 37696409600.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 39074209792.0000 - val_loss: 37681856512.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 39051558912.0000 - val_loss: 37685026816.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39022604288.0000 - val_loss: 37668175872.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38988267520.0000 - val_loss: 37623033856.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 38961229824.0000 - val_loss: 37601189888.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38931714048.0000 - val_loss: 37610844160.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38906916864.0000 - val_loss: 37564112896.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38882938880.0000 - val_loss: 37555130368.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38866264064.0000 - val_loss: 37559029760.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38833606656.0000 - val_loss: 37515153408.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38812839936.0000 - val_loss: 37509734400.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38782980096.0000 - val_loss: 37489356800.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38767058944.0000 - val_loss: 37456723968.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 38733565952.0000 - val_loss: 37443031040.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38706098176.0000 - val_loss: 37444390912.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 38685024256.0000 - val_loss: 37410283520.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38662287360.0000 - val_loss: 37407711232.0000\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38640226304.0000 - val_loss: 37369061376.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 38618722304.0000 - val_loss: 37378736128.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38597246976.0000 - val_loss: 37375660032.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 38579195904.0000 - val_loss: 37357969408.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38552657920.0000 - val_loss: 37331681280.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 38525431808.0000 - val_loss: 37300400128.0000\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38510325760.0000 - val_loss: 37301489664.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38488899584.0000 - val_loss: 37311762432.0000\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 38461751296.0000 - val_loss: 37250641920.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 38446219264.0000 - val_loss: 37267062784.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38429278208.0000 - val_loss: 37250670592.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38401081344.0000 - val_loss: 37234458624.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 38380376064.0000 - val_loss: 37219594240.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38373601280.0000 - val_loss: 37202423808.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38344523776.0000 - val_loss: 37195243520.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 38338031616.0000 - val_loss: 37186703360.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38302937088.0000 - val_loss: 37155696640.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 38281977856.0000 - val_loss: 37134454784.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38270197760.0000 - val_loss: 37147873280.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38243278848.0000 - val_loss: 37120434176.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38225592320.0000 - val_loss: 37103198208.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38210912256.0000 - val_loss: 37093478400.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38195851264.0000 - val_loss: 37083709440.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38166556672.0000 - val_loss: 37067870208.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 38159331328.0000 - val_loss: 37099552768.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 38134251520.0000 - val_loss: 37051838464.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38111449088.0000 - val_loss: 37031759872.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 38094336000.0000 - val_loss: 37004582912.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38081552384.0000 - val_loss: 37004316672.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38061588480.0000 - val_loss: 36981071872.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 38038253568.0000 - val_loss: 36986826752.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 38026399744.0000 - val_loss: 36972277760.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38010978304.0000 - val_loss: 36957245440.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 37995859968.0000 - val_loss: 36941615104.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37984514048.0000 - val_loss: 36949807104.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37959045120.0000 - val_loss: 36935163904.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37943537664.0000 - val_loss: 36940451840.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37926735872.0000 - val_loss: 36929904640.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37903306752.0000 - val_loss: 36878942208.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37891137536.0000 - val_loss: 36869529600.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37873123328.0000 - val_loss: 36888514560.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37865607168.0000 - val_loss: 36831186944.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37842554880.0000 - val_loss: 36853743616.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37825560576.0000 - val_loss: 36835246080.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37807714304.0000 - val_loss: 36827041792.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37794648064.0000 - val_loss: 36807692288.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37777252352.0000 - val_loss: 36825952256.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37765095424.0000 - val_loss: 36790296576.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 900us/step - loss: 37750259712.0000 - val_loss: 36793757696.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37732995072.0000 - val_loss: 36761817088.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37722988544.0000 - val_loss: 36767436800.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37701332992.0000 - val_loss: 36751577088.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37687607296.0000 - val_loss: 36730757120.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37674332160.0000 - val_loss: 36748038144.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37660475392.0000 - val_loss: 36684365824.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37657935872.0000 - val_loss: 36698099712.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37626650624.0000 - val_loss: 36667297792.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37617577984.0000 - val_loss: 36679487488.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37601005568.0000 - val_loss: 36662431744.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37591158784.0000 - val_loss: 36657569792.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37579395072.0000 - val_loss: 36645945344.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37560078336.0000 - val_loss: 36627828736.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37545435136.0000 - val_loss: 36623048704.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37530906624.0000 - val_loss: 36618772480.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 37520072704.0000 - val_loss: 36601311232.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37499580416.0000 - val_loss: 36579803136.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37487591424.0000 - val_loss: 36566544384.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37481189376.0000 - val_loss: 36555055104.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37460398080.0000 - val_loss: 36556902400.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37450219520.0000 - val_loss: 36566700032.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37432913920.0000 - val_loss: 36542337024.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37416448000.0000 - val_loss: 36524728320.0000\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 37404372992.0000 - val_loss: 36517904384.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37396254720.0000 - val_loss: 36510294016.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37392109568.0000 - val_loss: 36488810496.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 37368967168.0000 - val_loss: 36485169152.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37357228032.0000 - val_loss: 36474425344.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37348122624.0000 - val_loss: 36463284224.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37328965632.0000 - val_loss: 36453007360.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37321031680.0000 - val_loss: 36446855168.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37306314752.0000 - val_loss: 36448710656.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37289242624.0000 - val_loss: 36453167104.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37273526272.0000 - val_loss: 36430848000.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37263065088.0000 - val_loss: 36434583552.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37252849664.0000 - val_loss: 36425424896.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37247410176.0000 - val_loss: 36391170048.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 37233766400.0000 - val_loss: 36369846272.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37220188160.0000 - val_loss: 36381384704.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37207068672.0000 - val_loss: 36400627712.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 37191933952.0000 - val_loss: 36360916992.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37194702848.0000 - val_loss: 36369281024.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37174710272.0000 - val_loss: 36367716352.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37157138432.0000 - val_loss: 36353036288.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 37140373504.0000 - val_loss: 36341006336.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37132869632.0000 - val_loss: 36319162368.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37119307776.0000 - val_loss: 36316262400.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37118529536.0000 - val_loss: 36310052864.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37102030848.0000 - val_loss: 36295479296.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37086691328.0000 - val_loss: 36298772480.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37084012544.0000 - val_loss: 36282929152.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37062451200.0000 - val_loss: 36282118144.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37059432448.0000 - val_loss: 36273659904.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37039853568.0000 - val_loss: 36259708928.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37030043648.0000 - val_loss: 36248801280.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37016338432.0000 - val_loss: 36241100800.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37008646144.0000 - val_loss: 36202774528.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 36998324224.0000 - val_loss: 36213379072.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 36990083072.0000 - val_loss: 36194205696.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 36980477952.0000 - val_loss: 36184068096.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 36962418688.0000 - val_loss: 36180631552.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23df9425490>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7119090025111907"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23df9725d60>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAF9CAYAAAAQg/wSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/40lEQVR4nO3de3RU5b3/8c+TYYAQwEBBhSAiaMELAsdoxfx0KUqxXhDUagva1Z5WrMf2FLW0WLHqqRUsxyptradgaxWRUlGjQhUrUitWFDREDgJVRIGAh2iJIEQIyfP7Y2cumey5JTOz90zer7Vc8OzM5cuYlf3JczXWWgEAAKClIq8LAAAA8CNCEgAAgAtCEgAAgAtCEgAAgAtCEgAAgAtCEgAAgIushSRjzB+MMbuMMf+b4uOvMMa8Y4xZb4x5LFt1AQAApMJka58kY8xZkj6T9Ii19qQkjz1O0p8ljbHW7jbGHG6t3ZWVwgAAAFKQtZ4ka+3fJf0r+poxZogx5nljzJvGmFeMMcOav3SNpPuttbubn0tAAgAAnsr1nKS5kr5vrT1F0g8l/bb5+hclfdEY86oxZpUx5vwc1wUAANBCp1y9kTGmu6QzJD1ujAld7hJVx3GSzpY0QNIrxpiTrLV1uaoPAAAgWs5Ckpxeqzpr7UiXr22XtMpa2yBpizFmk5zQtDqH9QEAAITlbLjNWrtHTgD6qiQZx4jmL1dKOqf5eh85w2/v56o2AACAWNncAmChpNckDTXGbDfGfFvSZEnfNsZUS1ov6ZLmhy+T9Ikx5h1JKyRNs9Z+kq3aAAAAksnaFgAAAAD5jB23AQAAXBCSAAAAXGRldVufPn3soEGDsvHSAAAAGfXmm29+bK3tG3s9KyFp0KBBWrNmTTZeGgAAIKOMMR+6XWe4DQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAAwAUhCQAA+M+HH0qvvOJpCUkPuDXGDJW0KOrSYEk/tdbel62iAABAB3XggHTKKdL69U7bWs9KSdqTZK3dZK0daa0dKekUSfslPZXtwgAAQAdzyy1S166RgPSnP3laTtKepBjnStpsrf0wG8UAAIAO6MUXpbFjI+2rr5YeflgyxrualH5I+pqkhW5fMMZMkTRFkgYOHNjOsgAAQMHbuVPq3z/S7tnTmYtUWupZSdFSnrhtjOksabykx92+bq2da60tt9aW9+3bN1P1AQCAQtPYKI0Z0zIgrVkjffqpbwKSlN7qtq9Iesta+3/ZKgYAABS4++6TOnWSVqxw2r/+tTM5+5RTPC3LTTrDbV9XnKE2AACAhN54Q/rSlyLtceOkpUulQMC7mpJIKSQZY7pJGivp2uyWAwAACsru3VJZmVRfH7n20UfSEUd4V1OKUhpus9but9Z+wVr7abYLAgAABcBaadIkqXfvSEBavty5ngcBSWLHbQAAkGmPPCIVFUkLm2fp/PSnTjgaM8bbutKU7hYAAAAA7jZskE44IdIeOVJatUrq0sWzktqDkAQAANpn/34nHH0Ytdf0++9LxxzjXU0ZwHAbAABou6lTpZKSSEB68klnaC3PA5JETxIAAGiLJUukiy+OtK+7Trr/fs+PEskkQhIAAEjd1q3S0UdH2v36Sf/8p9S9u3c1ZQnDbQAAILmGBmczyOiA9Pbb0o4dBRmQJEISAABI5uc/lzp3dnbNlqR585x5R8OHe1tXljHcBgAA3L3yinTWWZH2xInS4sXOHkgdACEJAAC0VFsrHX54pG2MtGuX1KePdzV5oGNEQQAAkFxTkzR+fMuA9OqrzvUOFpAkQhIAAJCkuXOlQEB69lmnPWuWM+/ojDO8rctDDLcBANCRVVc7x4eEVFRIf/ub1ImIwCcAAEBHtHevNGSIM/8oZNs2acAA72ryGYbbAADoSKyVpkyRevaMBKSlS53rBKQWCEkAAHQUoeX78+Y57ZtucsLRBRd4W5dPMdwGAECh27xZOvbYSPu445y5SMXF3tWUB+hJAgCgUB04IJ10UsuAtHGjc9YaASkpQhIAAIXollukrl2l9eud9oIFztDa0KHe1pVHGG4DAKCQvPiiNHZspH311dLDDzu7ZiMthCQAAArBzp1S//6Rdo8e0tatUmmpZyXlO4bbAADIZ42N0pgxLQPS6tXSnj0EpHYiJAEAkK/uu8/ZGXvFCqc9Z44z76i83NOyCgXDbQAA5Js33pC+9KVIe+xY6bnnnLPXkDGEJAAA8sXu3VJZmVRfH7m2c6d05JHe1VTAGG4DAMDvrJUmTZJ6944EpOXLnesEpKwhJAEA4Gfz5ztHiSxc6LR/+lMnHI0Z421dHQDDbQAA+NGGDdIJJ0TaI0dKq1ZJXbp4VlJHQ0gCAMBP9u93jhLZsiVy7f33pWOO8a6mDorhNgAA/GLqVKmkJBKQnnzSGVojIHmCniQAALy2ZIl08cWR9nXXSfffz1EiHiMkAQDgla1bpaOPjrT79ZP++U+pe3fvakIYw20AAORaQ4OzGWR0QHr7bWnHDgKSj6QUkowxpcaYxcaYjcaYDcaY0dkuDACAgvTzn0udOzu7ZkvSvHnOvKPhw72tC62kOtw2R9Lz1trLjTGdJXXLYk0AABSeV16Rzjor0p44UVq82NkDCb6UNCQZY3pKOkvSNyXJWntQ0sHslgUAQIGorZUOPzzSNkbatUvq08e7mpCSVOLrYEm1kh4yxlQZYx40xpTEPsgYM8UYs8YYs6a2tjbjhQIAkFeamqTx41sGpJUrnesEpLyQSkjqJOnfJD1grR0laZ+k6bEPstbOtdaWW2vL+/btm+EyAQDII3PnSoGA9OyzTnvWLGfeUUWFt3UhLanMSdouabu19vXm9mK5hCQAADq86mrn+JCQigppxQopGPSsJLRd0pBkrf3IGLPNGDPUWrtJ0rmS3sl+aQAA5Im9e6UhQ5z5RyHbtkkDBnhXE9ot1Sn135e0wBjztqSRku7KWkUAAOQLa6UpU6SePSMBaelS5zoBKe+ltAWAtXatpPLslgIAQB5ZvFj66lcj7Ztukv77v72rBxnHsSQAAKRj82bp2GMj7eOOc+YiFRd7VxOygh2sAABIxYED0kkntQxIGzc6Z60RkAoSIQkAgGRmzJC6dpXWr3faCxY4846GDvW2LmQVw20AAMTz4ovS2LGR9tVXSw8/7OyajYJHSAIAINbOnVL//pF2jx7S1q1SaalnJSH3GG4DACCksVEaM6ZlQFq9Wtqzh4DUARGSAACQpPvukzp1cnbIlqQ5c5x5R+XsgNNRMdwGAOjY3nhD+tKXIu2xY6XnnnPOXkOHRkgCAHRMu3dLZWVSfX3k2s6d0pFHelcTfIXhNgBAx2KtNGmS1Lt3JCAtX+5cJyAhCiEJANBxzJ8vFRVJCxc67VtvdcLRmDHe1gVfYrgNAFD4NmyQTjgh0h4xQnr9dalLF+9qgu8RkgAAhWv/fucokS1bItc2b5YGD/auJuQNhtsAAIVp6lSppCQSkJ54whlaIyAhRfQkAQAKy5Il0sUXR9rXXSfdfz9HiSBthCQAQGHYulU6+uhIu18/6Z//lLp3964m5DWG2wAA+a2hQTr99JYB6e23pR07CEhoF0ISACB/zZwpde7srFSTpHnznHlHw4d7WxcKAsNtAID8s3KldOaZkfbEidLixc4eSECGEJIAAPmjtlY6/PBI2xhp1y6pTx/vakLBInIDAPyvqUkaP75lQFq50rlOQEKWEJIAAP42d64UCEjPPuu0Z81y5h1VVHhbFwoew20AAH+qrpZGjoy0KyqkFSukYNCzktCxEJIAAP6yd680ZIgz/yhk2zZpwADvakKHxHAbAMAfrJWmTJF69owEpKVLnesEJHiAkAQA8F5o+f68eU77xhudcHTBBd7WhQ6N4TYAgHc2b5aOPTbSHjJEWrdOKi72riagGT1JAIDcO3BAOumklgFpwwbpvfcISPANQhIAILdmzJC6dpXWr3fajz7qDK0NG+ZtXUAMhtsAALnx4ovS2LGR9tVXSw8/7OyaDfgQIQkAkF07d0r9+0faPXpIW7dKpaWelQSkguE2AEB2NDZK553XMiCtXi3t2UNAQl4gJAEAMm/OHKlTJ2n58kjbWqm83Nu6gDSkNNxmjPlA0l5JjZIOWWv5LgcAtLZ6tXTaaZH22LHSc885Z68BeSadOUnnWGs/zlolAID8tXu3VFYm1ddHru3cKR15pHc1Ae3EcBsAoO2slSZNknr3jgSk5cud6wQk5LlUQ5KV9IIx5k1jzBS3Bxhjphhj1hhj1tRGH0oIAChM8+c7R4ksXOi0b73VCUdjxnhbF5AhqQ63VVhrdxhjDpf0V2PMRmvt36MfYK2dK2muJJWXl9sM1wkA8IsNG6QTToi0R4yQXn9d6tLFu5qALEipJ8lau6P5z12SnpJ0WuJnAAAKzv790uDBLQPS5s3S2rUEJBSkpCHJGFNijOkR+rukL0v632wXBgDwkalTpZISacsWp714sTO0Nniwp2UB2ZTKcNsRkp4yzrbxnSQ9Zq19PqtVAQD8YckS6eKLI+1rr5UeeICjRNAhJA1J1tr3JY3IQS0AAL/YulU6+uhI+4gjpPfek7p3964mIMfYAgAAENHQIJ1+esuAVF0tffQRAQkdDiEJAOCYOVPq3NlZqSZJ8+Y5845OPtnbugCPpLPjNgCgEK1cKZ15ZqQ9caIzMbuI36PRsRGSAKCj+vhjqW/fSNsYadcuqU8f72oCfIRfEwCgo2lqkiZMaBmQVq50rhOQgDBCEgB0JHPnSoGA9PTTTnvWLGfeUUWFt3UBPsRwGwB0BNXV0siRkXZFhbRihRQMelYS4HeEJAAoZHv3SkOGSNEHj2/bJg0Y4F1NQJ5guA0ACpG10pQpUs+ekYC0dKlznYAEpISQBACFJrR8f948p33jjU44uuACb+sC8gzDbQBQKDZvlo49NtIeMkRat04qLvauJiCP0ZMEAPnuwAHppJNaBqQNG5yz1ghIQJsRkgAgn82YIXXtKq1f77Tnz3eG1oYN87YuoAAw3AYA+ejFF6WxYyPtyZOdgGSMdzUBBYaQBAD5ZOdOqX//SLtHD2nrVqm01LOSgELFcBsA5IPGRum881oGpNWrpT17CEhAlhCSAMDv5syROnWSli+PtK2Vysu9rQsocAy3AYBfrV4tnXZapD12rPTcc87ZawCyjpAEAH5TV+fsir1vX+Tazp3SkUd6VhLQETHcBgB+Ya00aZLUq1ckIC1f7lwnIAE5R0gCAD+YP985SmThQqd9661OOBozxtu6gA6M4TYA8NLGjdLxx0faI0ZIr78udeniXU0AJBGSAMAb+/c7R4ls2RK5tnmzNHiwdzUBaIHhNgDItalTpZKSSEBavNgZWiMgAb5CTxIA5MqSJdLFF0fa114rPfAAR4kAPkVIAoBs27pVOvroSPuII6T33pO6d/euJgBJMdwGANnS0CCdfnrLgFRdLX30EQEJyAOEJADIhpkzpc6dnZVqkjRvnjPv6OSTva0LQMoYbgOATFq5UjrzzEh74kRnYnYRv5MC+YaQBACZ8PHHUt++kbYx0q5dUp8+3tUEoF341QYA2qOpSZowoWVAWrnSuU5AAvIaIQkA2mrePCkQkJ5+2mnPnOnMO6qo8LYuABnBcBsApKu6Who5MtKuqJBWrJCCQc9KApB5KYckY0xA0hpJNdbai7JXEgD41N690pAhUm1t5Nq2bdKAAd7VBCBr0hlu+4GkDdkqBAB8y1ppyhSpZ89IQFq61LlOQAIKVkohyRgzQNKFkh7MbjkA4DOh5fvz5jntG290wtEFF3hbF4CsS3W47T5JP5LUI94DjDFTJE2RpIEDB7a7MADw1ObN0rHHRtpDhkjr1knFxd7VBCCnkvYkGWMukrTLWvtmosdZa+daa8utteV9o5fCAkA+OXBAOumklgFpwwbnrDUCEtChpDLcViFpvDHmA0l/kjTGGPNoVqsCAC/MmCF17SqtX++05893htaGDfO2LgCeSDrcZq29WdLNkmSMOVvSD621V2W3LADIoRdflMaOjbQnT3YCkjHe1QTAc+yTBKDj2rlT6t8/0u7RQ9q6VSot9awkAP6RVkiy1v5N0t+yUgkA5EpjozRunLR8eeTa6tVSebl3NQEFrLKqRrOXbdKOunr1Ly3WtHFDNWFUmddlJcWxJAA6ljlzpE6dIgFpzhxn3hEBCciKyqoa3fzkOtXU1ctKqqmr181PrlNlVY3XpSXFcBuAjmH1aum00yLtsWOl555zzl4DkDWzl21SfUNji2v1DY2avWyT73uTCElAAcvXLu6MqqtzdsXety9ybedO6cgjPSsJ6Eh21NWndd1PGG4DClQ+d3FnhLXSpElSr16RgLR8uXOdgATkTP9S9/3F4l33E0ISUKASdXEXvEcfdY4SWbjQac+Y4YSjMWO8rQvogKaNG6riYMth7eJgQNPGDfWootQx3AYUqHzu4m6zjRul44+PtE8+WXrjDalLF+9qAjq40BB/Pg79E5KAAtW/tFg1LoEoH7q407Z/v3OUyJYtkWubN0uDB3tXE4CwCaPK0gpFfplPyXAbUKDyuYs7LTfeKJWURALS4sXO0BoBCchLfppPSUgCCtSEUWWaeelwlZUWy0gqKy3WzEuH50UXd0qWLnWODbn3Xqd97bVSU5N02WXe1gWgXfw0n5LhNqCApdvFnRe2bZMGDoy0jzhCeu89qXt372oCkDF+mk9JTxKA/NDQII0e3TIgVVdLH31EQAIKiJ+2DCAkAfC/mTOlzp2lVauc9rx5zryjk0/2ti4AGeen+ZQMtwHwr5UrpTPPjLQnTnQmZhfx+x1QqPy0ZQAhCYD/fPyx1LdvpG2MtGuX1KePdzUByBm/zKfk1zEA/tHUJE2Y0DIgrVzpXCcgAcgxQhIAf5g3TwoEpKefdtp33eXMO6qo8LYuAB0Ww20AvFVdLY0cGWmPHi29/LIUDHpWEgBIhCQAXtm7VxoyRKqtjVzbulU66ijvagKAKAy3Acgta6UpU6SePSMBackS5zoBCYCPEJIA5M4TTzjL9+fNc9o33OCEowsv9LYuAHDBcBuA7Hv/fWdoLWTIEGndOqk49zvoAkCq6EkCkD0HDji7YkcHpA0bnLPWCEgAfI6QBCA7br1V6trV6TGSpPnznaG1YcO8rQsAUsRwG4DMWr5cOu+8SHvyZCcgGeNdTQDQBoQkAJnx0UdSv36Rdo8ezpL+0lLPSgKA9mC4DUD7NDY6PUfRAWn1amnPHgISgLxGSALQJpVVNbrv4uulTp2cITZJmjPHmXdUXu5tcQCQAQy3AUjb3x5dqglXXxRu/33QKF036Wf6+ZkjNcG7sgAgowhJAFJXVycNGKCz9+0LXzr1+vmq7d5LapRmL9ukCaPKvKsPADKIkAQgOWudVWoLF4YvTbryTv1j0MgWD9tRV5/jwgAgewhJABJ79FHp6qsj7RkzVFFyjmpcAlH/UjaIBFA4CElAFlRW1Wj2sk3aUVev/qXFmjZuaP4NQ23cKB1/fKQ9fLizaq1LF02rqtHNT65TfUNj+MvFwYCmjRvqQaEAkB2EJCDDKmMCRE1dvW5+0tl1Oi+C0v790kknSVu2RK5t3iwNHhxuhv4deR8EASCBpCHJGNNV0t8ldWl+/GJr7W3ZLgzIV7OXbWrRwyJJ9Q2N+TGp+cYbpXvvjbQXL5Yuu8z1oRNGlfn/3wMA7ZBKT9IBSWOstZ8ZY4KSVhpjnrPWrspybUBeijd52deTmpculS6KLOnXtddKDzzAUSIAOrSkIclaayV91twMNv9ns1kUkM/6lxa7TmouMkbHTF/qr6GpbdukgQMj7SOOkN591zlSBAA6uJR23DbGBIwxayXtkvRXa+3rLo+ZYoxZY4xZU1tbm+EygfwxbdxQFQcDra43WiuryBylyqqa3BcX0tAgnXFGy4BUXe2cv0ZAAgBJKYYka22jtXakpAGSTjPGnOTymLnW2nJrbXnfvn0zXCaQPyaMKtPMS4errLRYRlLAZcgqNEfJE7NmSZ07S6+95rTnzXP2QTr5ZG/qAQCfSmt1m7W2zhjzN0nnS/rfrFQEFIDoSc3HTF/q+picz1FauVI688xIe+JEZ2J2EUc4AoCbVFa39ZXU0ByQiiWdJ+nurFcGFIh4c5RytvHixx9L0b27xki7dkl9+uTm/QEgT6XyK2Q/SSuMMW9LWi1nTtKS7JYFFA63OUo52XixqUmaMKFlQFq50rlOQEKOVFbVqGLWSzpm+lJVzHrJ27l4QJpSWd32tqRROagFKEiebLw4b540ZUqkfddd0s03Z+/9YhTEjuNot7zfWBUdHjtuAzmQs40Xq6ulkSMj7dGjpZdfloLB7L93M26MCMnrjVUBpbi6DYDP7d0rHX54y4C0dav0j3/kNCBJiW+M6FjycmNVIAohCchn1jrDaj17SqH9yZYsca4fdZQnJXFjREi8xQk5W7QAtBMhCchXTzzhLN+fN89pT53qhKMLL/S0LG6MCPFs0QKQIcxJAvLN++9LQ4ZE2kOGSOvWScX+CCHTxg1tMSdJ4sbYUXmyaAHIIEISkC8OHJBOPdUJRCEbNkjDhnlXkwtujIiWs0ULQBYQkoB8cOut0p13Rtrz50tXXeVdPUlwYwRQCAhJgJ8tXy6dd16kPXmyE5BczoMDAGQWIQnwo48+kvr1i7S7d5e2bZNKSz0rCQA6Gla3AX7S2Oj0HEUHpNWrnX2QCEgAkFOEJMAv5syROnVyhthCbWul8nJv6wKADorhNsBrq1dLp50WaY8dKz33nBQIxH8OACDrCEk+xiGhBa6uThowQNq3L3Jt507pyCM9Kwn+x88FIHcYbvOp0CGhNXX1soocElpZVeN1aWgva51Var16RQLSiy861wlISICfC0BuEZJ8ikNCC9SjjzpHiTz2mNOeMcMJR+ee621dyAv8XAByi+E2n+KQ0NTkzdDDxo3S8cdHmn0H6bv/+YCmXjhcE7yrCnmGnwtAbtGT5FMcEpqc29DD1EVrNfKOF/wz/LB/vzR4cIuAdNaUeTr/33+jDz5rZKgEaeHnApBbhCSf4vTs5NyGHiSprr7BH+HjxhulkhJpyxZJ0i2Tb9OgHy/R1l6RPZAYKkE6+LkA5BYhyacmjCrTzEuHq6y0WEZSWWmxZl463J9DSVlQWVWjilkv6ZjpS1Ux6yXXwJNoiMHT8LF0qXNsyL33Ou1rr5WamvTYgFNdH85QCVLV0X8uALnGnCQf66iHhIaG0UK9RKEVPJJafB79S4tVkyBg5Dx8bNsmDRwYaR9xhPTuu1KPHpLi18tQCdLRUX8uAF6gJwm+k+oKHrehh2g5Cx8NDdIZZ7QMSNXVzvlrzQFJYqgEAPINIQm+k+oKntDQQ69uwVaPzVn4mDVL6txZeu01pz13rrOk/+STWz2UoRIAyC8Mt8F30hmWCg095HwrgJUrpTPPjCpkgvTEE84eSAkwVAIA+YOQBN+ZNm5oizlJUvKeoZyFj48/lvr2bXmttlbq0yfh0/JmPyf4Gt9HQG4RkuA7oR/6vroZNDVJl14qPf105NrKlVJFRdKnpjoRPR3cLDuebHwfAUjMWGsz/qLl5eV2zZo1GX9dFJ68uNnPmydNmRJp33WXdPPNKT+9YtZLrsOHZaXFenX6mLTLib1ZSk5PW+z8prz4bJGyTH8fAYgwxrxprS2PvU5PEjzj+9+M335bGjEi0h49Wnr5ZSnYeqJ4Ipk+SiLR6r/Q5+b22d6waK2mLlqrMgJTXuJIEiD3WN2GrIu3MaRvD+vcu9fZ4ygqIE388UIdc9YtqrjnlbR38s70URKp3CzdPttQnzEnx+cnjiQBco+QhKxyO18tdIP23W/G1jq7Y/fsKe3aJUl6bc7DOn7Gc6pSj1b1pyrT+yOlcrNM9hn6IowiLeyzBeQeIQlZlai3yFe/GYeW78+d67SnTpWs1Q/3D2h3b1em90dK5WaZymfIME1+YZ8tIPeYk4SMiDdJOFFv0b1Xjkx7qX/Gvf++NGRIpD1kiLRunVRcHK7TTboBI5NbFKSy+s9tG4VYDNPkH/bZAnKLkIR2SzQBO9HGkNE3+5q6egWMadVLk7XVWQcOSKee6gSikA0bpGHDWtWZyfPWMrXiLNnNMvazNYrMSZIYpgGAVLAFAMLaegNPtDQ53saQ0cMEbkvagwEjWamhycZ9Xpvdeqt0552R9vz50lVXuT401eX20Y+P9xmm+1qZFK8utgkAgHZsAWCMOUrSI5KOlNQkaa61dk7mS4SX2rMcP9GQVCpDQ27zlhoaW4f32GXuaVu+XDrvvEh78mQnIBkT9ynpbGyZ7DNMZel+trj1PPl+CwYXhDoAuZTKcNshSTdZa98yxvSQ9KYx5q/W2neyXBtyKNUbuNtNKtmQVLKhoXTm97RpsvFHH0n9+kXaJSXS9u1SaWlKT091Hki8z/D2Z9YnnZ/lhWyEtmyGmHwMdQDyW9LVbdbandbat5r/vlfSBkn8RCowqdzA4y3n79bZ/dvonGF9Xa/HSmd+z2HFQdc9l1w1Njo9R9EB6Y03pM8+SzkgpSPeZ1hX36DKqpq4/84iYzzZsyjToS3Rdg+Z4Nt9tQAUrLS2ADDGDJI0StLrLl+bYoxZY4xZU1tbm6HykKp4GzamKpXl+PFuUu/u2uf63BUbk38fVFbVaN+BQ62uBwNGwaLWw2B7Pm9I7Sb8q19JnTo5Q2yS7rvoP1T51nZnsnaWJAp7s5dtcl26L0mN1nqyuWOmt2DIdojxW08cgMKXckgyxnSX9ISkqdbaPbFft9bOtdaWW2vL+8aekg5X7Q020a/T3t/gU9l7J92bUbLHh+quq29ocb1Xt6BmXz5CV552lGJjUlPMVKVWN+E1a5w5Rj/4gSTplaNHavC0p3XfiRdkPYgkWi0Wmp8189LhCrjMgfKiRyTTmxNmO8T4al8tAB1CSiHJGBOUE5AWWGufzG5JHUMmhyZS+Q0+WSBLZaO6dG9GxkgzKtfFfV+3uiVpT/0h3bBorRa+vk2prL3cUVcv1dVJ3bu36Ck69fr5uvprd6qpyAkC2Q4iE0aVqVc393PdoudnNcVZUZrrHpFMb06Y7RDDjtMAci2V1W1G0u8lbbDW/jL7JXUMmZw0m+w3+FQnvCaboOy2nD92/51oTVZ6dNXWcDv2fePV3dgcIhpT2Z7CWv3PC/dJd18Uufbiizrmr5+71pXtIHLbxScm3SAz03svtUcmNyeMt91DpkJMOisNASATUlndViHpaknrjDFrm6/9xFr7l6xV1QFkcmgi2U03U4HM7SZ1zrC+LYJQMtHvG6/uVF2yfoXmLLkncmHGDOlnP5Mk9V/tvndTvCCSyU0epfR3wy6EHpFchBh2nAaQS0lDkrV2pdRqagjaKZO9CcluupkMZG43qaVv79Tu/Q1xnhH/fVM5OiNWMGB04qc7VHn/NZGLw4dLq1dLXbqEL6UTRDK9tDzRjTwUxuobGhUwRo3WhjfdLISbPyEGQCHhgFuPZHJ+RbK5JdmeK3LbxSe6rtqKJ3p+TnTdbhOaox1TUqS1j/xHy4D03nvS22+3CEhur51ovk2ulpZHz0OTnOHE0P/zjhQsMrVgAQCyjbPbPJLpoYlEv8HnYnina7AopR6h2PeNrruyqkY3LFrrOpdo5qt/1NdXLo5cWLxYuuyyhO+Vaq9GrpaWe7njtl+wISSAfEJI8lCuhiayOVfE7TyyeEqLg7p9/Ilx33fCqDJNXbS2xbVzNq/WQ4vviFy49lrpgQcSHiWSrlSGPjMxZ6nQ9vlpy2dCUASQTwhJBSLZDStbgSzeMn43Bw41JX1MWXNg6benVq898K3w9U+699IXdnwo9ejR5lrjSdbTlqnej3hhzMo5JDifht3a+pkUWlAEUNgISXnGLQxJSnrDSuW3/nR7BiqratJanRY9zyd2hdyKjbXaUVevPl2Mnnz0h/q3mo3h511yzW/1revGa0IWApKUvKctWe9Hqp9boonq+Tbs1NYeIT9tfwAAyRibyl40aSovL7dr1qzJ+Ot2ZJVVNbr9mfWtdqcuDgbUNVjkurqstDioki6dVFNX32o/o1C7LE7QCr127GTnUCBwe81UFQcDrkHhulWP68cvPxxu/2Tc9/Ty2RM972E5ZvpS13+nkXTvlSM1bXG1GhojjwgGjGZfPsK15ujPz01ZabFenT4mQ5VnhlsIjDd3zEjaMuvChK+VyvcZAOSSMeZNa215q+uEJP9LZ95PWwSLjEq6dGoVwEJCS9VLi4Pad/BQi0CQrtBrRSvfvl6LF/w43H7huNP1X9/8mVb+5Ly4r1NZVaM7nl0fDofJ5ju1R8Us9z2XykqLtf/gIdeA2qtbUFU//XLc10wUvBKFjFyLF2q6dCpy/X5JJeRlak8qAMiUeCGJ4bYMaesP/lSel868n7ZoaLJxA5IU2fk60WNSEduD1Gv/p6r69eQWjxn1/QXa3e0wmT0H4r5OZVVNq96buvoGTXu8WlLmh6vi7TSeaKgx2b5Rfhl2Svb9F29YrWuwqNX/z1RXTLKXEoB8wT5JGdDWc9hSfV6yeT+lxcG09inyQsCYyL5Ftklzn7yzRUC6fPLdGvTjJdrd7TBJ0mHF7megSc6N2603q6HJZuVstug9l6TER7Gkyg/nkKXy/RdvQnXd/oaMnvsGAH5ET1IGtHUSa7zn3fTnSI9IZVVNwptycTCg28efKEkthp/aIt5cofYyku65wpmjc/STCzTqF5GhtV+c9Q39dvQVrZ6z7+AhVVbVuH5+iVZC1dTVq2LWSxkfygn1fsQbeotVGhPy3HpsZl463NNhp1S+bxP1eNEjBKDQEZIyoK3LmhMd8Bpa6TR72aa4AalbsEh3XTpcUvsDUpGRBvTqqnd37Wvza8RzxpDemhD4RDIDNKr52lv9h+mKSbN0KOD+LdjQaOOuHivtFoz7b40eBou3Yqw9c2JSWaoeLDLh4Bp6v9jVh1MXrc3qPKpUpPJ9W6jnzAFAKghJGdDW+SWJDngN/Uaf6KZsZbTmw3/piTdr2t0D1GSVlYDU7WC9fnXjhdJnuyMXt27VZfe/nXTIakddvWvACBYZBYqMGptav0Lsldiekbbu7xMKVqkMs83+6oik83okZx6Vl8v+U/m+zcWhtQDgV8xJyoC2zi9xe1600E0pnvqGRj26amtWJ3W3mbX6+bLf6J17v6ovhALSkiWStdJRR6U0Qbl/abFrwGhosurRpZN6dYs/byladNBsyzltsWeuJVLWPAwV7/1jZeOMuFSl+n07YVSZXp0+RltmXahXp48hIAHoMAhJGZDOYapuz4t3sGvot3a/T8qOdf6mV/XBLy7W5LXPS5IePX2iKmYu1zGvKHygabJ/V+hmHS9gfFrfoKqffln3XTky6cG40YGsLUOjqa4ujBeMkwVCr3abbuv3LQB0FAy3ZUiiSazJ5sB0DRZp38HWN+FzhvXVhFFlWvPhv/Toqq1Zqz1Tjqr7SK/87jvh9gel/fSVb/9Ghzp3VUPMPKGZlw5vMXH5sOKgjHGWzgeMCfewxJt/1L+02Albj1e32ncpWmxwSXVoNPr/WaIhtrLS4nbttO323rnE5GsAiI+QlGWJ5sBIrXe5jrZiY22LP/0mtOqu86EGPf3IDTq+9oPw1879zgPaeeTR6tIpoPqY/ZVCASh26Cbe/KNgwLRY8h8KPrc/s14NLvOSosX2jKQyETnVzTtT3R079P5uk+uZBA0A/kVIyrJ4c2CmLlqrIuNMmI5nR1Tvix9ZSTf+fb7+87VF4WtTL7pJz540Ro3WqqykS9zaY5fqnzOsrxa+vq1Vr1BDkw0frxLbYzN10dqkNcb2kqQyETmV4bV0w02ox4bdpgEgfxCS2iD2HLVe3YK67WL3pdyJ5psk6QQJD8MkC1PpMMaZO91eZ3ywVo8tmhFuP3XC2brhoptkjFHoqJtE4S52qX6i4cRP6xu09rb4R3zEUxZnGCvZEFOi/2dGale4ac+wLAAgtwhJaQrNg4ke5tm9v0HTFleH26nu6ZPM/oOHNKNyXcYCktT+gNT3s91aff/V4fa+YFeN/o8/ak/X7s7rp/Aa6e5YXRpnFVuvBJ9te4axDisOuh7BUlocbFNYixYvCLV1a4JsIrQB6OgISQm43SRmL9vkOg+modHqjmfX6/OGphY3OqntPUG79zdogU8mbBc1NeqRP/9U/+/DSBgc/41f6u1+X0zrddwOuE3m0/0NrXbfrqyqiRv42rtJY7zFckkW0SWVKAi1ddf2bPFjaAOAXDM2E2MvMcrLy+2aNWsy/rq55DZ5NxNnduWjb655Rrcvnxtu33HuNXqo/JJWn0cqn09ouCrdeVYBY9RkbXj+ktsGmomGPdNxzPSlrv8OI2nLrAvb/LrxjjQJrZDLxnu2VaJaU5msDgD5xBjzprW2PPY6+yTF4fabfUcLSMN3vqsP7r4oHJBWHj1Cg6c9rYfKL1GwyGjy6QNb7LEz+fSBSfd0auveT43Whg9hXRBnA8099YfSes1ENaZzPVWJ9mjK1nu2VVuP2gGAQkJIiqMj3wx6fv6Z1v/ycj37yA3ha6de/4iu+trP1VTkhJuGJqsn3tyu/QcjwaT86N6a2XyWXDyheS0zLx3e4hDYks6BlIez4oXV0Jl30afYt0Vbd1BPJlEQytZ7tpXfQhsAeIGQFEeym0FxsAA/Omt177P/rbfnfE0lDZ9LkiZdeacG/XiJarv3bvXw+oYm7d7fEO7hCU1ej7eqrLQ42GIo7MChpvDf9x1sVKf2TvpRZo75iN6JWlKLzS3bE8ASBSG/7X7tt9AGAF5gTlIclVU1umHRWtdei9DN06/7F7XFJetXaM6Se8LtX4++UvecdXWCZ8RXWhzUvoOHWmwAGQwYlXTupE/rG9S/tFj7Dx5q86o/KfH8p0zN43Gbl1YcDLQrvOTTirF8qhUA2iPenCRCUgIzKtdpwaqtLW7GoZtkvACVbwZ/sl0vPfjdcHtD30G65Bv36mCn1A6PjSdYZNS9ayfV7W9Qt84B12NX2qo4GNBlp5Tpsde3xl01WJaBmzqTlwGgY4gXktgCwEX0b9ChM8Xq9je0+G169rJNed2T1KXhgJb94XsaVLczfO2sKfO0tVe/jLx+aJuEe68cqRtS2Bk7VdHL+5dU73Tdz0jKzJJ1Ji8DQMdGSIoRO8RSV9+g4mBA9145ssXN9pxhffPi0Fk3t7z0oK5ZXRluf3fCzXp+aEXG32f3/gbd8ez6jPa4GRMJPfECUkh79hmqrKpRUZw9nZi8DAAdAyEpRiqb+lVW1Wjh69u8KK9dztm8Wg8tviPcXjDyfN3y5evbv0tiAu2Zd5To9SqralLalynVXp/o3sPSbkF99vkh14DE5GUA6DgISTESHcgqRXqa0t012kv99tTqtQe+FW7XlpTq7Gvmal+Xbh5W1T6zl21KqYcqlV6f2N7DeMEuYEx4i4Pow3mZ0AwAhYmQFCPesRkBY1RZVaOb/lydNwGpU+MhLXpsuk7ZsTF87fxv/VobDz/Gw6raJ7S3Uio9RKn2+rj1Hrppav7/znEdANAxFOBmP+0TLwA1Wqupi9bmTUC6btXjeu+/J4QD0s3jvqdBP16S04BUHAyopHN6O2tLzhL+iiG9FSxqOQwYLDK6aEQ/Vcx6KW4vUsCYtPcZSnVIrn9pccLhWABAYaEnKUZZG84V85NTtr+jJxb8KNx+4bjTde3En8ia9uXh0uJg0onSIUYKrwpsy5wkK+mtrZ/qytOO0oqNteFhrXhntoVEbzuQjlTOkgsWmYR7O7HiDQAKT9KQZIz5g6SLJO2y1p6U/ZK8NW3c0FYbCOaDXvs/VdWvJ7e4Nur7C7S722EZef2SLp1SDklnDOmtt7Z+2q7PsL6hUSs21rbYj6hi1ktxXzO0gWUoxIR2AL/9mfXhDSxj5w6FJmvX1NW3mgQevfnlYTGv7YYVbwBQeFLpSfqjpN9IeiS7pfhD6CY6NYN7+2STsU363VN36cvvrgpfu3zy3Voz4MSMvk86vWuvbv5Xxt6zYtZL4XCTqAa3ENfQaMPXYucOxU7Wtors4h27EWXFrJcSBkRWvAFAYUoakqy1fzfGDMpBLb6RL5tFfm3t85q17Dfh9i/O+oZ+O/oKDyvKvOhwE29SfehxyURv5eA2tygUkGJ30040lJaJnb0BAP6UsTlJxpgpkqZI0sCBAzP1sp6ZNm6opi2ubnH+mF8M27VFzz/0/XD7rf5DdcWku3UoUJhTzOobGjO2qjAUeNLZTTvenCWOJwGAwpaxu6q1dq6kuZJzdlumXjdT0j2sc8KoMq358F++2lW728F6vTz3GvXdVxe+Nvq6h7SzZ1/vinJRMaS33vhgd0YDZqZWFYbmDsULPm5zi9zmqTHEBgCFr0NsARCaf1JTVy+ryBBOZVVNwuet2FibmwKTsVY/X/YbvXPvV8MB6VuX36ZBP17iu4B01ekDteCa0Srp7L9erehgM23cUBUHA3G/Hm3CqDLNvHS4ykqL095eAACQv/x3J8uCVI4aceOHZd3jNv1Dv6u8K9z+ffkl+tm513hYUXxG0p0TnB2pP01xJVyuxM4dCv2Zau/ihFFlhCIA6GBS2QJgoaSzJfUxxmyXdJu19vfZLiyTUpl/UllVo9ufWR9exdSrW1DdOge076A3WwEcVfeRXvndd8LtD0uP1Lh//40+D3b1pJ5URA9VpbL3UHt0CxZpf0NTSo+NN3eI4AMASCSV1W1fz0Uh2ZRs/kllVY2mPV6thqbIvJdMH8yaqs6HGvT0Izfo+NoPwtfO/c4D2vyFo3JeizFSqlOBYoeqku03Fb3xY7qzjYqDAd116XA9vmZr0u0GmDsEAGirDjEnKdn8k9nLNrUISF654ZVH9c97JoYD0g0X3qhBP17iSUCSUg9IRmo1Ryc0j6dXt2CrxweM0ZWnHaWqn35ZW2ZdmHZdoff64BP3nqq2HE0CAECsDjEnKXb+SWm3oKyVbli01hf7IY3+sFoL/3RLuP3UCWfrhotucrpy8sBhxcG4QeRzlyGxRmv1xJs1Kj+6tyaMKkvryJOy0uLwe8UbRm2ytk3hCwCAaB0iJEmR+SczKtdpwaqt4SEeLwNS3892a/X9V4fb+4JdNfo//qg9Xbt7VlNbxJuk7TZhPiR64vxFI/q5brUQKDJqjOrhix06S2cZPwAA6eowIUly5h5FBySvFDU16uE/36YzP1wbvjb+G7/U2/2+6F1R7RAvlCRbHRj6erytFnp06aSSLp3irj5j/yIAQDZ1qJA0e9kmzwPSN9c8o9uXzw237zj3Gj1UfomHFbVPMGBahJLoTTuLEhwjIkXCVbww9Wl9g9be9uW4z093GT8AAOnoUCHJy6G14Tvf1bOP3BBurzx6hL5xxX+pqSiQ4Fn+19BoNbV5btc5w/rqiTdrwj07iQJSdI9Pe4bNWMYPAMiWgg9JlVU1uuPZ9Z4t6e/5+Wd67bffVEnD5+Frp17/iGq79/aknmypqauPe4RL6GDa0J+xGzsybAYA8KOCDkmVVTXeHVJrre5dco8mvvO38KVJV96pfwwamftaPNZkrT6IWW1WWVWjilkvhYfJLjulTCs21jJsBgDwjYIOSbOXbfIkIF2yfoXmLLkn3P716Ct1z1lXJ3hGYYsdNgudpRfqOaqpq9cTb9awpxEAwFcKOiTleg7S4E+266UHvxtub+g7SJd8414d7NR6Q8V8E0gyCTue2IndUtvP0gMAIJfyOiRFr6SKHaKprKqRkXKymq1LwwEt+8P3NKhuZ/jaWVPmaWuvfjl499xotFbFwUDcfY/iKencqVXwSeUsPQAAvJa3x5KEhmxq6upl5fQa3fzkOlVW1UiSbn9mfU4C0i0vPahNv7wsHJCuu2S6Bv14SV4GJCOppLP7arvQER9laW7U6LbRZLxVa2wCCQDwk7wNSYmGbCqralI+5qKtzt68Wh/cfZGuWV0pSXpsxPka9KNn9dyw/5fV980mK+nnE4fHPeduwqgyvTp9jNI5LMUt+CQ7Sw8AAD/I2+G2REM2s5dtytr79ttTq9ce+Fa4XdutVGdPmat9Xbpl7T1zJfpctEQbNMbb1yh2eDNe8GETSABAPsjbkBTvRt2pKDsTtjs1HtKix6brlB0bw9e+8q1facPhgzP+Xu3VlknW0YEm2QaN8fY1SmcZP5tAAgD8Lm9DktuNWpJcDp1vt++uWqzpL/8x3L553Pe0cOT5mX+jDNk88wJnj6jHq9XQ1DoslRYHddGIfm3el4ieIABAR2BsG5Z1J1NeXm7XrFmT8deNFVrdVlNXn5WVbKdsf0dPLPhRuP3Ccafr2ok/kTX+nsoV2tFaciawh+Zn9eoW1G0Xn0iYAQAgijHmTWtteavr+RySQkbe8UJGJ2r32v+pqn49ucW1Ud9foN3dDsvYe2RbMGA0+/IRBCIAAJKIF5LydrhNcnqSontK2svYJv3PU3dp3Lurwtcun3y31gw4MSOvn0sNjVZ3PLuekAQAQBvlbUiKPdqiva6sXqa7n/91uP2Ls76h346+IiOvnS3dgkU6cMjGnaTt1aG+AAAUgrwNSW77JLVFxQdrtWDRjHD7rf5DdcWku3Uo4O+PpjgY0F3NZ50Nmr7U63IAACg4/k4CCbT3CIvD6veq+ldfb3Ft9HUPaWfPvu163VwoLQ7q9vGRCdilxUHXIcfS4vw/Mw4AAK/kZUiqrKpp+0o2a/Xab7+pfp99Er70s3O+rd+fNjEjtWVKSeeA9h1s2VMWb3Xa7eNPbLXcP1hkdPv4/JtLBQCAX+RdSJpRuU6Prtrapude/49FmvbK/HD7vd4DdN41/5Op0jLCSJp8+kDdOWF4ys9h3yIAADIvr0JSZVWNFrQhIJ340Xta+vDUFteGT12kvV1KMlRZeoyRrI3sjB36s6wd4YYdrAEAyKy8Ckmzl21Ka5ita8Pn2vjLy1tc++qkWVp91EmZLSxKWWmxdu2pd935u6y0WK9OH5O19wYAAJmTVyEpnTPZ/rzgRzpt+zvh9u9Ou1Qzz/n3bJQlSboqaojsmDirzdo72RwAAOROXoWk0DBVIldUv6BfPP+rcPtAIKihNz3pPDlLroqZQxTv8N3+pcVZqwEAAGRWXoWkRAHp6N079PLcKS2unXr9I6rt3jujNUSfERe7FD/E7fDd4mAgfJ4aAADwv7wKSW4CTY3aPPuSFtemTLxFL3xxdMbeI14YiofVZgAA5L+8CkmxmyZ+c80zun353HD7mePP0n+O/1HG3q84GNDM5l2tQyqralIKP6w2AwAgv+VVSLp9/ImaumitTvi/9/WXP/5n+HpDUUDH3/hERo8ScVuOH3teXE1dvW5+cp0kEYgAACgwRV4XkI4Jo8pU0jmgu5+bE7526vWP6LhpT2c8IL06fUyr4ON2Xlx9Q6NmL9uUsfcGAAD+kFKyMMacL2mOpICkB621s7JaVQL7DzbqO5fdqu4H67X5C0dl/PUTTbCOt4Q/9nqqQ3IAAMC/kvYkGWMCku6X9BVJJ0j6ujHmhGwXFk//0mL9X48+bQpIFUN6qyzBMvyAMa3mIMW+d7LroSG5mrp6WUWG5CqratKuFwAAeCeV4bbTJL1nrX3fWntQ0p8kXZLkOVkzbdxQBQPp73lUMaS3FlwzWq9OH6P7rhyp4mCgxdeLgwHdc8WIhD0+08YNdX1edM8TQ3IAABSGVIbbyiRti2pvl/Sl2AcZY6ZImiJJAwcOzEhxbkIh5pan1mnfwca4jwsYoyZrXYe72rpEP5XnpTokBwAA/C2VkOTWbdNqW0dr7VxJcyWpvLw8nSPW0hZaXl9ZVaPbn1nfYlsAyX3pfrzXaOt7x8Nu2wAAFIZUhtu2S4qeADRA0o7slJOeCaPKtPa2L+u+K0eqrLRYRs7KtGQBKZtSGZIDAAD+l0pP0mpJxxljjpFUI+lrkiZltao0+WnjRnbbBgCgMCQNSdbaQ8aY70laJmcLgD9Ya9dnvbI85qfQBgAA2ialfZKstX+R9Jcs1wIAAOAbebXjNgAAQK4QkgAAAFwQkgAAAFwQkgAAAFwQkgAAAFwQkgAAAFwQkgAAAFwQkgAAAFwQkgAAAFwYa23mX9SYWkkfZujl+kj6OEOvVaj4jBLj80mOzyg5PqPE+HyS4zNKzqvP6Ghrbd/Yi1kJSZlkjFljrS33ug4/4zNKjM8nOT6j5PiMEuPzSY7PKDm/fUYMtwEAALggJAEAALjIh5A01+sC8gCfUWJ8PsnxGSXHZ5QYn09yfEbJ+eoz8v2cJAAAAC/kQ08SAABAzvk2JBljzjfGbDLGvGeMme51PX5kjPmDMWaXMeZ/va7Fj4wxRxljVhhjNhhj1htjfuB1TX5jjOlqjHnDGFPd/Bnd4XVNfmSMCRhjqowxS7yuxY+MMR8YY9YZY9YaY9Z4XY8fGWNKjTGLjTEbm38mjfa6Jr8wxgxt/t4J/bfHGDPV67oknw63GWMCkv4paayk7ZJWS/q6tfYdTwvzGWPMWZI+k/SItfYkr+vxG2NMP0n9rLVvGWN6SHpT0gS+jyKMMUZSibX2M2NMUNJKST+w1q7yuDRfMcbcKKlcUk9r7UVe1+M3xpgPJJVba9kDKA5jzMOSXrHWPmiM6Sypm7W2zuOyfKf5/l8j6UvW2kztt9hmfu1JOk3Se9ba9621ByX9SdIlHtfkO9bav0v6l9d1+JW1dqe19q3mv++VtEFSmbdV+Yt1fNbcDDb/57/fnDxkjBkg6UJJD3pdC/KTMaanpLMk/V6SrLUHCUhxnStpsx8CkuTfkFQmaVtUe7u4uaEdjDGDJI2S9LrHpfhO81DSWkm7JP3VWstn1NJ9kn4kqcnjOvzMSnrBGPOmMWaK18X40GBJtZIeah62fdAYU+J1UT71NUkLvS4ixK8hybhc47dbtIkxprukJyRNtdbu8boev7HWNlprR0oaIOk0YwxDt82MMRdJ2mWtfdPrWnyuwlr7b5K+Iun65qkAiOgk6d8kPWCtHSVpnyTm2sZoHoYcL+lxr2sJ8WtI2i7pqKj2AEk7PKoFeax5ns0TkhZYa5/0uh4/a+7+/5uk872txFcqJI1vnnPzJ0ljjDGPeluS/1hrdzT/uUvSU3KmTCBiu6TtUb20i+WEJrT0FUlvWWv/z+tCQvwaklZLOs4Yc0xzsvyapGc8rgl5pnlS8u8lbbDW/tLrevzIGNPXGFPa/PdiSedJ2uhpUT5irb3ZWjvAWjtIzs+hl6y1V3lclq8YY0qaF0aoeQjpy5JYcRvFWvuRpG3GmKHNl86VxAKS1r4uHw21SU4XoO9Yaw8ZY74naZmkgKQ/WGvXe1yW7xhjFko6W1IfY8x2SbdZa3/vbVW+UiHpaknrmufcSNJPrLV/8a4k3+kn6eHmFSVFkv5srWWZO9JxhKSnnN9J1EnSY9ba570tyZe+L2lB8y/+70v6lsf1+IoxppucFe3Xel1LNF9uAQAAAOA1vw63AQAAeIqQBAAA4IKQBAAA4IKQBAAA4IKQBAAA8lK6B70bY64wxrzTfKD3Y0kfz+o2AACQj9I56N0Yc5ykP0saY63dbYw5vHkD1LjoSQIAAHnJ7aB3Y8wQY8zzzWcJvmKMGdb8pWsk3W+t3d383IQBSSIkAQCAwjJX0vettadI+qGk3zZf/6KkLxpjXjXGrDLGJD2CyZc7bgMAAKSr+UDzMyQ93rwLvCR1af6zk6Tj5JxUMUDSK8aYk5rPrXRFSAIAAIWiSFKdtXaky9e2S1plrW2QtMUYs0lOaFqd6MUAAADynrV2j5wA9FXJOejcGDOi+cuVks5pvt5HzvDb+4lej5AEAADyUvNB769JGmqM2W6M+bakyZK+bYyplrRe0iXND18m6RNjzDuSVkiaZq39JOHrswUAAABAa/QkAQAAuCAkAQAAuCAkAQAAuCAkAQAAuCAkAQAAuCAkAQAAuCAkAQAAuCAkAQAAuPj/erhCnCiWssIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 430311899136.0000 - val_loss: 427755438080.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429480542208.0000 - val_loss: 425884155904.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 425842671616.0000 - val_loss: 420030447616.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417258078208.0000 - val_loss: 408319295488.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402239520768.0000 - val_loss: 389626167296.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379972091904.0000 - val_loss: 363747311616.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 350630510592.0000 - val_loss: 330922917888.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315392589824.0000 - val_loss: 293367119872.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276630077440.0000 - val_loss: 253618536448.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237172113408.0000 - val_loss: 214778855424.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 200230240256.0000 - val_loss: 179919306752.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 168451424256.0000 - val_loss: 151533076480.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 143607267328.0000 - val_loss: 130413355008.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 126363287552.0000 - val_loss: 116745011200.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 115713769472.0000 - val_loss: 108789399552.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 109917134848.0000 - val_loss: 104709496832.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 107046330368.0000 - val_loss: 102796312576.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 105675038720.0000 - val_loss: 101810733056.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104913846272.0000 - val_loss: 101218336768.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104391786496.0000 - val_loss: 100748959744.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103923941376.0000 - val_loss: 100297809920.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103467933696.0000 - val_loss: 99839893504.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103012417536.0000 - val_loss: 99381010432.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102537404416.0000 - val_loss: 98881757184.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102046375936.0000 - val_loss: 98381955072.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101551628288.0000 - val_loss: 97869807616.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101020270592.0000 - val_loss: 97344495616.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 100488265728.0000 - val_loss: 96804888576.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99937107968.0000 - val_loss: 96234422272.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99366412288.0000 - val_loss: 95660310528.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98773409792.0000 - val_loss: 95064064000.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98179751936.0000 - val_loss: 94454956032.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 97559805952.0000 - val_loss: 93840449536.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96924532736.0000 - val_loss: 93182738432.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96278552576.0000 - val_loss: 92522921984.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 95612067840.0000 - val_loss: 91858501632.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94948352000.0000 - val_loss: 91171946496.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94244093952.0000 - val_loss: 90473488384.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93548912640.0000 - val_loss: 89755639808.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92811542528.0000 - val_loss: 89028493312.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92079587328.0000 - val_loss: 88279334912.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91331436544.0000 - val_loss: 87525007360.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90558423040.0000 - val_loss: 86745063424.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89785057280.0000 - val_loss: 85960589312.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89002205184.0000 - val_loss: 85166563328.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88196956160.0000 - val_loss: 84367458304.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 87413702656.0000 - val_loss: 83543760896.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 86556327936.0000 - val_loss: 82710151168.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 85711413248.0000 - val_loss: 81860837376.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 84863967232.0000 - val_loss: 80983703552.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 83987275776.0000 - val_loss: 80115286016.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 83115884544.0000 - val_loss: 79249940480.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 82225586176.0000 - val_loss: 78327627776.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 81328128000.0000 - val_loss: 77426614272.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 80391438336.0000 - val_loss: 76513001472.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 79476449280.0000 - val_loss: 75577966592.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 78538145792.0000 - val_loss: 74630152192.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 77589405696.0000 - val_loss: 73678299136.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 76628172800.0000 - val_loss: 72715952128.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 75675320320.0000 - val_loss: 71746748416.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 74703110144.0000 - val_loss: 70779666432.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 73733816320.0000 - val_loss: 69818572800.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 72767225856.0000 - val_loss: 68863713280.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 71803723776.0000 - val_loss: 67866750976.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 70819004416.0000 - val_loss: 66899283968.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 69854437376.0000 - val_loss: 65938956288.0000\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 68889755648.0000 - val_loss: 64992866304.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67941163008.0000 - val_loss: 64053780480.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67006062592.0000 - val_loss: 63137726464.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 66107879424.0000 - val_loss: 62250262528.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 65227014144.0000 - val_loss: 61378990080.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 64370155520.0000 - val_loss: 60551823360.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 63532072960.0000 - val_loss: 59730034688.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 62724300800.0000 - val_loss: 58961940480.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 61969825792.0000 - val_loss: 58217447424.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 61210595328.0000 - val_loss: 57487179776.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 60518895616.0000 - val_loss: 56814436352.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 59836456960.0000 - val_loss: 56181477376.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 59199004672.0000 - val_loss: 55536259072.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58589442048.0000 - val_loss: 54974582784.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58006122496.0000 - val_loss: 54418300928.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57479438336.0000 - val_loss: 53900439552.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56969719808.0000 - val_loss: 53435531264.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56499916800.0000 - val_loss: 52977598464.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56065900544.0000 - val_loss: 52575158272.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55644442624.0000 - val_loss: 52198207488.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55281614848.0000 - val_loss: 51853500416.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54898098176.0000 - val_loss: 51501998080.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54572109824.0000 - val_loss: 51188035584.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54269288448.0000 - val_loss: 50912002048.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54011359232.0000 - val_loss: 50661691392.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53748477952.0000 - val_loss: 50420097024.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53485535232.0000 - val_loss: 50199535616.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53265453056.0000 - val_loss: 49998004224.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53059002368.0000 - val_loss: 49816776704.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52861771776.0000 - val_loss: 49640755200.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52672307200.0000 - val_loss: 49476071424.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52489486336.0000 - val_loss: 49302032384.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52343627776.0000 - val_loss: 49155592192.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52181311488.0000 - val_loss: 49050914816.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52028121088.0000 - val_loss: 48884649984.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51916386304.0000 - val_loss: 48776929280.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51762089984.0000 - val_loss: 48690675712.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 51665448960.0000 - val_loss: 48558948352.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51529072640.0000 - val_loss: 48465383424.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51407155200.0000 - val_loss: 48334184448.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51312336896.0000 - val_loss: 48244850688.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51185967104.0000 - val_loss: 48157798400.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51078696960.0000 - val_loss: 48054382592.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50974883840.0000 - val_loss: 47958593536.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50872504320.0000 - val_loss: 47857401856.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50774831104.0000 - val_loss: 47775477760.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50660397056.0000 - val_loss: 47685722112.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50556686336.0000 - val_loss: 47604760576.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50456039424.0000 - val_loss: 47530291200.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50343800832.0000 - val_loss: 47411830784.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50242121728.0000 - val_loss: 47313854464.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50144485376.0000 - val_loss: 47214473216.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50026868736.0000 - val_loss: 47115571200.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49919078400.0000 - val_loss: 47012884480.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49813221376.0000 - val_loss: 46924656640.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49697353728.0000 - val_loss: 46809411584.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49578438656.0000 - val_loss: 46748737536.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49477300224.0000 - val_loss: 46610952192.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49363443712.0000 - val_loss: 46526210048.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49254354944.0000 - val_loss: 46421286912.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49130094592.0000 - val_loss: 46309154816.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49023840256.0000 - val_loss: 46235815936.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48921149440.0000 - val_loss: 46121615360.0000\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48798486528.0000 - val_loss: 46011588608.0000\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48691228672.0000 - val_loss: 45933117440.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48582983680.0000 - val_loss: 45843894272.0000\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48468852736.0000 - val_loss: 45718351872.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48355205120.0000 - val_loss: 45622812672.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48252604416.0000 - val_loss: 45508743168.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48139943936.0000 - val_loss: 45435297792.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48004980736.0000 - val_loss: 45402927104.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47894962176.0000 - val_loss: 45185662976.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47761211392.0000 - val_loss: 45080264704.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47641546752.0000 - val_loss: 44983136256.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47508594688.0000 - val_loss: 44853579776.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47373774848.0000 - val_loss: 44724203520.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47265673216.0000 - val_loss: 44603604992.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47114326016.0000 - val_loss: 44506554368.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46992617472.0000 - val_loss: 44384370688.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46866608128.0000 - val_loss: 44262936576.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46737596416.0000 - val_loss: 44189634560.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46616072192.0000 - val_loss: 44042379264.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46497484800.0000 - val_loss: 43949039616.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46376071168.0000 - val_loss: 43829456896.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46258061312.0000 - val_loss: 43735306240.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46135406592.0000 - val_loss: 43621117952.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46028193792.0000 - val_loss: 43520954368.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45907619840.0000 - val_loss: 43406462976.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45782315008.0000 - val_loss: 43306307584.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45679284224.0000 - val_loss: 43224924160.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45539631104.0000 - val_loss: 43107991552.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45428043776.0000 - val_loss: 42988376064.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45320916992.0000 - val_loss: 42882990080.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45187166208.0000 - val_loss: 42789773312.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45059530752.0000 - val_loss: 42674167808.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44941914112.0000 - val_loss: 42566225920.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44833902592.0000 - val_loss: 42470481920.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44716748800.0000 - val_loss: 42357977088.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44602572800.0000 - val_loss: 42282287104.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44476444672.0000 - val_loss: 42149531648.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44359057408.0000 - val_loss: 42045562880.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44254212096.0000 - val_loss: 41950896128.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44129705984.0000 - val_loss: 41888579584.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44033945600.0000 - val_loss: 41804382208.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 43912364032.0000 - val_loss: 41649831936.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43829178368.0000 - val_loss: 41564635136.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43702738944.0000 - val_loss: 41474908160.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43598729216.0000 - val_loss: 41374281728.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43496067072.0000 - val_loss: 41299140608.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43392937984.0000 - val_loss: 41220980736.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43295932416.0000 - val_loss: 41116405760.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43183288320.0000 - val_loss: 41017786368.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43082604544.0000 - val_loss: 40935600128.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 42995609600.0000 - val_loss: 40860057600.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 42877489152.0000 - val_loss: 40781844480.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 42785337344.0000 - val_loss: 40703426560.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42678448128.0000 - val_loss: 40606302208.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42570735616.0000 - val_loss: 40541229056.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42484047872.0000 - val_loss: 40415145984.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42385440768.0000 - val_loss: 40396554240.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42277675008.0000 - val_loss: 40251518976.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42191732736.0000 - val_loss: 40156807168.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42095767552.0000 - val_loss: 40090750976.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42006405120.0000 - val_loss: 39992139776.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41924567040.0000 - val_loss: 39995617280.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41819881472.0000 - val_loss: 39864041472.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41748135936.0000 - val_loss: 39811149824.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41653891072.0000 - val_loss: 39759036416.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41574879232.0000 - val_loss: 39651057664.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41498664960.0000 - val_loss: 39614672896.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41422168064.0000 - val_loss: 39576305664.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41346318336.0000 - val_loss: 39487676416.0000\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41279873024.0000 - val_loss: 39420383232.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41202577408.0000 - val_loss: 39350751232.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41134219264.0000 - val_loss: 39302164480.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41102016512.0000 - val_loss: 39274758144.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40997609472.0000 - val_loss: 39174504448.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40936669184.0000 - val_loss: 39143460864.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40865161216.0000 - val_loss: 39076044800.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40799772672.0000 - val_loss: 39047307264.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40746430464.0000 - val_loss: 38991585280.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40706076672.0000 - val_loss: 38923173888.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40641495040.0000 - val_loss: 38902124544.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40563351552.0000 - val_loss: 38838460416.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40509190144.0000 - val_loss: 38800728064.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40450772992.0000 - val_loss: 38750289920.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40385769472.0000 - val_loss: 38681894912.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40341405696.0000 - val_loss: 38631034880.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40286162944.0000 - val_loss: 38594727936.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 40225046528.0000 - val_loss: 38566248448.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40166367232.0000 - val_loss: 38509686784.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40122466304.0000 - val_loss: 38466686976.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40062750720.0000 - val_loss: 38433120256.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40009580544.0000 - val_loss: 38431494144.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39958937600.0000 - val_loss: 38367301632.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39902105600.0000 - val_loss: 38316785664.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39849869312.0000 - val_loss: 38275682304.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39812190208.0000 - val_loss: 38237138944.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39760982016.0000 - val_loss: 38201888768.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39710986240.0000 - val_loss: 38182936576.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39683104768.0000 - val_loss: 38137950208.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39620464640.0000 - val_loss: 38092169216.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39579705344.0000 - val_loss: 38068686848.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39521112064.0000 - val_loss: 38022594560.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39500120064.0000 - val_loss: 37997314048.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39448842240.0000 - val_loss: 37962379264.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39397740544.0000 - val_loss: 37915762688.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39353774080.0000 - val_loss: 37912748032.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39314272256.0000 - val_loss: 37887602688.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39270875136.0000 - val_loss: 37826547712.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39228551168.0000 - val_loss: 37809094656.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39197868032.0000 - val_loss: 37817860096.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39150571520.0000 - val_loss: 37774696448.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39107637248.0000 - val_loss: 37711486976.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39093719040.0000 - val_loss: 37692964864.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39043383296.0000 - val_loss: 37692878848.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38995218432.0000 - val_loss: 37637935104.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38956937216.0000 - val_loss: 37632856064.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38919315456.0000 - val_loss: 37604941824.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38890213376.0000 - val_loss: 37559984128.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38859186176.0000 - val_loss: 37510938624.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38811475968.0000 - val_loss: 37532565504.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38783823872.0000 - val_loss: 37562757120.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38753140736.0000 - val_loss: 37512306688.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38709936128.0000 - val_loss: 37455810560.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38677975040.0000 - val_loss: 37400764416.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38629318656.0000 - val_loss: 37458411520.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38605185024.0000 - val_loss: 37393182720.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38585634816.0000 - val_loss: 37341392896.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38534156288.0000 - val_loss: 37314154496.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38512279552.0000 - val_loss: 37305237504.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38484357120.0000 - val_loss: 37272969216.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38437191680.0000 - val_loss: 37245333504.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38398087168.0000 - val_loss: 37301448704.0000\n",
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38406467584.0000 - val_loss: 37214007296.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38342844416.0000 - val_loss: 37200908288.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38311079936.0000 - val_loss: 37168975872.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38289666048.0000 - val_loss: 37174767616.0000\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38252384256.0000 - val_loss: 37116174336.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38242754560.0000 - val_loss: 37201158144.0000\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 38233792512.0000 - val_loss: 37099245568.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38166712320.0000 - val_loss: 37063385088.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38152638464.0000 - val_loss: 37036331008.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38114234368.0000 - val_loss: 37037301760.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38096986112.0000 - val_loss: 37017325568.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38080155648.0000 - val_loss: 36999454720.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38052585472.0000 - val_loss: 36955652096.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38029627392.0000 - val_loss: 36984520704.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37997531136.0000 - val_loss: 36980146176.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37956419584.0000 - val_loss: 36901789696.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37941809152.0000 - val_loss: 36895510528.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37922156544.0000 - val_loss: 36873752576.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37900017664.0000 - val_loss: 36835385344.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37875118080.0000 - val_loss: 36837773312.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37847691264.0000 - val_loss: 36847239168.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37821878272.0000 - val_loss: 36793262080.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37798223872.0000 - val_loss: 36794392576.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37770207232.0000 - val_loss: 36762447872.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37763239936.0000 - val_loss: 36779094016.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37727395840.0000 - val_loss: 36774506496.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37704441856.0000 - val_loss: 36759662592.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37684224000.0000 - val_loss: 36765155328.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37670998016.0000 - val_loss: 36678299648.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37637484544.0000 - val_loss: 36651995136.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37618266112.0000 - val_loss: 36649279488.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37588631552.0000 - val_loss: 36663980032.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37584850944.0000 - val_loss: 36628602880.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37557465088.0000 - val_loss: 36647256064.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37535154176.0000 - val_loss: 36592480256.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37511327744.0000 - val_loss: 36568584192.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37504724992.0000 - val_loss: 36576468992.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37467643904.0000 - val_loss: 36538908672.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37453172736.0000 - val_loss: 36568850432.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37427077120.0000 - val_loss: 36516028416.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37406023680.0000 - val_loss: 36513107968.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37395640320.0000 - val_loss: 36499144704.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37375852544.0000 - val_loss: 36485390336.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37351071744.0000 - val_loss: 36451430400.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37325152256.0000 - val_loss: 36455833600.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37315981312.0000 - val_loss: 36410855424.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37292707840.0000 - val_loss: 36390428672.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37285470208.0000 - val_loss: 36396113920.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37253865472.0000 - val_loss: 36420509696.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37245227008.0000 - val_loss: 36397203456.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37210578944.0000 - val_loss: 36338286592.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37197721600.0000 - val_loss: 36344004608.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37181526016.0000 - val_loss: 36327448576.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37158268928.0000 - val_loss: 36314132480.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37145759744.0000 - val_loss: 36285739008.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37123092480.0000 - val_loss: 36271878144.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37118005248.0000 - val_loss: 36252889088.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37110124544.0000 - val_loss: 36232028160.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37074796544.0000 - val_loss: 36225335296.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37052166144.0000 - val_loss: 36252102656.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37035188224.0000 - val_loss: 36248195072.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37011664896.0000 - val_loss: 36230864896.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37017026560.0000 - val_loss: 36183662592.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36981665792.0000 - val_loss: 36196360192.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36960186368.0000 - val_loss: 36176642048.0000\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36958851072.0000 - val_loss: 36130684928.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36940320768.0000 - val_loss: 36135694336.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36908867584.0000 - val_loss: 36110970880.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36899168256.0000 - val_loss: 36196802560.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36885458944.0000 - val_loss: 36096675840.0000\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36882710528.0000 - val_loss: 36070612992.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36850151424.0000 - val_loss: 36065992704.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36836696064.0000 - val_loss: 36042293248.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36827385856.0000 - val_loss: 36054298624.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36804378624.0000 - val_loss: 36013166592.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36804710400.0000 - val_loss: 35993628672.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36791267328.0000 - val_loss: 35993452544.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36765691904.0000 - val_loss: 36017029120.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36776165376.0000 - val_loss: 35981598720.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36737327104.0000 - val_loss: 36005265408.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36721012736.0000 - val_loss: 35998515200.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36703035392.0000 - val_loss: 35938697216.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36692561920.0000 - val_loss: 35941625856.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36675092480.0000 - val_loss: 35938406400.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36663177216.0000 - val_loss: 35939323904.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36645961728.0000 - val_loss: 35922567168.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36636827648.0000 - val_loss: 35885830144.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36607004672.0000 - val_loss: 35934769152.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36623872000.0000 - val_loss: 35957252096.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36601286656.0000 - val_loss: 35871961088.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36575797248.0000 - val_loss: 35853545472.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36566626304.0000 - val_loss: 35864301568.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 35350368256.000 - 0s 1ms/step - loss: 36552847360.0000 - val_loss: 35878707200.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36545478656.0000 - val_loss: 35844108288.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36516519936.0000 - val_loss: 35842551808.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36511588352.0000 - val_loss: 35791253504.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36497362944.0000 - val_loss: 35755495424.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36497494016.0000 - val_loss: 35743903744.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36480925696.0000 - val_loss: 35748634624.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36460335104.0000 - val_loss: 35724484608.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36449034240.0000 - val_loss: 35748261888.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36423770112.0000 - val_loss: 35722907648.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36445581312.0000 - val_loss: 35721682944.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36404584448.0000 - val_loss: 35706871808.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 37305171968.000 - 0s 1ms/step - loss: 36404260864.0000 - val_loss: 35681894400.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36389109760.0000 - val_loss: 35681005568.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36375470080.0000 - val_loss: 35637542912.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36357197824.0000 - val_loss: 35684814848.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36342321152.0000 - val_loss: 35630755840.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36344438784.0000 - val_loss: 35646394368.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36329553920.0000 - val_loss: 35624951808.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36301930496.0000 - val_loss: 35601956864.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36281937920.0000 - val_loss: 35685228544.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36290416640.0000 - val_loss: 35629211648.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36272709632.0000 - val_loss: 35587751936.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36280836096.0000 - val_loss: 35560402944.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36244221952.0000 - val_loss: 35571564544.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36235247616.0000 - val_loss: 35554418688.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36224225280.0000 - val_loss: 35523170304.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36218015744.0000 - val_loss: 35487797248.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36197900288.0000 - val_loss: 35519500288.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36179525632.0000 - val_loss: 35535110144.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36177047552.0000 - val_loss: 35484958720.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36161433600.0000 - val_loss: 35502968832.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36154707968.0000 - val_loss: 35451826176.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36135952384.0000 - val_loss: 35471347712.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36129935360.0000 - val_loss: 35418759168.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36135190528.0000 - val_loss: 35436871680.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36096913408.0000 - val_loss: 35429543936.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36083400704.0000 - val_loss: 35369353216.0000\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36106760192.0000 - val_loss: 35370881024.0000\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36076564480.0000 - val_loss: 35375624192.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36049842176.0000 - val_loss: 35384348672.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36040867840.0000 - val_loss: 35364356096.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36038520832.0000 - val_loss: 35334709248.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36025389056.0000 - val_loss: 35335483392.0000\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36017283072.0000 - val_loss: 35314397184.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35997290496.0000 - val_loss: 35304615936.0000\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 35983847424.0000 - val_loss: 35326926848.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35978493952.0000 - val_loss: 35284365312.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35973316608.0000 - val_loss: 35279052800.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35949436928.0000 - val_loss: 35263229952.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35942903808.0000 - val_loss: 35267121152.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35932565504.0000 - val_loss: 35288571904.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35922804736.0000 - val_loss: 35258843136.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35910610944.0000 - val_loss: 35226812416.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35906502656.0000 - val_loss: 35239636992.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35886534656.0000 - val_loss: 35202588672.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35879301120.0000 - val_loss: 35251343360.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35867152384.0000 - val_loss: 35201097728.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35880570880.0000 - val_loss: 35191037952.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35838869504.0000 - val_loss: 35159306240.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35838181376.0000 - val_loss: 35185442816.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35818565632.0000 - val_loss: 35186663424.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35811721216.0000 - val_loss: 35107901440.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35810791424.0000 - val_loss: 35167031296.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35792556032.0000 - val_loss: 35125141504.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35779358720.0000 - val_loss: 35147493376.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35781980160.0000 - val_loss: 35153227776.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35766923264.0000 - val_loss: 35089481728.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35756756992.0000 - val_loss: 35079852032.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35744251904.0000 - val_loss: 35074617344.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35735785472.0000 - val_loss: 35074662400.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35714928640.0000 - val_loss: 35060625408.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35721895936.0000 - val_loss: 35047575552.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35694321664.0000 - val_loss: 35037741056.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35686670336.0000 - val_loss: 35014193152.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35676336128.0000 - val_loss: 35060862976.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35677474816.0000 - val_loss: 35046600704.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35655045120.0000 - val_loss: 35038040064.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35653623808.0000 - val_loss: 34990137344.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35639173120.0000 - val_loss: 35022856192.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35619139584.0000 - val_loss: 34951225344.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35633233920.0000 - val_loss: 35017334784.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35627515904.0000 - val_loss: 34915950592.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35600453632.0000 - val_loss: 34961649664.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35594416128.0000 - val_loss: 34976296960.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35606806528.0000 - val_loss: 34927775744.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35587944448.0000 - val_loss: 34940567552.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35565924352.0000 - val_loss: 34927296512.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35564298240.0000 - val_loss: 34979528704.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35552866304.0000 - val_loss: 34932232192.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35550269440.0000 - val_loss: 34966360064.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35534442496.0000 - val_loss: 34880024576.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35525758976.0000 - val_loss: 34886914048.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35523862528.0000 - val_loss: 34828746752.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35504410624.0000 - val_loss: 34850250752.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35497684992.0000 - val_loss: 34885574656.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35488337920.0000 - val_loss: 34842324992.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35482054656.0000 - val_loss: 34810982400.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35470172160.0000 - val_loss: 34831876096.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35454939136.0000 - val_loss: 34875150336.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35452071936.0000 - val_loss: 34791542784.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35442110464.0000 - val_loss: 34846466048.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35443437568.0000 - val_loss: 34788630528.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35426291712.0000 - val_loss: 34797928448.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35440271360.0000 - val_loss: 34781904896.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35406831616.0000 - val_loss: 34771898368.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35400683520.0000 - val_loss: 34788171776.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35390595072.0000 - val_loss: 34780962816.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35413737472.0000 - val_loss: 34757128192.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35393662976.0000 - val_loss: 34794553344.0000\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 34931417088.000 - 0s 1ms/step - loss: 35382296576.0000 - val_loss: 34778247168.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35360903168.0000 - val_loss: 34775576576.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35348287488.0000 - val_loss: 34717233152.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35347062784.0000 - val_loss: 34737979392.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35342532608.0000 - val_loss: 34716356608.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35339116544.0000 - val_loss: 34684272640.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35325845504.0000 - val_loss: 34725781504.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35327229952.0000 - val_loss: 34721009664.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35317645312.0000 - val_loss: 34725326848.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35310546944.0000 - val_loss: 34648338432.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35283898368.0000 - val_loss: 34694086656.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35289235456.0000 - val_loss: 34725908480.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35281510400.0000 - val_loss: 34658861056.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35280674816.0000 - val_loss: 34638946304.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35263922176.0000 - val_loss: 34691051520.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35258724352.0000 - val_loss: 34603794432.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35248738304.0000 - val_loss: 34633392128.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35237715968.0000 - val_loss: 34605273088.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35232964608.0000 - val_loss: 34602610688.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35225149440.0000 - val_loss: 34622771200.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35220357120.0000 - val_loss: 34640293888.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35228786688.0000 - val_loss: 34574938112.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35206479872.0000 - val_loss: 34591657984.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35196203008.0000 - val_loss: 34566230016.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35198230528.0000 - val_loss: 34561949696.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35176816640.0000 - val_loss: 34513915904.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35184431104.0000 - val_loss: 34518695936.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35180658688.0000 - val_loss: 34496745472.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35171004416.0000 - val_loss: 34489745408.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35183001600.0000 - val_loss: 34527571968.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35152744448.0000 - val_loss: 34488008704.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35136303104.0000 - val_loss: 34532667392.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35141230592.0000 - val_loss: 34507845632.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35134365696.0000 - val_loss: 34489606144.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35132137472.0000 - val_loss: 34504404992.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35123040256.0000 - val_loss: 34451255296.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35117699072.0000 - val_loss: 34491686912.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35116683264.0000 - val_loss: 34423992320.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23df9771e50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7244856442096482"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23dfab0c670>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result shows that as the number of unit increases the r2 score increases and the scatter points are more aligned with the y_test line. However, each iteration takes more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Higher Epoch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "  1/114 [..............................] - ETA: 0s - loss: 429952073728.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 430354857984.0000 - val_loss: 427942412288.0000\n",
      "Epoch 2/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 430327922688.0000 - val_loss: 427886608384.0000\n",
      "Epoch 3/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 430226046976.0000 - val_loss: 427727945728.0000\n",
      "Epoch 4/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 429994803200.0000 - val_loss: 427410128896.0000\n",
      "Epoch 5/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 429576847360.0000 - val_loss: 426879254528.0000\n",
      "Epoch 6/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 428928925696.0000 - val_loss: 426100260864.0000\n",
      "Epoch 7/1000\n",
      "114/114 [==============================] - 0s 878us/step - loss: 428016861184.0000 - val_loss: 425039331328.0000\n",
      "Epoch 8/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 426808573952.0000 - val_loss: 423665532928.0000\n",
      "Epoch 9/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 425274081280.0000 - val_loss: 421953961984.0000\n",
      "Epoch 10/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 423391199232.0000 - val_loss: 419883876352.0000\n",
      "Epoch 11/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 421144756224.0000 - val_loss: 417442791424.0000\n",
      "Epoch 12/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 418516697088.0000 - val_loss: 414607966208.0000\n",
      "Epoch 13/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 415506628608.0000 - val_loss: 411401486336.0000\n",
      "Epoch 14/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 412100493312.0000 - val_loss: 407767875584.0000\n",
      "Epoch 15/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 408300683264.0000 - val_loss: 403761889280.0000\n",
      "Epoch 16/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 404104019968.0000 - val_loss: 399356198912.0000\n",
      "Epoch 17/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 399509618688.0000 - val_loss: 394534617088.0000\n",
      "Epoch 18/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 394522853376.0000 - val_loss: 389345640448.0000\n",
      "Epoch 19/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 389147820032.0000 - val_loss: 383766528000.0000\n",
      "Epoch 20/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 383394250752.0000 - val_loss: 377797246976.0000\n",
      "Epoch 21/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 377281085440.0000 - val_loss: 371500941312.0000\n",
      "Epoch 22/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 370773950464.0000 - val_loss: 364712722432.0000\n",
      "Epoch 23/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 363826806784.0000 - val_loss: 357562712064.0000\n",
      "Epoch 24/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 356526882816.0000 - val_loss: 350088298496.0000\n",
      "Epoch 25/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 348898033664.0000 - val_loss: 342287056896.0000\n",
      "Epoch 26/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 340969586688.0000 - val_loss: 334206304256.0000\n",
      "Epoch 27/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 332778504192.0000 - val_loss: 325847875584.0000\n",
      "Epoch 28/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 324336910336.0000 - val_loss: 317276160000.0000\n",
      "Epoch 29/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 315687403520.0000 - val_loss: 308492500992.0000\n",
      "Epoch 30/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 306862981120.0000 - val_loss: 299571904512.0000\n",
      "Epoch 31/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 297883762688.0000 - val_loss: 290508308480.0000\n",
      "Epoch 32/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 288784613376.0000 - val_loss: 281321701376.0000\n",
      "Epoch 33/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 279611047936.0000 - val_loss: 272063037440.0000\n",
      "Epoch 34/1000\n",
      "114/114 [==============================] - 0s 834us/step - loss: 270384726016.0000 - val_loss: 262834585600.0000\n",
      "Epoch 35/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 261145051136.0000 - val_loss: 253549232128.0000\n",
      "Epoch 36/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 251922989056.0000 - val_loss: 244323500032.0000\n",
      "Epoch 37/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 242755469312.0000 - val_loss: 235177115648.0000\n",
      "Epoch 38/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 233661874176.0000 - val_loss: 226115321856.0000\n",
      "Epoch 39/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 224707035136.0000 - val_loss: 217220186112.0000\n",
      "Epoch 40/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 215903256576.0000 - val_loss: 208491921408.0000\n",
      "Epoch 41/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 207319662592.0000 - val_loss: 199957807104.0000\n",
      "Epoch 42/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 198959480832.0000 - val_loss: 191730647040.0000\n",
      "Epoch 43/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 190844567552.0000 - val_loss: 183751458816.0000\n",
      "Epoch 44/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 183036542976.0000 - val_loss: 176039772160.0000\n",
      "Epoch 45/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 175530868736.0000 - val_loss: 168669118464.0000\n",
      "Epoch 46/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 168390475776.0000 - val_loss: 161705869312.0000\n",
      "Epoch 47/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 161617149952.0000 - val_loss: 155119222784.0000\n",
      "Epoch 48/1000\n",
      "114/114 [==============================] - 0s 834us/step - loss: 155234910208.0000 - val_loss: 148903428096.0000\n",
      "Epoch 49/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 149242445824.0000 - val_loss: 143117910016.0000\n",
      "Epoch 50/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 143675752448.0000 - val_loss: 137755082752.0000\n",
      "Epoch 51/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 138551607296.0000 - val_loss: 132817494016.0000\n",
      "Epoch 52/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 133844754432.0000 - val_loss: 128339640320.0000\n",
      "Epoch 53/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 129571536896.0000 - val_loss: 124279758848.0000\n",
      "Epoch 54/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 125743587328.0000 - val_loss: 120629100544.0000\n",
      "Epoch 55/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 122340007936.0000 - val_loss: 117422104576.0000\n",
      "Epoch 56/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 119349395456.0000 - val_loss: 114664701952.0000\n",
      "Epoch 57/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 116742914048.0000 - val_loss: 112214548480.0000\n",
      "Epoch 58/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 114520653824.0000 - val_loss: 110154801152.0000\n",
      "Epoch 59/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 112633724928.0000 - val_loss: 108429451264.0000\n",
      "Epoch 60/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 111059968000.0000 - val_loss: 106976296960.0000\n",
      "Epoch 61/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 109757366272.0000 - val_loss: 105821790208.0000\n",
      "Epoch 62/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 108692365312.0000 - val_loss: 104866488320.0000\n",
      "Epoch 63/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 808us/step - loss: 107825020928.0000 - val_loss: 104074493952.0000\n",
      "Epoch 64/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 107132919808.0000 - val_loss: 103458676736.0000\n",
      "Epoch 65/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 106583449600.0000 - val_loss: 102960816128.0000\n",
      "Epoch 66/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 106145275904.0000 - val_loss: 102577045504.0000\n",
      "Epoch 67/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 105793200128.0000 - val_loss: 102257426432.0000\n",
      "Epoch 68/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 105504358400.0000 - val_loss: 101980758016.0000\n",
      "Epoch 69/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 105252102144.0000 - val_loss: 101757394944.0000\n",
      "Epoch 70/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 105036070912.0000 - val_loss: 101548523520.0000\n",
      "Epoch 71/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 104837308416.0000 - val_loss: 101361532928.0000\n",
      "Epoch 72/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 104653348864.0000 - val_loss: 101177483264.0000\n",
      "Epoch 73/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 104474124288.0000 - val_loss: 101001764864.0000\n",
      "Epoch 74/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 104298610688.0000 - val_loss: 100824637440.0000\n",
      "Epoch 75/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 104122507264.0000 - val_loss: 100650024960.0000\n",
      "Epoch 76/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 103946543104.0000 - val_loss: 100474003456.0000\n",
      "Epoch 77/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 103766384640.0000 - val_loss: 100288151552.0000\n",
      "Epoch 78/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 103580983296.0000 - val_loss: 100103872512.0000\n",
      "Epoch 79/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 103394402304.0000 - val_loss: 99918053376.0000\n",
      "Epoch 80/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 103207444480.0000 - val_loss: 99725754368.0000\n",
      "Epoch 81/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 103014014976.0000 - val_loss: 99532365824.0000\n",
      "Epoch 82/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 102819528704.0000 - val_loss: 99337756672.0000\n",
      "Epoch 83/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 102621069312.0000 - val_loss: 99136446464.0000\n",
      "Epoch 84/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 102422028288.0000 - val_loss: 98938003456.0000\n",
      "Epoch 85/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 102216515584.0000 - val_loss: 98733604864.0000\n",
      "Epoch 86/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 102013337600.0000 - val_loss: 98525650944.0000\n",
      "Epoch 87/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 101802000384.0000 - val_loss: 98317729792.0000\n",
      "Epoch 88/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 101595168768.0000 - val_loss: 98106212352.0000\n",
      "Epoch 89/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 101379735552.0000 - val_loss: 97892941824.0000\n",
      "Epoch 90/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 101169831936.0000 - val_loss: 97676247040.0000\n",
      "Epoch 91/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 100950032384.0000 - val_loss: 97460592640.0000\n",
      "Epoch 92/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 100734140416.0000 - val_loss: 97240211456.0000\n",
      "Epoch 93/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 100513390592.0000 - val_loss: 97020739584.0000\n",
      "Epoch 94/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 100292829184.0000 - val_loss: 96796672000.0000\n",
      "Epoch 95/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 100062601216.0000 - val_loss: 96573120512.0000\n",
      "Epoch 96/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 99840393216.0000 - val_loss: 96343736320.0000\n",
      "Epoch 97/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 99612852224.0000 - val_loss: 96120741888.0000\n",
      "Epoch 98/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 99383189504.0000 - val_loss: 95889793024.0000\n",
      "Epoch 99/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 99151577088.0000 - val_loss: 95656763392.0000\n",
      "Epoch 100/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 98921340928.0000 - val_loss: 95428313088.0000\n",
      "Epoch 101/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 98687885312.0000 - val_loss: 95190417408.0000\n",
      "Epoch 102/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 98454028288.0000 - val_loss: 94963204096.0000\n",
      "Epoch 103/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 98220924928.0000 - val_loss: 94728798208.0000\n",
      "Epoch 104/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 97986338816.0000 - val_loss: 94491082752.0000\n",
      "Epoch 105/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 97754324992.0000 - val_loss: 94255316992.0000\n",
      "Epoch 106/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 97518755840.0000 - val_loss: 94020796416.0000\n",
      "Epoch 107/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 97280409600.0000 - val_loss: 93785923584.0000\n",
      "Epoch 108/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 97046233088.0000 - val_loss: 93551902720.0000\n",
      "Epoch 109/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 96811155456.0000 - val_loss: 93316481024.0000\n",
      "Epoch 110/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 96574464000.0000 - val_loss: 93078847488.0000\n",
      "Epoch 111/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 96338739200.0000 - val_loss: 92842123264.0000\n",
      "Epoch 112/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 96097288192.0000 - val_loss: 92602621952.0000\n",
      "Epoch 113/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 95857508352.0000 - val_loss: 92363800576.0000\n",
      "Epoch 114/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 95618818048.0000 - val_loss: 92119867392.0000\n",
      "Epoch 115/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 95376465920.0000 - val_loss: 91880292352.0000\n",
      "Epoch 116/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 95135096832.0000 - val_loss: 91637825536.0000\n",
      "Epoch 117/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 94891941888.0000 - val_loss: 91395866624.0000\n",
      "Epoch 118/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 94648868864.0000 - val_loss: 91150344192.0000\n",
      "Epoch 119/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 94412726272.0000 - val_loss: 90905460736.0000\n",
      "Epoch 120/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 94161903616.0000 - val_loss: 90664067072.0000\n",
      "Epoch 121/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 93915635712.0000 - val_loss: 90417618944.0000\n",
      "Epoch 122/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 93670645760.0000 - val_loss: 90170859520.0000\n",
      "Epoch 123/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 93424869376.0000 - val_loss: 89925541888.0000\n",
      "Epoch 124/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 93175193600.0000 - val_loss: 89676357632.0000\n",
      "Epoch 125/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 92928598016.0000 - val_loss: 89427697664.0000\n",
      "Epoch 126/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 92679954432.0000 - val_loss: 89179488256.0000\n",
      "Epoch 127/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 92425732096.0000 - val_loss: 88927272960.0000\n",
      "Epoch 128/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 729us/step - loss: 92175884288.0000 - val_loss: 88678055936.0000\n",
      "Epoch 129/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 91925569536.0000 - val_loss: 88424243200.0000\n",
      "Epoch 130/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 91671879680.0000 - val_loss: 88170618880.0000\n",
      "Epoch 131/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 91417640960.0000 - val_loss: 87915692032.0000\n",
      "Epoch 132/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 91163090944.0000 - val_loss: 87659282432.0000\n",
      "Epoch 133/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 90905944064.0000 - val_loss: 87403388928.0000\n",
      "Epoch 134/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 90651926528.0000 - val_loss: 87146233856.0000\n",
      "Epoch 135/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 90394394624.0000 - val_loss: 86893936640.0000\n",
      "Epoch 136/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 90136756224.0000 - val_loss: 86632194048.0000\n",
      "Epoch 137/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 89878511616.0000 - val_loss: 86369697792.0000\n",
      "Epoch 138/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 89619243008.0000 - val_loss: 86115311616.0000\n",
      "Epoch 139/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 89356615680.0000 - val_loss: 85851865088.0000\n",
      "Epoch 140/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 89098608640.0000 - val_loss: 85589680128.0000\n",
      "Epoch 141/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 88835080192.0000 - val_loss: 85332967424.0000\n",
      "Epoch 142/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 88579620864.0000 - val_loss: 85068267520.0000\n",
      "Epoch 143/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 88318697472.0000 - val_loss: 84808507392.0000\n",
      "Epoch 144/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 88053473280.0000 - val_loss: 84546404352.0000\n",
      "Epoch 145/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 87788544000.0000 - val_loss: 84282482688.0000\n",
      "Epoch 146/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 87524302848.0000 - val_loss: 84018806784.0000\n",
      "Epoch 147/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 87260635136.0000 - val_loss: 83750756352.0000\n",
      "Epoch 148/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 86995197952.0000 - val_loss: 83484729344.0000\n",
      "Epoch 149/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 86729449472.0000 - val_loss: 83221676032.0000\n",
      "Epoch 150/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 86463799296.0000 - val_loss: 82954813440.0000\n",
      "Epoch 151/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 86195634176.0000 - val_loss: 82684026880.0000\n",
      "Epoch 152/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 85936324608.0000 - val_loss: 82423529472.0000\n",
      "Epoch 153/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 85660540928.0000 - val_loss: 82147041280.0000\n",
      "Epoch 154/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 85391187968.0000 - val_loss: 81874632704.0000\n",
      "Epoch 155/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 85118222336.0000 - val_loss: 81608204288.0000\n",
      "Epoch 156/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 84845379584.0000 - val_loss: 81331200000.0000\n",
      "Epoch 157/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 84572651520.0000 - val_loss: 81058684928.0000\n",
      "Epoch 158/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 84301037568.0000 - val_loss: 80783605760.0000\n",
      "Epoch 159/1000\n",
      "114/114 [==============================] - 0s 843us/step - loss: 84025958400.0000 - val_loss: 80508747776.0000\n",
      "Epoch 160/1000\n",
      "114/114 [==============================] - 0s 860us/step - loss: 83748790272.0000 - val_loss: 80234586112.0000\n",
      "Epoch 161/1000\n",
      "114/114 [==============================] - 0s 852us/step - loss: 83472252928.0000 - val_loss: 79955795968.0000\n",
      "Epoch 162/1000\n",
      "114/114 [==============================] - 0s 852us/step - loss: 83196190720.0000 - val_loss: 79674171392.0000\n",
      "Epoch 163/1000\n",
      "114/114 [==============================] - 0s 834us/step - loss: 82912714752.0000 - val_loss: 79397617664.0000\n",
      "Epoch 164/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 82634293248.0000 - val_loss: 79115345920.0000\n",
      "Epoch 165/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 82355290112.0000 - val_loss: 78834360320.0000\n",
      "Epoch 166/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 82069610496.0000 - val_loss: 78550073344.0000\n",
      "Epoch 167/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 81787666432.0000 - val_loss: 78267277312.0000\n",
      "Epoch 168/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 81500856320.0000 - val_loss: 77979541504.0000\n",
      "Epoch 169/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 81212579840.0000 - val_loss: 77692223488.0000\n",
      "Epoch 170/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 80925679616.0000 - val_loss: 77407248384.0000\n",
      "Epoch 171/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 80637190144.0000 - val_loss: 77111304192.0000\n",
      "Epoch 172/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 80347840512.0000 - val_loss: 76821512192.0000\n",
      "Epoch 173/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 80059244544.0000 - val_loss: 76532236288.0000\n",
      "Epoch 174/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 79766413312.0000 - val_loss: 76239183872.0000\n",
      "Epoch 175/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 79471198208.0000 - val_loss: 75946065920.0000\n",
      "Epoch 176/1000\n",
      "114/114 [==============================] - 0s 852us/step - loss: 79177752576.0000 - val_loss: 75649032192.0000\n",
      "Epoch 177/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 78890385408.0000 - val_loss: 75355897856.0000\n",
      "Epoch 178/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 78590640128.0000 - val_loss: 75060428800.0000\n",
      "Epoch 179/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 78294147072.0000 - val_loss: 74772209664.0000\n",
      "Epoch 180/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 78000857088.0000 - val_loss: 74475520000.0000\n",
      "Epoch 181/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 77710336000.0000 - val_loss: 74169581568.0000\n",
      "Epoch 182/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 77404848128.0000 - val_loss: 73874030592.0000\n",
      "Epoch 183/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 77112401920.0000 - val_loss: 73579151360.0000\n",
      "Epoch 184/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 76816252928.0000 - val_loss: 73287229440.0000\n",
      "Epoch 185/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 76522766336.0000 - val_loss: 72988327936.0000\n",
      "Epoch 186/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 76232032256.0000 - val_loss: 72694448128.0000\n",
      "Epoch 187/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 75932139520.0000 - val_loss: 72401879040.0000\n",
      "Epoch 188/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 75644076032.0000 - val_loss: 72111349760.0000\n",
      "Epoch 189/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 75349032960.0000 - val_loss: 71818076160.0000\n",
      "Epoch 190/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 75058839552.0000 - val_loss: 71524835328.0000\n",
      "Epoch 191/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 74765910016.0000 - val_loss: 71236788224.0000\n",
      "Epoch 192/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 74474250240.0000 - val_loss: 70942203904.0000\n",
      "Epoch 193/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 711us/step - loss: 74182066176.0000 - val_loss: 70654525440.0000\n",
      "Epoch 194/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 73893036032.0000 - val_loss: 70355550208.0000\n",
      "Epoch 195/1000\n",
      "114/114 [==============================] - 0s 878us/step - loss: 73600032768.0000 - val_loss: 70064242688.0000\n",
      "Epoch 196/1000\n",
      "114/114 [==============================] - 0s 852us/step - loss: 73300279296.0000 - val_loss: 69771026432.0000\n",
      "Epoch 197/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 73006227456.0000 - val_loss: 69479596032.0000\n",
      "Epoch 198/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 72710750208.0000 - val_loss: 69184815104.0000\n",
      "Epoch 199/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 72418222080.0000 - val_loss: 68888002560.0000\n",
      "Epoch 200/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 72125808640.0000 - val_loss: 68598554624.0000\n",
      "Epoch 201/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 71833280512.0000 - val_loss: 68305870848.0000\n",
      "Epoch 202/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 71541170176.0000 - val_loss: 68017700864.0000\n",
      "Epoch 203/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 71246725120.0000 - val_loss: 67722264576.0000\n",
      "Epoch 204/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 70954213376.0000 - val_loss: 67425300480.0000\n",
      "Epoch 205/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 70661455872.0000 - val_loss: 67132342272.0000\n",
      "Epoch 206/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 70369189888.0000 - val_loss: 66842345472.0000\n",
      "Epoch 207/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 70081019904.0000 - val_loss: 66556170240.0000\n",
      "Epoch 208/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 69790171136.0000 - val_loss: 66267914240.0000\n",
      "Epoch 209/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 69497544704.0000 - val_loss: 65976172544.0000\n",
      "Epoch 210/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 69208367104.0000 - val_loss: 65687515136.0000\n",
      "Epoch 211/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 68925726720.0000 - val_loss: 65405644800.0000\n",
      "Epoch 212/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 68637581312.0000 - val_loss: 65121193984.0000\n",
      "Epoch 213/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 68355170304.0000 - val_loss: 64840228864.0000\n",
      "Epoch 214/1000\n",
      "114/114 [==============================] - 0s 702us/step - loss: 68069158912.0000 - val_loss: 64553992192.0000\n",
      "Epoch 215/1000\n",
      "114/114 [==============================] - 0s 702us/step - loss: 67789111296.0000 - val_loss: 64274432000.0000\n",
      "Epoch 216/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 67511234560.0000 - val_loss: 63998124032.0000\n",
      "Epoch 217/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 67235020800.0000 - val_loss: 63723601920.0000\n",
      "Epoch 218/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 66957942784.0000 - val_loss: 63447744512.0000\n",
      "Epoch 219/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 66684006400.0000 - val_loss: 63180201984.0000\n",
      "Epoch 220/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 66410901504.0000 - val_loss: 62907285504.0000\n",
      "Epoch 221/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 66143293440.0000 - val_loss: 62637674496.0000\n",
      "Epoch 222/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 65870893056.0000 - val_loss: 62371725312.0000\n",
      "Epoch 223/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 65600438272.0000 - val_loss: 62104907776.0000\n",
      "Epoch 224/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 65332637696.0000 - val_loss: 61836398592.0000\n",
      "Epoch 225/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 65063804928.0000 - val_loss: 61575028736.0000\n",
      "Epoch 226/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 64800141312.0000 - val_loss: 61306609664.0000\n",
      "Epoch 227/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 64534609920.0000 - val_loss: 61046337536.0000\n",
      "Epoch 228/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 64275488768.0000 - val_loss: 60797911040.0000\n",
      "Epoch 229/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 64019955712.0000 - val_loss: 60539924480.0000\n",
      "Epoch 230/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 63761674240.0000 - val_loss: 60284047360.0000\n",
      "Epoch 231/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 63512678400.0000 - val_loss: 60031680512.0000\n",
      "Epoch 232/1000\n",
      "114/114 [==============================] - 0s 702us/step - loss: 63262486528.0000 - val_loss: 59786653696.0000\n",
      "Epoch 233/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 63020584960.0000 - val_loss: 59549544448.0000\n",
      "Epoch 234/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 62780760064.0000 - val_loss: 59307810816.0000\n",
      "Epoch 235/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 62534451200.0000 - val_loss: 59071148032.0000\n",
      "Epoch 236/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 62300225536.0000 - val_loss: 58836787200.0000\n",
      "Epoch 237/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 62068240384.0000 - val_loss: 58611712000.0000\n",
      "Epoch 238/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 61836247040.0000 - val_loss: 58381238272.0000\n",
      "Epoch 239/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 61602795520.0000 - val_loss: 58149130240.0000\n",
      "Epoch 240/1000\n",
      "114/114 [==============================] - ETA: 0s - loss: 63104937984.000 - 0s 764us/step - loss: 61376036864.0000 - val_loss: 57921245184.0000\n",
      "Epoch 241/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 61145493504.0000 - val_loss: 57700311040.0000\n",
      "Epoch 242/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 60924751872.0000 - val_loss: 57480273920.0000\n",
      "Epoch 243/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 60704911360.0000 - val_loss: 57266266112.0000\n",
      "Epoch 244/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 60484509696.0000 - val_loss: 57050329088.0000\n",
      "Epoch 245/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 60270702592.0000 - val_loss: 56838680576.0000\n",
      "Epoch 246/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 60057698304.0000 - val_loss: 56628707328.0000\n",
      "Epoch 247/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 59851829248.0000 - val_loss: 56426258432.0000\n",
      "Epoch 248/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 59649515520.0000 - val_loss: 56224784384.0000\n",
      "Epoch 249/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 59447988224.0000 - val_loss: 56030121984.0000\n",
      "Epoch 250/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 59248910336.0000 - val_loss: 55839600640.0000\n",
      "Epoch 251/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 59057598464.0000 - val_loss: 55650648064.0000\n",
      "Epoch 252/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 58867421184.0000 - val_loss: 55468781568.0000\n",
      "Epoch 253/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 58676047872.0000 - val_loss: 55282159616.0000\n",
      "Epoch 254/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 58494406656.0000 - val_loss: 55101374464.0000\n",
      "Epoch 255/1000\n",
      "114/114 [==============================] - 0s 702us/step - loss: 58310197248.0000 - val_loss: 54924656640.0000\n",
      "Epoch 256/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 58131619840.0000 - val_loss: 54752907264.0000\n",
      "Epoch 257/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 57958854656.0000 - val_loss: 54581186560.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 57778991104.0000 - val_loss: 54414614528.0000\n",
      "Epoch 259/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 57608445952.0000 - val_loss: 54241275904.0000\n",
      "Epoch 260/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 57439801344.0000 - val_loss: 54078271488.0000\n",
      "Epoch 261/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 57278074880.0000 - val_loss: 53920870400.0000\n",
      "Epoch 262/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 57110319104.0000 - val_loss: 53763915776.0000\n",
      "Epoch 263/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 56947392512.0000 - val_loss: 53610545152.0000\n",
      "Epoch 264/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 56793432064.0000 - val_loss: 53450342400.0000\n",
      "Epoch 265/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 56635904000.0000 - val_loss: 53304602624.0000\n",
      "Epoch 266/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 56482451456.0000 - val_loss: 53154988032.0000\n",
      "Epoch 267/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 56332447744.0000 - val_loss: 53010223104.0000\n",
      "Epoch 268/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 56180649984.0000 - val_loss: 52868505600.0000\n",
      "Epoch 269/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 56035540992.0000 - val_loss: 52727459840.0000\n",
      "Epoch 270/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 55896420352.0000 - val_loss: 52592107520.0000\n",
      "Epoch 271/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 55759421440.0000 - val_loss: 52467077120.0000\n",
      "Epoch 272/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 55625588736.0000 - val_loss: 52334530560.0000\n",
      "Epoch 273/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 55493029888.0000 - val_loss: 52210569216.0000\n",
      "Epoch 274/1000\n",
      "114/114 [==============================] - 0s 702us/step - loss: 55365648384.0000 - val_loss: 52089360384.0000\n",
      "Epoch 275/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 55240949760.0000 - val_loss: 51971457024.0000\n",
      "Epoch 276/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 55117090816.0000 - val_loss: 51850559488.0000\n",
      "Epoch 277/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 54997209088.0000 - val_loss: 51735146496.0000\n",
      "Epoch 278/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 54876139520.0000 - val_loss: 51623297024.0000\n",
      "Epoch 279/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 54760583168.0000 - val_loss: 51512287232.0000\n",
      "Epoch 280/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 54647947264.0000 - val_loss: 51401883648.0000\n",
      "Epoch 281/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 54535266304.0000 - val_loss: 51298422784.0000\n",
      "Epoch 282/1000\n",
      "114/114 [==============================] - 0s 887us/step - loss: 54427312128.0000 - val_loss: 51195248640.0000\n",
      "Epoch 283/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 54320136192.0000 - val_loss: 51094138880.0000\n",
      "Epoch 284/1000\n",
      "114/114 [==============================] - 0s 834us/step - loss: 54215376896.0000 - val_loss: 50997182464.0000\n",
      "Epoch 285/1000\n",
      "114/114 [==============================] - 0s 904us/step - loss: 54113652736.0000 - val_loss: 50898632704.0000\n",
      "Epoch 286/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 54014869504.0000 - val_loss: 50804207616.0000\n",
      "Epoch 287/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 53915705344.0000 - val_loss: 50710081536.0000\n",
      "Epoch 288/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53818089472.0000 - val_loss: 50620162048.0000\n",
      "Epoch 289/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53725155328.0000 - val_loss: 50530775040.0000\n",
      "Epoch 290/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 53633183744.0000 - val_loss: 50444734464.0000\n",
      "Epoch 291/1000\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53542391808.0000 - val_loss: 50360516608.0000\n",
      "Epoch 292/1000\n",
      "114/114 [==============================] - 0s 975us/step - loss: 53455978496.0000 - val_loss: 50281295872.0000\n",
      "Epoch 293/1000\n",
      "114/114 [==============================] - 0s 834us/step - loss: 53366480896.0000 - val_loss: 50197258240.0000\n",
      "Epoch 294/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53281050624.0000 - val_loss: 50119520256.0000\n",
      "Epoch 295/1000\n",
      "114/114 [==============================] - 0s 957us/step - loss: 53197852672.0000 - val_loss: 50041794560.0000\n",
      "Epoch 296/1000\n",
      "114/114 [==============================] - 0s 896us/step - loss: 53115023360.0000 - val_loss: 49966723072.0000\n",
      "Epoch 297/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 53034020864.0000 - val_loss: 49889210368.0000\n",
      "Epoch 298/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 52957020160.0000 - val_loss: 49814896640.0000\n",
      "Epoch 299/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52879855616.0000 - val_loss: 49745084416.0000\n",
      "Epoch 300/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 52802244608.0000 - val_loss: 49680748544.0000\n",
      "Epoch 301/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 52726534144.0000 - val_loss: 49606737920.0000\n",
      "Epoch 302/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 52649066496.0000 - val_loss: 49540640768.0000\n",
      "Epoch 303/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 52577910784.0000 - val_loss: 49475215360.0000\n",
      "Epoch 304/1000\n",
      "114/114 [==============================] - 0s 869us/step - loss: 52502609920.0000 - val_loss: 49408520192.0000\n",
      "Epoch 305/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 52433854464.0000 - val_loss: 49340575744.0000\n",
      "Epoch 306/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52367302656.0000 - val_loss: 49277050880.0000\n",
      "Epoch 307/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 52300808192.0000 - val_loss: 49215946752.0000\n",
      "Epoch 308/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 52233658368.0000 - val_loss: 49159548928.0000\n",
      "Epoch 309/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 52165152768.0000 - val_loss: 49099358208.0000\n",
      "Epoch 310/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 52104445952.0000 - val_loss: 49039659008.0000\n",
      "Epoch 311/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 52044382208.0000 - val_loss: 48985718784.0000\n",
      "Epoch 312/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51982045184.0000 - val_loss: 48927203328.0000\n",
      "Epoch 313/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51927457792.0000 - val_loss: 48871043072.0000\n",
      "Epoch 314/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51866226688.0000 - val_loss: 48823840768.0000\n",
      "Epoch 315/1000\n",
      "114/114 [==============================] - 0s 913us/step - loss: 51808657408.0000 - val_loss: 48773095424.0000\n",
      "Epoch 316/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 51758256128.0000 - val_loss: 48719290368.0000\n",
      "Epoch 317/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 51700699136.0000 - val_loss: 48667602944.0000\n",
      "Epoch 318/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51644661760.0000 - val_loss: 48624893952.0000\n",
      "Epoch 319/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 51594096640.0000 - val_loss: 48581328896.0000\n",
      "Epoch 320/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 51540008960.0000 - val_loss: 48529915904.0000\n",
      "Epoch 321/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51488452608.0000 - val_loss: 48483545088.0000\n",
      "Epoch 322/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51440439296.0000 - val_loss: 48437276672.0000\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 729us/step - loss: 51391053824.0000 - val_loss: 48389091328.0000\n",
      "Epoch 324/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51340726272.0000 - val_loss: 48347779072.0000\n",
      "Epoch 325/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51299958784.0000 - val_loss: 48301391872.0000\n",
      "Epoch 326/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 51249827840.0000 - val_loss: 48257503232.0000\n",
      "Epoch 327/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 51202654208.0000 - val_loss: 48217710592.0000\n",
      "Epoch 328/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 51158233088.0000 - val_loss: 48177360896.0000\n",
      "Epoch 329/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 51117076480.0000 - val_loss: 48135479296.0000\n",
      "Epoch 330/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 51070058496.0000 - val_loss: 48100450304.0000\n",
      "Epoch 331/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 51029852160.0000 - val_loss: 48062246912.0000\n",
      "Epoch 332/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 50982232064.0000 - val_loss: 48027107328.0000\n",
      "Epoch 333/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50947141632.0000 - val_loss: 47988625408.0000\n",
      "Epoch 334/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 50900602880.0000 - val_loss: 47944716288.0000\n",
      "Epoch 335/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 50857111552.0000 - val_loss: 47905943552.0000\n",
      "Epoch 336/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 50821275648.0000 - val_loss: 47873490944.0000\n",
      "Epoch 337/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50780045312.0000 - val_loss: 47829643264.0000\n",
      "Epoch 338/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 50741678080.0000 - val_loss: 47796797440.0000\n",
      "Epoch 339/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50702655488.0000 - val_loss: 47763021824.0000\n",
      "Epoch 340/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50662416384.0000 - val_loss: 47729385472.0000\n",
      "Epoch 341/1000\n",
      "114/114 [==============================] - 0s 702us/step - loss: 50623815680.0000 - val_loss: 47698063360.0000\n",
      "Epoch 342/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 50589741056.0000 - val_loss: 47665500160.0000\n",
      "Epoch 343/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 50552877056.0000 - val_loss: 47631134720.0000\n",
      "Epoch 344/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 50514345984.0000 - val_loss: 47598575616.0000\n",
      "Epoch 345/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 50478497792.0000 - val_loss: 47575285760.0000\n",
      "Epoch 346/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50441363456.0000 - val_loss: 47532998656.0000\n",
      "Epoch 347/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50405826560.0000 - val_loss: 47499145216.0000\n",
      "Epoch 348/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 50374893568.0000 - val_loss: 47471513600.0000\n",
      "Epoch 349/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50342076416.0000 - val_loss: 47444049920.0000\n",
      "Epoch 350/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 50304086016.0000 - val_loss: 47412457472.0000\n",
      "Epoch 351/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 50276921344.0000 - val_loss: 47382204416.0000\n",
      "Epoch 352/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 50243145728.0000 - val_loss: 47348543488.0000\n",
      "Epoch 353/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 50205179904.0000 - val_loss: 47325548544.0000\n",
      "Epoch 354/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 50175795200.0000 - val_loss: 47303745536.0000\n",
      "Epoch 355/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 50140495872.0000 - val_loss: 47265714176.0000\n",
      "Epoch 356/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 50107621376.0000 - val_loss: 47236046848.0000\n",
      "Epoch 357/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 50080063488.0000 - val_loss: 47207419904.0000\n",
      "Epoch 358/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 50047950848.0000 - val_loss: 47178166272.0000\n",
      "Epoch 359/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 50015117312.0000 - val_loss: 47150370816.0000\n",
      "Epoch 360/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 49985040384.0000 - val_loss: 47129329664.0000\n",
      "Epoch 361/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 49958383616.0000 - val_loss: 47102095360.0000\n",
      "Epoch 362/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 49922654208.0000 - val_loss: 47072444416.0000\n",
      "Epoch 363/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49898110976.0000 - val_loss: 47045935104.0000\n",
      "Epoch 364/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 49863213056.0000 - val_loss: 47016378368.0000\n",
      "Epoch 365/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49836404736.0000 - val_loss: 46989377536.0000\n",
      "Epoch 366/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 49805152256.0000 - val_loss: 46971305984.0000\n",
      "Epoch 367/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49774616576.0000 - val_loss: 46936735744.0000\n",
      "Epoch 368/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49748291584.0000 - val_loss: 46908252160.0000\n",
      "Epoch 369/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49716310016.0000 - val_loss: 46889287680.0000\n",
      "Epoch 370/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49688907776.0000 - val_loss: 46857322496.0000\n",
      "Epoch 371/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 49659858944.0000 - val_loss: 46839099392.0000\n",
      "Epoch 372/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 49635180544.0000 - val_loss: 46811619328.0000\n",
      "Epoch 373/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49608105984.0000 - val_loss: 46789693440.0000\n",
      "Epoch 374/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 49576820736.0000 - val_loss: 46759940096.0000\n",
      "Epoch 375/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 49550516224.0000 - val_loss: 46737780736.0000\n",
      "Epoch 376/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49520377856.0000 - val_loss: 46713311232.0000\n",
      "Epoch 377/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 49499492352.0000 - val_loss: 46697381888.0000\n",
      "Epoch 378/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49467338752.0000 - val_loss: 46667534336.0000\n",
      "Epoch 379/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 49445085184.0000 - val_loss: 46651297792.0000\n",
      "Epoch 380/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 49412431872.0000 - val_loss: 46621650944.0000\n",
      "Epoch 381/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 49387503616.0000 - val_loss: 46596050944.0000\n",
      "Epoch 382/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 49372332032.0000 - val_loss: 46573228032.0000\n",
      "Epoch 383/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 49336565760.0000 - val_loss: 46551949312.0000\n",
      "Epoch 384/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49311682560.0000 - val_loss: 46526382080.0000\n",
      "Epoch 385/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 49287614464.0000 - val_loss: 46506590208.0000\n",
      "Epoch 386/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 49264230400.0000 - val_loss: 46486024192.0000\n",
      "Epoch 387/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 49238614016.0000 - val_loss: 46455611392.0000\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 720us/step - loss: 49212416000.0000 - val_loss: 46434164736.0000\n",
      "Epoch 389/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 49189015552.0000 - val_loss: 46419972096.0000\n",
      "Epoch 390/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 49164427264.0000 - val_loss: 46394937344.0000\n",
      "Epoch 391/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 49140408320.0000 - val_loss: 46379159552.0000\n",
      "Epoch 392/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49114296320.0000 - val_loss: 46355451904.0000\n",
      "Epoch 393/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49090330624.0000 - val_loss: 46328643584.0000\n",
      "Epoch 394/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 49065672704.0000 - val_loss: 46314323968.0000\n",
      "Epoch 395/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 49041895424.0000 - val_loss: 46289297408.0000\n",
      "Epoch 396/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 49018122240.0000 - val_loss: 46265147392.0000\n",
      "Epoch 397/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 48996769792.0000 - val_loss: 46243471360.0000\n",
      "Epoch 398/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48969142272.0000 - val_loss: 46225076224.0000\n",
      "Epoch 399/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 48946597888.0000 - val_loss: 46204616704.0000\n",
      "Epoch 400/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48921817088.0000 - val_loss: 46182166528.0000\n",
      "Epoch 401/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48903606272.0000 - val_loss: 46161317888.0000\n",
      "Epoch 402/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 48875700224.0000 - val_loss: 46134202368.0000\n",
      "Epoch 403/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48849825792.0000 - val_loss: 46119448576.0000\n",
      "Epoch 404/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 48828157952.0000 - val_loss: 46098968576.0000\n",
      "Epoch 405/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48804044800.0000 - val_loss: 46074331136.0000\n",
      "Epoch 406/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48782802944.0000 - val_loss: 46059274240.0000\n",
      "Epoch 407/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48758054912.0000 - val_loss: 46030721024.0000\n",
      "Epoch 408/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48738582528.0000 - val_loss: 46017343488.0000\n",
      "Epoch 409/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 48713031680.0000 - val_loss: 45995704320.0000\n",
      "Epoch 410/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 48686518272.0000 - val_loss: 45977559040.0000\n",
      "Epoch 411/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 48666791936.0000 - val_loss: 45959720960.0000\n",
      "Epoch 412/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 48643162112.0000 - val_loss: 45935697920.0000\n",
      "Epoch 413/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48621789184.0000 - val_loss: 45914976256.0000\n",
      "Epoch 414/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48597815296.0000 - val_loss: 45891588096.0000\n",
      "Epoch 415/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48577531904.0000 - val_loss: 45877125120.0000\n",
      "Epoch 416/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48551845888.0000 - val_loss: 45857079296.0000\n",
      "Epoch 417/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48532443136.0000 - val_loss: 45840179200.0000\n",
      "Epoch 418/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48510095360.0000 - val_loss: 45820502016.0000\n",
      "Epoch 419/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48487333888.0000 - val_loss: 45800620032.0000\n",
      "Epoch 420/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48459153408.0000 - val_loss: 45773357056.0000\n",
      "Epoch 421/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48439656448.0000 - val_loss: 45753044992.0000\n",
      "Epoch 422/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48416669696.0000 - val_loss: 45737209856.0000\n",
      "Epoch 423/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48395120640.0000 - val_loss: 45713088512.0000\n",
      "Epoch 424/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 48370278400.0000 - val_loss: 45696167936.0000\n",
      "Epoch 425/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 48353873920.0000 - val_loss: 45681946624.0000\n",
      "Epoch 426/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 48327798784.0000 - val_loss: 45657001984.0000\n",
      "Epoch 427/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48306221056.0000 - val_loss: 45638402048.0000\n",
      "Epoch 428/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 48288460800.0000 - val_loss: 45625610240.0000\n",
      "Epoch 429/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48263499776.0000 - val_loss: 45597413376.0000\n",
      "Epoch 430/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48239005696.0000 - val_loss: 45577498624.0000\n",
      "Epoch 431/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 48221753344.0000 - val_loss: 45557223424.0000\n",
      "Epoch 432/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 48197033984.0000 - val_loss: 45535805440.0000\n",
      "Epoch 433/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48171933696.0000 - val_loss: 45519589376.0000\n",
      "Epoch 434/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48146391040.0000 - val_loss: 45496905728.0000\n",
      "Epoch 435/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48126930944.0000 - val_loss: 45475328000.0000\n",
      "Epoch 436/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48104652800.0000 - val_loss: 45461803008.0000\n",
      "Epoch 437/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48081674240.0000 - val_loss: 45440536576.0000\n",
      "Epoch 438/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48062935040.0000 - val_loss: 45414219776.0000\n",
      "Epoch 439/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 48036016128.0000 - val_loss: 45397401600.0000\n",
      "Epoch 440/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 48013901824.0000 - val_loss: 45377859584.0000\n",
      "Epoch 441/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 47992524800.0000 - val_loss: 45360824320.0000\n",
      "Epoch 442/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 47969058816.0000 - val_loss: 45345693696.0000\n",
      "Epoch 443/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47946850304.0000 - val_loss: 45314641920.0000\n",
      "Epoch 444/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 47925755904.0000 - val_loss: 45293293568.0000\n",
      "Epoch 445/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 47903662080.0000 - val_loss: 45273616384.0000\n",
      "Epoch 446/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 47882276864.0000 - val_loss: 45250867200.0000\n",
      "Epoch 447/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 47858089984.0000 - val_loss: 45236805632.0000\n",
      "Epoch 448/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 47831310336.0000 - val_loss: 45216452608.0000\n",
      "Epoch 449/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47813591040.0000 - val_loss: 45189484544.0000\n",
      "Epoch 450/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47798915072.0000 - val_loss: 45177311232.0000\n",
      "Epoch 451/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47761399808.0000 - val_loss: 45152919552.0000\n",
      "Epoch 452/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 47739723776.0000 - val_loss: 45138305024.0000\n",
      "Epoch 453/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 808us/step - loss: 47719538688.0000 - val_loss: 45112569856.0000\n",
      "Epoch 454/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 47691444224.0000 - val_loss: 45087621120.0000\n",
      "Epoch 455/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 47669243904.0000 - val_loss: 45068660736.0000\n",
      "Epoch 456/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 47639793664.0000 - val_loss: 45045633024.0000\n",
      "Epoch 457/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47614005248.0000 - val_loss: 45023637504.0000\n",
      "Epoch 458/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47588544512.0000 - val_loss: 45002170368.0000\n",
      "Epoch 459/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 47562330112.0000 - val_loss: 44976852992.0000\n",
      "Epoch 460/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 47536111616.0000 - val_loss: 44954587136.0000\n",
      "Epoch 461/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 47510839296.0000 - val_loss: 44932317184.0000\n",
      "Epoch 462/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47487533056.0000 - val_loss: 44902633472.0000\n",
      "Epoch 463/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47462019072.0000 - val_loss: 44878274560.0000\n",
      "Epoch 464/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 47434006528.0000 - val_loss: 44855324672.0000\n",
      "Epoch 465/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 47397994496.0000 - val_loss: 44825182208.0000\n",
      "Epoch 466/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 47369637888.0000 - val_loss: 44797440000.0000\n",
      "Epoch 467/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 47336976384.0000 - val_loss: 44776206336.0000\n",
      "Epoch 468/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 47308488704.0000 - val_loss: 44751036416.0000\n",
      "Epoch 469/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 47275859968.0000 - val_loss: 44720852992.0000\n",
      "Epoch 470/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 47245115392.0000 - val_loss: 44691578880.0000\n",
      "Epoch 471/1000\n",
      "114/114 [==============================] - ETA: 0s - loss: 46282772480.000 - 0s 790us/step - loss: 47208841216.0000 - val_loss: 44658892800.0000\n",
      "Epoch 472/1000\n",
      "114/114 [==============================] - 0s 931us/step - loss: 47176630272.0000 - val_loss: 44630298624.0000\n",
      "Epoch 473/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 47142617088.0000 - val_loss: 44598571008.0000\n",
      "Epoch 474/1000\n",
      "114/114 [==============================] - 0s 843us/step - loss: 47115804672.0000 - val_loss: 44562509824.0000\n",
      "Epoch 475/1000\n",
      "114/114 [==============================] - 0s 825us/step - loss: 47074643968.0000 - val_loss: 44536504320.0000\n",
      "Epoch 476/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 47041568768.0000 - val_loss: 44508979200.0000\n",
      "Epoch 477/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 47004131328.0000 - val_loss: 44472541184.0000\n",
      "Epoch 478/1000\n",
      "114/114 [==============================] - 0s 860us/step - loss: 46968483840.0000 - val_loss: 44440457216.0000\n",
      "Epoch 479/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 46937182208.0000 - val_loss: 44404850688.0000\n",
      "Epoch 480/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 46899638272.0000 - val_loss: 44372639744.0000\n",
      "Epoch 481/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 46861205504.0000 - val_loss: 44341526528.0000\n",
      "Epoch 482/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46823522304.0000 - val_loss: 44312535040.0000\n",
      "Epoch 483/1000\n",
      "114/114 [==============================] - 0s 852us/step - loss: 46788206592.0000 - val_loss: 44282642432.0000\n",
      "Epoch 484/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 46751764480.0000 - val_loss: 44243697664.0000\n",
      "Epoch 485/1000\n",
      "114/114 [==============================] - 0s 983us/step - loss: 46712905728.0000 - val_loss: 44209758208.0000\n",
      "Epoch 486/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46672809984.0000 - val_loss: 44184698880.0000\n",
      "Epoch 487/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 46636822528.0000 - val_loss: 44146315264.0000\n",
      "Epoch 488/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 46609190912.0000 - val_loss: 44118335488.0000\n",
      "Epoch 489/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 46564933632.0000 - val_loss: 44081856512.0000\n",
      "Epoch 490/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 46527512576.0000 - val_loss: 44052602880.0000\n",
      "Epoch 491/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 46493937664.0000 - val_loss: 44024909824.0000\n",
      "Epoch 492/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 46462017536.0000 - val_loss: 43993808896.0000\n",
      "Epoch 493/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 46427512832.0000 - val_loss: 43966763008.0000\n",
      "Epoch 494/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 46398636032.0000 - val_loss: 43938238464.0000\n",
      "Epoch 495/1000\n",
      "114/114 [==============================] - 0s 931us/step - loss: 46362521600.0000 - val_loss: 43905290240.0000\n",
      "Epoch 496/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46332940288.0000 - val_loss: 43879555072.0000\n",
      "Epoch 497/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 46302203904.0000 - val_loss: 43850850304.0000\n",
      "Epoch 498/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 46271877120.0000 - val_loss: 43823206400.0000\n",
      "Epoch 499/1000\n",
      "114/114 [==============================] - 0s 834us/step - loss: 46241345536.0000 - val_loss: 43794731008.0000\n",
      "Epoch 500/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 46214934528.0000 - val_loss: 43774263296.0000\n",
      "Epoch 501/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 46187249664.0000 - val_loss: 43748294656.0000\n",
      "Epoch 502/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 46158602240.0000 - val_loss: 43728117760.0000\n",
      "Epoch 503/1000\n",
      "114/114 [==============================] - 0s 843us/step - loss: 46131798016.0000 - val_loss: 43695353856.0000\n",
      "Epoch 504/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 46106599424.0000 - val_loss: 43667832832.0000\n",
      "Epoch 505/1000\n",
      "114/114 [==============================] - 0s 913us/step - loss: 46078074880.0000 - val_loss: 43650019328.0000\n",
      "Epoch 506/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46055677952.0000 - val_loss: 43628613632.0000\n",
      "Epoch 507/1000\n",
      "114/114 [==============================] - 0s 904us/step - loss: 46026919936.0000 - val_loss: 43610324992.0000\n",
      "Epoch 508/1000\n",
      "114/114 [==============================] - 0s 896us/step - loss: 46003548160.0000 - val_loss: 43577012224.0000\n",
      "Epoch 509/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 45976485888.0000 - val_loss: 43564998656.0000\n",
      "Epoch 510/1000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45949517824.0000 - val_loss: 43539619840.0000\n",
      "Epoch 511/1000\n",
      "114/114 [==============================] - 0s 896us/step - loss: 45927587840.0000 - val_loss: 43509350400.0000\n",
      "Epoch 512/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 45903249408.0000 - val_loss: 43485593600.0000\n",
      "Epoch 513/1000\n",
      "114/114 [==============================] - 0s 939us/step - loss: 45877694464.0000 - val_loss: 43465060352.0000\n",
      "Epoch 514/1000\n",
      "114/114 [==============================] - 0s 869us/step - loss: 45849157632.0000 - val_loss: 43451060224.0000\n",
      "Epoch 515/1000\n",
      "114/114 [==============================] - 0s 878us/step - loss: 45827813376.0000 - val_loss: 43424796672.0000\n",
      "Epoch 516/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 45800865792.0000 - val_loss: 43397369856.0000\n",
      "Epoch 517/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 45774962688.0000 - val_loss: 43376852992.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 518/1000\n",
      "114/114 [==============================] - 0s 852us/step - loss: 45752201216.0000 - val_loss: 43351339008.0000\n",
      "Epoch 519/1000\n",
      "114/114 [==============================] - 0s 869us/step - loss: 45726191616.0000 - val_loss: 43337375744.0000\n",
      "Epoch 520/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 45703348224.0000 - val_loss: 43302866944.0000\n",
      "Epoch 521/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 45675331584.0000 - val_loss: 43278225408.0000\n",
      "Epoch 522/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 45649739776.0000 - val_loss: 43257139200.0000\n",
      "Epoch 523/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 45633302528.0000 - val_loss: 43231051776.0000\n",
      "Epoch 524/1000\n",
      "114/114 [==============================] - 0s 834us/step - loss: 45600989184.0000 - val_loss: 43213815808.0000\n",
      "Epoch 525/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 45570510848.0000 - val_loss: 43201429504.0000\n",
      "Epoch 526/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 45542400000.0000 - val_loss: 43171336192.0000\n",
      "Epoch 527/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 45513179136.0000 - val_loss: 43146375168.0000\n",
      "Epoch 528/1000\n",
      "114/114 [==============================] - 0s 817us/step - loss: 45489258496.0000 - val_loss: 43118239744.0000\n",
      "Epoch 529/1000\n",
      "114/114 [==============================] - 0s 939us/step - loss: 45458616320.0000 - val_loss: 43097575424.0000\n",
      "Epoch 530/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 45434187776.0000 - val_loss: 43076300800.0000\n",
      "Epoch 531/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 45404807168.0000 - val_loss: 43055529984.0000\n",
      "Epoch 532/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 45377335296.0000 - val_loss: 43023245312.0000\n",
      "Epoch 533/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 45346488320.0000 - val_loss: 42998734848.0000\n",
      "Epoch 534/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 45317287936.0000 - val_loss: 42967076864.0000\n",
      "Epoch 535/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 45284790272.0000 - val_loss: 42940624896.0000\n",
      "Epoch 536/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 45255950336.0000 - val_loss: 42917433344.0000\n",
      "Epoch 537/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 45226237952.0000 - val_loss: 42884624384.0000\n",
      "Epoch 538/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 45194305536.0000 - val_loss: 42858016768.0000\n",
      "Epoch 539/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 45164163072.0000 - val_loss: 42825715712.0000\n",
      "Epoch 540/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 45132115968.0000 - val_loss: 42807201792.0000\n",
      "Epoch 541/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 45100314624.0000 - val_loss: 42778984448.0000\n",
      "Epoch 542/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 45066944512.0000 - val_loss: 42742333440.0000\n",
      "Epoch 543/1000\n",
      "114/114 [==============================] - 0s 808us/step - loss: 45034237952.0000 - val_loss: 42717454336.0000\n",
      "Epoch 544/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 45001945088.0000 - val_loss: 42686107648.0000\n",
      "Epoch 545/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 44970594304.0000 - val_loss: 42648997888.0000\n",
      "Epoch 546/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 44932653056.0000 - val_loss: 42625044480.0000\n",
      "Epoch 547/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 44900016128.0000 - val_loss: 42593116160.0000\n",
      "Epoch 548/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44867575808.0000 - val_loss: 42564296704.0000\n",
      "Epoch 549/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 44831256576.0000 - val_loss: 42534744064.0000\n",
      "Epoch 550/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44800491520.0000 - val_loss: 42505895936.0000\n",
      "Epoch 551/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 44771119104.0000 - val_loss: 42472214528.0000\n",
      "Epoch 552/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44733374464.0000 - val_loss: 42451828736.0000\n",
      "Epoch 553/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 44700078080.0000 - val_loss: 42411683840.0000\n",
      "Epoch 554/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 44663873536.0000 - val_loss: 42390933504.0000\n",
      "Epoch 555/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 44633427968.0000 - val_loss: 42354806784.0000\n",
      "Epoch 556/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 44601589760.0000 - val_loss: 42333970432.0000\n",
      "Epoch 557/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44567871488.0000 - val_loss: 42304647168.0000\n",
      "Epoch 558/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 44535537664.0000 - val_loss: 42276810752.0000\n",
      "Epoch 559/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44503273472.0000 - val_loss: 42248437760.0000\n",
      "Epoch 560/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 44474830848.0000 - val_loss: 42224111616.0000\n",
      "Epoch 561/1000\n",
      "114/114 [==============================] - 0s 825us/step - loss: 44444979200.0000 - val_loss: 42197508096.0000\n",
      "Epoch 562/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 44409556992.0000 - val_loss: 42175102976.0000\n",
      "Epoch 563/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 44382818304.0000 - val_loss: 42148749312.0000\n",
      "Epoch 564/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 44352466944.0000 - val_loss: 42121867264.0000\n",
      "Epoch 565/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 44325728256.0000 - val_loss: 42087231488.0000\n",
      "Epoch 566/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44294504448.0000 - val_loss: 42072530944.0000\n",
      "Epoch 567/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44268531712.0000 - val_loss: 42046255104.0000\n",
      "Epoch 568/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 44238102528.0000 - val_loss: 42014945280.0000\n",
      "Epoch 569/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 44214415360.0000 - val_loss: 41988771840.0000\n",
      "Epoch 570/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 44191719424.0000 - val_loss: 41965289472.0000\n",
      "Epoch 571/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 44162609152.0000 - val_loss: 41957777408.0000\n",
      "Epoch 572/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 44136161280.0000 - val_loss: 41927393280.0000\n",
      "Epoch 573/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 44112846848.0000 - val_loss: 41906933760.0000\n",
      "Epoch 574/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44086521856.0000 - val_loss: 41880272896.0000\n",
      "Epoch 575/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 44062826496.0000 - val_loss: 41862520832.0000\n",
      "Epoch 576/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 44039376896.0000 - val_loss: 41833390080.0000\n",
      "Epoch 577/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 44015087616.0000 - val_loss: 41814110208.0000\n",
      "Epoch 578/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43991339008.0000 - val_loss: 41798049792.0000\n",
      "Epoch 579/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43967717376.0000 - val_loss: 41773641728.0000\n",
      "Epoch 580/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 43944308736.0000 - val_loss: 41760100352.0000\n",
      "Epoch 581/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43921842176.0000 - val_loss: 41737695232.0000\n",
      "Epoch 582/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43898023936.0000 - val_loss: 41719271424.0000\n",
      "Epoch 583/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 729us/step - loss: 43876077568.0000 - val_loss: 41694085120.0000\n",
      "Epoch 584/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43853176832.0000 - val_loss: 41676083200.0000\n",
      "Epoch 585/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 43831963648.0000 - val_loss: 41665294336.0000\n",
      "Epoch 586/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43806052352.0000 - val_loss: 41639526400.0000\n",
      "Epoch 587/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43789832192.0000 - val_loss: 41614475264.0000\n",
      "Epoch 588/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 43762798592.0000 - val_loss: 41593393152.0000\n",
      "Epoch 589/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43739504640.0000 - val_loss: 41578065920.0000\n",
      "Epoch 590/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43715723264.0000 - val_loss: 41551196160.0000\n",
      "Epoch 591/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43692433408.0000 - val_loss: 41535549440.0000\n",
      "Epoch 592/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43673284608.0000 - val_loss: 41516032000.0000\n",
      "Epoch 593/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 43653574656.0000 - val_loss: 41491292160.0000\n",
      "Epoch 594/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43626496000.0000 - val_loss: 41471389696.0000\n",
      "Epoch 595/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43608236032.0000 - val_loss: 41450106880.0000\n",
      "Epoch 596/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43581923328.0000 - val_loss: 41434877952.0000\n",
      "Epoch 597/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43557277696.0000 - val_loss: 41416830976.0000\n",
      "Epoch 598/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43537186816.0000 - val_loss: 41395515392.0000\n",
      "Epoch 599/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43515244544.0000 - val_loss: 41384656896.0000\n",
      "Epoch 600/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 43486666752.0000 - val_loss: 41349496832.0000\n",
      "Epoch 601/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43462594560.0000 - val_loss: 41332391936.0000\n",
      "Epoch 602/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43437068288.0000 - val_loss: 41308327936.0000\n",
      "Epoch 603/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 43417571328.0000 - val_loss: 41287278592.0000\n",
      "Epoch 604/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43388010496.0000 - val_loss: 41266581504.0000\n",
      "Epoch 605/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43364569088.0000 - val_loss: 41254141952.0000\n",
      "Epoch 606/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43339403264.0000 - val_loss: 41232416768.0000\n",
      "Epoch 607/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 43317858304.0000 - val_loss: 41208451072.0000\n",
      "Epoch 608/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43289632768.0000 - val_loss: 41184100352.0000\n",
      "Epoch 609/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43263619072.0000 - val_loss: 41156599808.0000\n",
      "Epoch 610/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 43242278912.0000 - val_loss: 41129820160.0000\n",
      "Epoch 611/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43213922304.0000 - val_loss: 41114501120.0000\n",
      "Epoch 612/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 43185618944.0000 - val_loss: 41092751360.0000\n",
      "Epoch 613/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43157524480.0000 - val_loss: 41067454464.0000\n",
      "Epoch 614/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 43131195392.0000 - val_loss: 41048203264.0000\n",
      "Epoch 615/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43106078720.0000 - val_loss: 41019809792.0000\n",
      "Epoch 616/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43076923392.0000 - val_loss: 40994533376.0000\n",
      "Epoch 617/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 43053957120.0000 - val_loss: 40962637824.0000\n",
      "Epoch 618/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 43035873280.0000 - val_loss: 40951541760.0000\n",
      "Epoch 619/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 42996105216.0000 - val_loss: 40917721088.0000\n",
      "Epoch 620/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 42966183936.0000 - val_loss: 40897703936.0000\n",
      "Epoch 621/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 42940268544.0000 - val_loss: 40869298176.0000\n",
      "Epoch 622/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42910347264.0000 - val_loss: 40844091392.0000\n",
      "Epoch 623/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 42882019328.0000 - val_loss: 40821534720.0000\n",
      "Epoch 624/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42856075264.0000 - val_loss: 40792571904.0000\n",
      "Epoch 625/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 42825101312.0000 - val_loss: 40773079040.0000\n",
      "Epoch 626/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42796310528.0000 - val_loss: 40744906752.0000\n",
      "Epoch 627/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42764558336.0000 - val_loss: 40721076224.0000\n",
      "Epoch 628/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 42735443968.0000 - val_loss: 40701997056.0000\n",
      "Epoch 629/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42709491712.0000 - val_loss: 40668643328.0000\n",
      "Epoch 630/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42676547584.0000 - val_loss: 40647102464.0000\n",
      "Epoch 631/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 42646814720.0000 - val_loss: 40618348544.0000\n",
      "Epoch 632/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 42617966592.0000 - val_loss: 40589328384.0000\n",
      "Epoch 633/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 42590879744.0000 - val_loss: 40568033280.0000\n",
      "Epoch 634/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 42562985984.0000 - val_loss: 40543256576.0000\n",
      "Epoch 635/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 42527502336.0000 - val_loss: 40513011712.0000\n",
      "Epoch 636/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 42498654208.0000 - val_loss: 40493776896.0000\n",
      "Epoch 637/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 42474528768.0000 - val_loss: 40470110208.0000\n",
      "Epoch 638/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 42448244736.0000 - val_loss: 40451321856.0000\n",
      "Epoch 639/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42417340416.0000 - val_loss: 40419045376.0000\n",
      "Epoch 640/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42385117184.0000 - val_loss: 40394862592.0000\n",
      "Epoch 641/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42354798592.0000 - val_loss: 40371990528.0000\n",
      "Epoch 642/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 42331344896.0000 - val_loss: 40341323776.0000\n",
      "Epoch 643/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 42298245120.0000 - val_loss: 40321482752.0000\n",
      "Epoch 644/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 42269765632.0000 - val_loss: 40295329792.0000\n",
      "Epoch 645/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 42240139264.0000 - val_loss: 40278523904.0000\n",
      "Epoch 646/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 42212990976.0000 - val_loss: 40250331136.0000\n",
      "Epoch 647/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42188148736.0000 - val_loss: 40230322176.0000\n",
      "Epoch 648/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 755us/step - loss: 42156535808.0000 - val_loss: 40206815232.0000\n",
      "Epoch 649/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 42128560128.0000 - val_loss: 40179593216.0000\n",
      "Epoch 650/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42102784000.0000 - val_loss: 40150921216.0000\n",
      "Epoch 651/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 42077548544.0000 - val_loss: 40138362880.0000\n",
      "Epoch 652/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 42048876544.0000 - val_loss: 40104644608.0000\n",
      "Epoch 653/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 42020552704.0000 - val_loss: 40076824576.0000\n",
      "Epoch 654/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 42003656704.0000 - val_loss: 40048406528.0000\n",
      "Epoch 655/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41968873472.0000 - val_loss: 40043053056.0000\n",
      "Epoch 656/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41940332544.0000 - val_loss: 40007905280.0000\n",
      "Epoch 657/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 41917919232.0000 - val_loss: 39981850624.0000\n",
      "Epoch 658/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 41890164736.0000 - val_loss: 39970398208.0000\n",
      "Epoch 659/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 41863770112.0000 - val_loss: 39943430144.0000\n",
      "Epoch 660/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41840062464.0000 - val_loss: 39916965888.0000\n",
      "Epoch 661/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 41811484672.0000 - val_loss: 39913328640.0000\n",
      "Epoch 662/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 41785704448.0000 - val_loss: 39880126464.0000\n",
      "Epoch 663/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41760804864.0000 - val_loss: 39864811520.0000\n",
      "Epoch 664/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41730711552.0000 - val_loss: 39830028288.0000\n",
      "Epoch 665/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41710579712.0000 - val_loss: 39804600320.0000\n",
      "Epoch 666/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41680994304.0000 - val_loss: 39792295936.0000\n",
      "Epoch 667/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 41654915072.0000 - val_loss: 39770058752.0000\n",
      "Epoch 668/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41631703040.0000 - val_loss: 39743537152.0000\n",
      "Epoch 669/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41608060928.0000 - val_loss: 39714770944.0000\n",
      "Epoch 670/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 41581838336.0000 - val_loss: 39700320256.0000\n",
      "Epoch 671/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 41556246528.0000 - val_loss: 39678865408.0000\n",
      "Epoch 672/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41530261504.0000 - val_loss: 39652601856.0000\n",
      "Epoch 673/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41506160640.0000 - val_loss: 39646650368.0000\n",
      "Epoch 674/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41483644928.0000 - val_loss: 39623204864.0000\n",
      "Epoch 675/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41455804416.0000 - val_loss: 39597453312.0000\n",
      "Epoch 676/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41435672576.0000 - val_loss: 39567441920.0000\n",
      "Epoch 677/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41406586880.0000 - val_loss: 39556829184.0000\n",
      "Epoch 678/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41386356736.0000 - val_loss: 39532789760.0000\n",
      "Epoch 679/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 41363939328.0000 - val_loss: 39511818240.0000\n",
      "Epoch 680/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41336000512.0000 - val_loss: 39494639616.0000\n",
      "Epoch 681/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41312006144.0000 - val_loss: 39480991744.0000\n",
      "Epoch 682/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41288089600.0000 - val_loss: 39455178752.0000\n",
      "Epoch 683/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41265258496.0000 - val_loss: 39437987840.0000\n",
      "Epoch 684/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 41247096832.0000 - val_loss: 39416455168.0000\n",
      "Epoch 685/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 41220399104.0000 - val_loss: 39393607680.0000\n",
      "Epoch 686/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41200533504.0000 - val_loss: 39383748608.0000\n",
      "Epoch 687/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41183535104.0000 - val_loss: 39360073728.0000\n",
      "Epoch 688/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41157808128.0000 - val_loss: 39341088768.0000\n",
      "Epoch 689/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 41139978240.0000 - val_loss: 39327490048.0000\n",
      "Epoch 690/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 41115066368.0000 - val_loss: 39308906496.0000\n",
      "Epoch 691/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41091878912.0000 - val_loss: 39295066112.0000\n",
      "Epoch 692/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41072271360.0000 - val_loss: 39272247296.0000\n",
      "Epoch 693/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 41054732288.0000 - val_loss: 39256846336.0000\n",
      "Epoch 694/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 41032179712.0000 - val_loss: 39245643776.0000\n",
      "Epoch 695/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 41006858240.0000 - val_loss: 39219970048.0000\n",
      "Epoch 696/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40991752192.0000 - val_loss: 39201103872.0000\n",
      "Epoch 697/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40966639616.0000 - val_loss: 39192776704.0000\n",
      "Epoch 698/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40950919168.0000 - val_loss: 39165698048.0000\n",
      "Epoch 699/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 40933404672.0000 - val_loss: 39152144384.0000\n",
      "Epoch 700/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 40909168640.0000 - val_loss: 39144607744.0000\n",
      "Epoch 701/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 40889892864.0000 - val_loss: 39121010688.0000\n",
      "Epoch 702/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 40874278912.0000 - val_loss: 39120703488.0000\n",
      "Epoch 703/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40861106176.0000 - val_loss: 39102373888.0000\n",
      "Epoch 704/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40834596864.0000 - val_loss: 39077289984.0000\n",
      "Epoch 705/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 40815984640.0000 - val_loss: 39066656768.0000\n",
      "Epoch 706/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40798519296.0000 - val_loss: 39043510272.0000\n",
      "Epoch 707/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 40782049280.0000 - val_loss: 39031402496.0000\n",
      "Epoch 708/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40763072512.0000 - val_loss: 39016685568.0000\n",
      "Epoch 709/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40745189376.0000 - val_loss: 39002304512.0000\n",
      "Epoch 710/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40731701248.0000 - val_loss: 38985543680.0000\n",
      "Epoch 711/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40711294976.0000 - val_loss: 38973693952.0000\n",
      "Epoch 712/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40692252672.0000 - val_loss: 38965551104.0000\n",
      "Epoch 713/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 738us/step - loss: 40677769216.0000 - val_loss: 38954098688.0000\n",
      "Epoch 714/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40662032384.0000 - val_loss: 38939009024.0000\n",
      "Epoch 715/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40644734976.0000 - val_loss: 38929051648.0000\n",
      "Epoch 716/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40626057216.0000 - val_loss: 38913703936.0000\n",
      "Epoch 717/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40610869248.0000 - val_loss: 38896762880.0000\n",
      "Epoch 718/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40591990784.0000 - val_loss: 38887886848.0000\n",
      "Epoch 719/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40575528960.0000 - val_loss: 38869229568.0000\n",
      "Epoch 720/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40558030848.0000 - val_loss: 38854193152.0000\n",
      "Epoch 721/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40542556160.0000 - val_loss: 38841839616.0000\n",
      "Epoch 722/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40526888960.0000 - val_loss: 38819799040.0000\n",
      "Epoch 723/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40516304896.0000 - val_loss: 38813937664.0000\n",
      "Epoch 724/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40497045504.0000 - val_loss: 38798786560.0000\n",
      "Epoch 725/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40483921920.0000 - val_loss: 38788911104.0000\n",
      "Epoch 726/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40471945216.0000 - val_loss: 38779695104.0000\n",
      "Epoch 727/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40450088960.0000 - val_loss: 38769893376.0000\n",
      "Epoch 728/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40434274304.0000 - val_loss: 38751846400.0000\n",
      "Epoch 729/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 40419160064.0000 - val_loss: 38740865024.0000\n",
      "Epoch 730/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40403361792.0000 - val_loss: 38727196672.0000\n",
      "Epoch 731/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40388444160.0000 - val_loss: 38716358656.0000\n",
      "Epoch 732/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40376107008.0000 - val_loss: 38704988160.0000\n",
      "Epoch 733/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40360296448.0000 - val_loss: 38691647488.0000\n",
      "Epoch 734/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40348221440.0000 - val_loss: 38680928256.0000\n",
      "Epoch 735/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40330588160.0000 - val_loss: 38659182592.0000\n",
      "Epoch 736/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 40312832000.0000 - val_loss: 38654693376.0000\n",
      "Epoch 737/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40296517632.0000 - val_loss: 38644563968.0000\n",
      "Epoch 738/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40281464832.0000 - val_loss: 38629748736.0000\n",
      "Epoch 739/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40268316672.0000 - val_loss: 38612955136.0000\n",
      "Epoch 740/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40251834368.0000 - val_loss: 38605664256.0000\n",
      "Epoch 741/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 40238448640.0000 - val_loss: 38594117632.0000\n",
      "Epoch 742/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40222597120.0000 - val_loss: 38577942528.0000\n",
      "Epoch 743/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40208187392.0000 - val_loss: 38566965248.0000\n",
      "Epoch 744/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40191803392.0000 - val_loss: 38547156992.0000\n",
      "Epoch 745/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40178905088.0000 - val_loss: 38539194368.0000\n",
      "Epoch 746/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40162832384.0000 - val_loss: 38527148032.0000\n",
      "Epoch 747/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40148828160.0000 - val_loss: 38523031552.0000\n",
      "Epoch 748/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40132755456.0000 - val_loss: 38513885184.0000\n",
      "Epoch 749/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 40117493760.0000 - val_loss: 38496313344.0000\n",
      "Epoch 750/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 40101765120.0000 - val_loss: 38484254720.0000\n",
      "Epoch 751/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40089661440.0000 - val_loss: 38477979648.0000\n",
      "Epoch 752/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 40081477632.0000 - val_loss: 38459015168.0000\n",
      "Epoch 753/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 40065540096.0000 - val_loss: 38449668096.0000\n",
      "Epoch 754/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 40042975232.0000 - val_loss: 38432309248.0000\n",
      "Epoch 755/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40029835264.0000 - val_loss: 38424829952.0000\n",
      "Epoch 756/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 40014331904.0000 - val_loss: 38408261632.0000\n",
      "Epoch 757/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39997227008.0000 - val_loss: 38405554176.0000\n",
      "Epoch 758/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39986102272.0000 - val_loss: 38394257408.0000\n",
      "Epoch 759/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39970697216.0000 - val_loss: 38377598976.0000\n",
      "Epoch 760/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39955542016.0000 - val_loss: 38358945792.0000\n",
      "Epoch 761/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39938056192.0000 - val_loss: 38352715776.0000\n",
      "Epoch 762/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39923290112.0000 - val_loss: 38340313088.0000\n",
      "Epoch 763/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39909838848.0000 - val_loss: 38319046656.0000\n",
      "Epoch 764/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 39892234240.0000 - val_loss: 38319357952.0000\n",
      "Epoch 765/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 39875362816.0000 - val_loss: 38301372416.0000\n",
      "Epoch 766/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 39861645312.0000 - val_loss: 38291963904.0000\n",
      "Epoch 767/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39846211584.0000 - val_loss: 38273265664.0000\n",
      "Epoch 768/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 39833538560.0000 - val_loss: 38263255040.0000\n",
      "Epoch 769/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39817711616.0000 - val_loss: 38257803264.0000\n",
      "Epoch 770/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39804428288.0000 - val_loss: 38243422208.0000\n",
      "Epoch 771/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39790952448.0000 - val_loss: 38229020672.0000\n",
      "Epoch 772/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39774392320.0000 - val_loss: 38221742080.0000\n",
      "Epoch 773/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 39756570624.0000 - val_loss: 38210523136.0000\n",
      "Epoch 774/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 39739699200.0000 - val_loss: 38196871168.0000\n",
      "Epoch 775/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39721254912.0000 - val_loss: 38185308160.0000\n",
      "Epoch 776/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 39714328576.0000 - val_loss: 38163664896.0000\n",
      "Epoch 777/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39692693504.0000 - val_loss: 38158249984.0000\n",
      "Epoch 778/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 738us/step - loss: 39679524864.0000 - val_loss: 38146486272.0000\n",
      "Epoch 779/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39660191744.0000 - val_loss: 38135943168.0000\n",
      "Epoch 780/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39646769152.0000 - val_loss: 38119948288.0000\n",
      "Epoch 781/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39634112512.0000 - val_loss: 38104326144.0000\n",
      "Epoch 782/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 39614537728.0000 - val_loss: 38099275776.0000\n",
      "Epoch 783/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39598002176.0000 - val_loss: 38089285632.0000\n",
      "Epoch 784/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39583854592.0000 - val_loss: 38063505408.0000\n",
      "Epoch 785/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39575810048.0000 - val_loss: 38050533376.0000\n",
      "Epoch 786/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39551946752.0000 - val_loss: 38040662016.0000\n",
      "Epoch 787/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39534325760.0000 - val_loss: 38028603392.0000\n",
      "Epoch 788/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39518121984.0000 - val_loss: 38015524864.0000\n",
      "Epoch 789/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 39502983168.0000 - val_loss: 38000058368.0000\n",
      "Epoch 790/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39490437120.0000 - val_loss: 37991690240.0000\n",
      "Epoch 791/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39470133248.0000 - val_loss: 37976231936.0000\n",
      "Epoch 792/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39458074624.0000 - val_loss: 37967888384.0000\n",
      "Epoch 793/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 39442137088.0000 - val_loss: 37951062016.0000\n",
      "Epoch 794/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39429210112.0000 - val_loss: 37943705600.0000\n",
      "Epoch 795/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 39415746560.0000 - val_loss: 37927403520.0000\n",
      "Epoch 796/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39396184064.0000 - val_loss: 37919514624.0000\n",
      "Epoch 797/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39380549632.0000 - val_loss: 37909430272.0000\n",
      "Epoch 798/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 39363149824.0000 - val_loss: 37899583488.0000\n",
      "Epoch 799/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39351095296.0000 - val_loss: 37891911680.0000\n",
      "Epoch 800/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39337811968.0000 - val_loss: 37880774656.0000\n",
      "Epoch 801/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39321550848.0000 - val_loss: 37868466176.0000\n",
      "Epoch 802/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39309869056.0000 - val_loss: 37860548608.0000\n",
      "Epoch 803/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39293571072.0000 - val_loss: 37846978560.0000\n",
      "Epoch 804/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39280181248.0000 - val_loss: 37836357632.0000\n",
      "Epoch 805/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39266508800.0000 - val_loss: 37817827328.0000\n",
      "Epoch 806/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39252840448.0000 - val_loss: 37807955968.0000\n",
      "Epoch 807/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39237746688.0000 - val_loss: 37816061952.0000\n",
      "Epoch 808/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39224823808.0000 - val_loss: 37794271232.0000\n",
      "Epoch 809/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39209283584.0000 - val_loss: 37775843328.0000\n",
      "Epoch 810/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39198011392.0000 - val_loss: 37769187328.0000\n",
      "Epoch 811/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39181180928.0000 - val_loss: 37758726144.0000\n",
      "Epoch 812/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39170654208.0000 - val_loss: 37746728960.0000\n",
      "Epoch 813/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39154249728.0000 - val_loss: 37735952384.0000\n",
      "Epoch 814/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39142580224.0000 - val_loss: 37728317440.0000\n",
      "Epoch 815/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39128952832.0000 - val_loss: 37709991936.0000\n",
      "Epoch 816/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39115653120.0000 - val_loss: 37713174528.0000\n",
      "Epoch 817/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39103815680.0000 - val_loss: 37701709824.0000\n",
      "Epoch 818/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39088234496.0000 - val_loss: 37690925056.0000\n",
      "Epoch 819/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 39077134336.0000 - val_loss: 37679591424.0000\n",
      "Epoch 820/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39066972160.0000 - val_loss: 37676957696.0000\n",
      "Epoch 821/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39052689408.0000 - val_loss: 37661782016.0000\n",
      "Epoch 822/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39039012864.0000 - val_loss: 37652512768.0000\n",
      "Epoch 823/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39030009856.0000 - val_loss: 37653020672.0000\n",
      "Epoch 824/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 39017123840.0000 - val_loss: 37646761984.0000\n",
      "Epoch 825/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 39011958784.0000 - val_loss: 37624098816.0000\n",
      "Epoch 826/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38992089088.0000 - val_loss: 37620539392.0000\n",
      "Epoch 827/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38983229440.0000 - val_loss: 37610475520.0000\n",
      "Epoch 828/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38968627200.0000 - val_loss: 37606289408.0000\n",
      "Epoch 829/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38958419968.0000 - val_loss: 37599166464.0000\n",
      "Epoch 830/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 38948036608.0000 - val_loss: 37586903040.0000\n",
      "Epoch 831/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 38937157632.0000 - val_loss: 37579984896.0000\n",
      "Epoch 832/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38925545472.0000 - val_loss: 37568593920.0000\n",
      "Epoch 833/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38913613824.0000 - val_loss: 37554831360.0000\n",
      "Epoch 834/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 38900969472.0000 - val_loss: 37549195264.0000\n",
      "Epoch 835/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 38893551616.0000 - val_loss: 37545435136.0000\n",
      "Epoch 836/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38883790848.0000 - val_loss: 37533089792.0000\n",
      "Epoch 837/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38872854528.0000 - val_loss: 37524004864.0000\n",
      "Epoch 838/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38860738560.0000 - val_loss: 37517176832.0000\n",
      "Epoch 839/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38844747776.0000 - val_loss: 37520347136.0000\n",
      "Epoch 840/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 38837829632.0000 - val_loss: 37508083712.0000\n",
      "Epoch 841/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 38828412928.0000 - val_loss: 37498793984.0000\n",
      "Epoch 842/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38814158848.0000 - val_loss: 37485711360.0000\n",
      "Epoch 843/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 738us/step - loss: 38808657920.0000 - val_loss: 37483102208.0000\n",
      "Epoch 844/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38795939840.0000 - val_loss: 37470371840.0000\n",
      "Epoch 845/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38786981888.0000 - val_loss: 37469954048.0000\n",
      "Epoch 846/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 38773862400.0000 - val_loss: 37456969728.0000\n",
      "Epoch 847/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38760312832.0000 - val_loss: 37451091968.0000\n",
      "Epoch 848/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38755385344.0000 - val_loss: 37447491584.0000\n",
      "Epoch 849/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38748258304.0000 - val_loss: 37435207680.0000\n",
      "Epoch 850/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38734938112.0000 - val_loss: 37431037952.0000\n",
      "Epoch 851/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38723260416.0000 - val_loss: 37415473152.0000\n",
      "Epoch 852/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38712295424.0000 - val_loss: 37423960064.0000\n",
      "Epoch 853/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38700609536.0000 - val_loss: 37413232640.0000\n",
      "Epoch 854/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38692831232.0000 - val_loss: 37407596544.0000\n",
      "Epoch 855/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38685138944.0000 - val_loss: 37394894848.0000\n",
      "Epoch 856/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38673547264.0000 - val_loss: 37394358272.0000\n",
      "Epoch 857/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38662066176.0000 - val_loss: 37379391488.0000\n",
      "Epoch 858/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38649368576.0000 - val_loss: 37374103552.0000\n",
      "Epoch 859/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38645055488.0000 - val_loss: 37369618432.0000\n",
      "Epoch 860/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38634164224.0000 - val_loss: 37364776960.0000\n",
      "Epoch 861/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38626504704.0000 - val_loss: 37355376640.0000\n",
      "Epoch 862/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38612967424.0000 - val_loss: 37350117376.0000\n",
      "Epoch 863/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 38603345920.0000 - val_loss: 37336109056.0000\n",
      "Epoch 864/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38594052096.0000 - val_loss: 37335023616.0000\n",
      "Epoch 865/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38587572224.0000 - val_loss: 37331591168.0000\n",
      "Epoch 866/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38576091136.0000 - val_loss: 37324906496.0000\n",
      "Epoch 867/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38565814272.0000 - val_loss: 37321859072.0000\n",
      "Epoch 868/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38556422144.0000 - val_loss: 37305561088.0000\n",
      "Epoch 869/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38549295104.0000 - val_loss: 37302697984.0000\n",
      "Epoch 870/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38540582912.0000 - val_loss: 37295280128.0000\n",
      "Epoch 871/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38531895296.0000 - val_loss: 37299449856.0000\n",
      "Epoch 872/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 38522007552.0000 - val_loss: 37286535168.0000\n",
      "Epoch 873/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38514814976.0000 - val_loss: 37280362496.0000\n",
      "Epoch 874/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38504579072.0000 - val_loss: 37271683072.0000\n",
      "Epoch 875/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38495191040.0000 - val_loss: 37264777216.0000\n",
      "Epoch 876/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38486757376.0000 - val_loss: 37259087872.0000\n",
      "Epoch 877/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38482010112.0000 - val_loss: 37256663040.0000\n",
      "Epoch 878/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38470029312.0000 - val_loss: 37250027520.0000\n",
      "Epoch 879/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38463680512.0000 - val_loss: 37248020480.0000\n",
      "Epoch 880/1000\n",
      "114/114 [==============================] - 0s 737us/step - loss: 38454972416.0000 - val_loss: 37229158400.0000\n",
      "Epoch 881/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38451171328.0000 - val_loss: 37220163584.0000\n",
      "Epoch 882/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38440570880.0000 - val_loss: 37229285376.0000\n",
      "Epoch 883/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38430679040.0000 - val_loss: 37214228480.0000\n",
      "Epoch 884/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38424588288.0000 - val_loss: 37211000832.0000\n",
      "Epoch 885/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38412128256.0000 - val_loss: 37209448448.0000\n",
      "Epoch 886/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38407520256.0000 - val_loss: 37211623424.0000\n",
      "Epoch 887/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38395162624.0000 - val_loss: 37203652608.0000\n",
      "Epoch 888/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38388752384.0000 - val_loss: 37195927552.0000\n",
      "Epoch 889/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38379520000.0000 - val_loss: 37190266880.0000\n",
      "Epoch 890/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38375428096.0000 - val_loss: 37190475776.0000\n",
      "Epoch 891/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38364176384.0000 - val_loss: 37178077184.0000\n",
      "Epoch 892/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38356127744.0000 - val_loss: 37169254400.0000\n",
      "Epoch 893/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38353063936.0000 - val_loss: 37171453952.0000\n",
      "Epoch 894/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38341042176.0000 - val_loss: 37159231488.0000\n",
      "Epoch 895/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38336987136.0000 - val_loss: 37150044160.0000\n",
      "Epoch 896/1000\n",
      "114/114 [==============================] - 0s 799us/step - loss: 38329548800.0000 - val_loss: 37151510528.0000\n",
      "Epoch 897/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 38316949504.0000 - val_loss: 37149839360.0000\n",
      "Epoch 898/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38306508800.0000 - val_loss: 37125390336.0000\n",
      "Epoch 899/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38304550912.0000 - val_loss: 37133201408.0000\n",
      "Epoch 900/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38294462464.0000 - val_loss: 37127917568.0000\n",
      "Epoch 901/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38287605760.0000 - val_loss: 37112594432.0000\n",
      "Epoch 902/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38280921088.0000 - val_loss: 37118332928.0000\n",
      "Epoch 903/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38269239296.0000 - val_loss: 37103292416.0000\n",
      "Epoch 904/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38262607872.0000 - val_loss: 37100228608.0000\n",
      "Epoch 905/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38254620672.0000 - val_loss: 37097459712.0000\n",
      "Epoch 906/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38243704832.0000 - val_loss: 37093478400.0000\n",
      "Epoch 907/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 38241804288.0000 - val_loss: 37079867392.0000\n",
      "Epoch 908/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 738us/step - loss: 38232117248.0000 - val_loss: 37074124800.0000\n",
      "Epoch 909/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 38222942208.0000 - val_loss: 37070225408.0000\n",
      "Epoch 910/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 38213517312.0000 - val_loss: 37064876032.0000\n",
      "Epoch 911/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38207377408.0000 - val_loss: 37061808128.0000\n",
      "Epoch 912/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38198685696.0000 - val_loss: 37053059072.0000\n",
      "Epoch 913/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38192414720.0000 - val_loss: 37048623104.0000\n",
      "Epoch 914/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38184919040.0000 - val_loss: 37040549888.0000\n",
      "Epoch 915/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38180560896.0000 - val_loss: 37034176512.0000\n",
      "Epoch 916/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38173179904.0000 - val_loss: 37029605376.0000\n",
      "Epoch 917/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38163664896.0000 - val_loss: 37017501696.0000\n",
      "Epoch 918/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38159446016.0000 - val_loss: 37007577088.0000\n",
      "Epoch 919/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38151499776.0000 - val_loss: 37004750848.0000\n",
      "Epoch 920/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38139027456.0000 - val_loss: 37005422592.0000\n",
      "Epoch 921/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38138347520.0000 - val_loss: 37014405120.0000\n",
      "Epoch 922/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38126882816.0000 - val_loss: 36996636672.0000\n",
      "Epoch 923/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38120513536.0000 - val_loss: 36994011136.0000\n",
      "Epoch 924/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38111948800.0000 - val_loss: 36987850752.0000\n",
      "Epoch 925/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 38106116096.0000 - val_loss: 36984225792.0000\n",
      "Epoch 926/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38097838080.0000 - val_loss: 36979920896.0000\n",
      "Epoch 927/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38086959104.0000 - val_loss: 36972089344.0000\n",
      "Epoch 928/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38082088960.0000 - val_loss: 36962025472.0000\n",
      "Epoch 929/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38073454592.0000 - val_loss: 36958330880.0000\n",
      "Epoch 930/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38067011584.0000 - val_loss: 36957011968.0000\n",
      "Epoch 931/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38059937792.0000 - val_loss: 36952498176.0000\n",
      "Epoch 932/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38055653376.0000 - val_loss: 36941148160.0000\n",
      "Epoch 933/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38046076928.0000 - val_loss: 36940226560.0000\n",
      "Epoch 934/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38039822336.0000 - val_loss: 36931891200.0000\n",
      "Epoch 935/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38033833984.0000 - val_loss: 36933410816.0000\n",
      "Epoch 936/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 38025793536.0000 - val_loss: 36925321216.0000\n",
      "Epoch 937/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 38021550080.0000 - val_loss: 36920434688.0000\n",
      "Epoch 938/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 38012182528.0000 - val_loss: 36908830720.0000\n",
      "Epoch 939/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 38004199424.0000 - val_loss: 36912992256.0000\n",
      "Epoch 940/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37998379008.0000 - val_loss: 36897480704.0000\n",
      "Epoch 941/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37993381888.0000 - val_loss: 36904947712.0000\n",
      "Epoch 942/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 37991718912.0000 - val_loss: 36892045312.0000\n",
      "Epoch 943/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37977284608.0000 - val_loss: 36889735168.0000\n",
      "Epoch 944/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37968580608.0000 - val_loss: 36888195072.0000\n",
      "Epoch 945/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37959716864.0000 - val_loss: 36880121856.0000\n",
      "Epoch 946/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37956988928.0000 - val_loss: 36871819264.0000\n",
      "Epoch 947/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37953368064.0000 - val_loss: 36865335296.0000\n",
      "Epoch 948/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37942558720.0000 - val_loss: 36868161536.0000\n",
      "Epoch 949/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37934235648.0000 - val_loss: 36853956608.0000\n",
      "Epoch 950/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37930033152.0000 - val_loss: 36859371520.0000\n",
      "Epoch 951/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37927837696.0000 - val_loss: 36848091136.0000\n",
      "Epoch 952/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37921857536.0000 - val_loss: 36842803200.0000\n",
      "Epoch 953/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 37907316736.0000 - val_loss: 36851040256.0000\n",
      "Epoch 954/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37906579456.0000 - val_loss: 36840062976.0000\n",
      "Epoch 955/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37894553600.0000 - val_loss: 36844105728.0000\n",
      "Epoch 956/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37890097152.0000 - val_loss: 36826980352.0000\n",
      "Epoch 957/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37884129280.0000 - val_loss: 36823027712.0000\n",
      "Epoch 958/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37874905088.0000 - val_loss: 36823908352.0000\n",
      "Epoch 959/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 37865930752.0000 - val_loss: 36817653760.0000\n",
      "Epoch 960/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37864497152.0000 - val_loss: 36812017664.0000\n",
      "Epoch 961/1000\n",
      "114/114 [==============================] - 0s 790us/step - loss: 37854404608.0000 - val_loss: 36806062080.0000\n",
      "Epoch 962/1000\n",
      "114/114 [==============================] - 0s 781us/step - loss: 37850755072.0000 - val_loss: 36795441152.0000\n",
      "Epoch 963/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37842767872.0000 - val_loss: 36796006400.0000\n",
      "Epoch 964/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37836009472.0000 - val_loss: 36787351552.0000\n",
      "Epoch 965/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37829165056.0000 - val_loss: 36787793920.0000\n",
      "Epoch 966/1000\n",
      "114/114 [==============================] - 0s 764us/step - loss: 37824729088.0000 - val_loss: 36786847744.0000\n",
      "Epoch 967/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37817434112.0000 - val_loss: 36761481216.0000\n",
      "Epoch 968/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37812330496.0000 - val_loss: 36773244928.0000\n",
      "Epoch 969/1000\n",
      "114/114 [==============================] - 0s 755us/step - loss: 37805273088.0000 - val_loss: 36768182272.0000\n",
      "Epoch 970/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37798338560.0000 - val_loss: 36766117888.0000\n",
      "Epoch 971/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37790896128.0000 - val_loss: 36758196224.0000\n",
      "Epoch 972/1000\n",
      "114/114 [==============================] - 0s 773us/step - loss: 37788971008.0000 - val_loss: 36757016576.0000\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 729us/step - loss: 37779443712.0000 - val_loss: 36752121856.0000\n",
      "Epoch 974/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37773275136.0000 - val_loss: 36746870784.0000\n",
      "Epoch 975/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37766676480.0000 - val_loss: 36737028096.0000\n",
      "Epoch 976/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37758672896.0000 - val_loss: 36731478016.0000\n",
      "Epoch 977/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37756895232.0000 - val_loss: 36727488512.0000\n",
      "Epoch 978/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37748518912.0000 - val_loss: 36725256192.0000\n",
      "Epoch 979/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37738020864.0000 - val_loss: 36719022080.0000\n",
      "Epoch 980/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37733191680.0000 - val_loss: 36711747584.0000\n",
      "Epoch 981/1000\n",
      "114/114 [==============================] - 0s 720us/step - loss: 37729144832.0000 - val_loss: 36705742848.0000\n",
      "Epoch 982/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37720723456.0000 - val_loss: 36706816000.0000\n",
      "Epoch 983/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 37715427328.0000 - val_loss: 36700262400.0000\n",
      "Epoch 984/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37708156928.0000 - val_loss: 36701097984.0000\n",
      "Epoch 985/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37714862080.0000 - val_loss: 36695994368.0000\n",
      "Epoch 986/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37694132224.0000 - val_loss: 36691533824.0000\n",
      "Epoch 987/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37688397824.0000 - val_loss: 36689358848.0000\n",
      "Epoch 988/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37684899840.0000 - val_loss: 36670963712.0000\n",
      "Epoch 989/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37677789184.0000 - val_loss: 36677836800.0000\n",
      "Epoch 990/1000\n",
      "114/114 [==============================] - 0s 746us/step - loss: 37673394176.0000 - val_loss: 36671389696.0000\n",
      "Epoch 991/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37662728192.0000 - val_loss: 36661387264.0000\n",
      "Epoch 992/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37659598848.0000 - val_loss: 36651560960.0000\n",
      "Epoch 993/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37653237760.0000 - val_loss: 36644851712.0000\n",
      "Epoch 994/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37646163968.0000 - val_loss: 36651548672.0000\n",
      "Epoch 995/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37645860864.0000 - val_loss: 36658774016.0000\n",
      "Epoch 996/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37644857344.0000 - val_loss: 36647407616.0000\n",
      "Epoch 997/1000\n",
      "114/114 [==============================] - 0s 711us/step - loss: 37630337024.0000 - val_loss: 36630974464.0000\n",
      "Epoch 998/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37623492608.0000 - val_loss: 36629159936.0000\n",
      "Epoch 999/1000\n",
      "114/114 [==============================] - 0s 729us/step - loss: 37617692672.0000 - val_loss: 36631408640.0000\n",
      "Epoch 1000/1000\n",
      "114/114 [==============================] - 0s 738us/step - loss: 37612916736.0000 - val_loss: 36624777216.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23dfbf29310>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=1000, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7070242111744418"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23dfc2d5a00>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Epoch definitely helps. But if it's too high it can cause overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since lowering the batch size will increase the time of training, we will try out increase the batch size and see the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 430357315584.0000 - val_loss: 427950637056.0000\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430356987904.0000 - val_loss: 427950276608.0000\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430356660224.0000 - val_loss: 427949850624.0000\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430356103168.0000 - val_loss: 427949228032.0000\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430355382272.0000 - val_loss: 427948507136.0000\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430354628608.0000 - val_loss: 427947556864.0000\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430353580032.0000 - val_loss: 427946344448.0000\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430352203776.0000 - val_loss: 427944771584.0000\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430350499840.0000 - val_loss: 427942871040.0000\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430348468224.0000 - val_loss: 427940511744.0000\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430345912320.0000 - val_loss: 427937759232.0000\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430342864896.0000 - val_loss: 427934416896.0000\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430339325952.0000 - val_loss: 427930484736.0000\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430335164416.0000 - val_loss: 427925995520.0000\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430330314752.0000 - val_loss: 427920687104.0000\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 430324842496.0000 - val_loss: 427914723328.0000\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 430318485504.0000 - val_loss: 427907973120.0000\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430311440384.0000 - val_loss: 427900403712.0000\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 430303444992.0000 - val_loss: 427891884032.0000\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430294532096.0000 - val_loss: 427882381312.0000\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430284636160.0000 - val_loss: 427871928320.0000\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430273691648.0000 - val_loss: 427860328448.0000\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 430261764096.0000 - val_loss: 427847614464.0000\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430248460288.0000 - val_loss: 427833491456.0000\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 430233681920.0000 - val_loss: 427817697280.0000\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 430217166848.0000 - val_loss: 427800166400.0000\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430198915072.0000 - val_loss: 427780964352.0000\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430179123200.0000 - val_loss: 427760123904.0000\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430157660160.0000 - val_loss: 427737513984.0000\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430134329344.0000 - val_loss: 427713200128.0000\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430109229056.0000 - val_loss: 427687051264.0000\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430082326528.0000 - val_loss: 427659001856.0000\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430053621760.0000 - val_loss: 427629019136.0000\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 430022754304.0000 - val_loss: 427597168640.0000\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429990019072.0000 - val_loss: 427563155456.0000\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429955383296.0000 - val_loss: 427527077888.0000\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429918519296.0000 - val_loss: 427488903168.0000\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429879459840.0000 - val_loss: 427448270848.0000\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429837778944.0000 - val_loss: 427404918784.0000\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429793312768.0000 - val_loss: 427358846976.0000\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429746290688.0000 - val_loss: 427310186496.0000\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429696581632.0000 - val_loss: 427259265024.0000\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429644677120.0000 - val_loss: 427205165056.0000\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429589594112.0000 - val_loss: 427148705792.0000\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429532119040.0000 - val_loss: 427089330176.0000\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429471858688.0000 - val_loss: 427027333120.0000\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429408944128.0000 - val_loss: 426962583552.0000\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429343145984.0000 - val_loss: 426895179776.0000\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429274628096.0000 - val_loss: 426824695808.0000\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429203161088.0000 - val_loss: 426751655936.0000\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429129203712.0000 - val_loss: 426675601408.0000\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 429051904000.0000 - val_loss: 426596466688.0000\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428971687936.0000 - val_loss: 426514382848.0000\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428888588288.0000 - val_loss: 426428956672.0000\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428802113536.0000 - val_loss: 426340614144.0000\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428712460288.0000 - val_loss: 426249289728.0000\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428620218368.0000 - val_loss: 426154393600.0000\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428524240896.0000 - val_loss: 426056220672.0000\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428424986624.0000 - val_loss: 425955262464.0000\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428322750464.0000 - val_loss: 425850929152.0000\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428217139200.0000 - val_loss: 425743187968.0000\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 428108120064.0000 - val_loss: 425632006144.0000\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427996086272.0000 - val_loss: 425517383680.0000\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427880677376.0000 - val_loss: 425399418880.0000\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427761238016.0000 - val_loss: 425278636032.0000\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427639406592.0000 - val_loss: 425153658880.0000\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427513479168.0000 - val_loss: 425025175552.0000\n",
      "Epoch 68/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 427383783424.0000 - val_loss: 424893644800.0000\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427250843648.0000 - val_loss: 424758476800.0000\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 427114659840.0000 - val_loss: 424619180032.0000\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426973986816.0000 - val_loss: 424476835840.0000\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426830561280.0000 - val_loss: 424330231808.0000\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426682908672.0000 - val_loss: 424180350976.0000\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426531946496.0000 - val_loss: 424026832896.0000\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426377183232.0000 - val_loss: 423869251584.0000\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426218586112.0000 - val_loss: 423707574272.0000\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 426055761920.0000 - val_loss: 423542456320.0000\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 425888907264.0000 - val_loss: 423374356480.0000\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 425719496704.0000 - val_loss: 423201079296.0000\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 425545596928.0000 - val_loss: 423023607808.0000\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 425367175168.0000 - val_loss: 422842597376.0000\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 425184624640.0000 - val_loss: 422658080768.0000\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424999026688.0000 - val_loss: 422469697536.0000\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424809267200.0000 - val_loss: 422276694016.0000\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424614592512.0000 - val_loss: 422080610304.0000\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424418115584.0000 - val_loss: 421879971840.0000\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424216428544.0000 - val_loss: 421675499520.0000\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 424010809344.0000 - val_loss: 421467357184.0000\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 423801323520.0000 - val_loss: 421255315456.0000\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 423587446784.0000 - val_loss: 421039079424.0000\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 423370424320.0000 - val_loss: 420817731584.0000\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 423148716032.0000 - val_loss: 420592910336.0000\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 422923337728.0000 - val_loss: 420364648448.0000\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 422693699584.0000 - val_loss: 420131504128.0000\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 422458916864.0000 - val_loss: 419894624256.0000\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 422221152256.0000 - val_loss: 419652567040.0000\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421977161728.0000 - val_loss: 419406872576.0000\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421730320384.0000 - val_loss: 419157344256.0000\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421479972864.0000 - val_loss: 418901917696.0000\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 421224087552.0000 - val_loss: 418643443712.0000\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 420964564992.0000 - val_loss: 418380578816.0000\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 420699504640.0000 - val_loss: 418114535424.0000\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 420433199104.0000 - val_loss: 417841643520.0000\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 420159062016.0000 - val_loss: 417567047680.0000\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 419883548672.0000 - val_loss: 417286488064.0000\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 419602137088.0000 - val_loss: 417003044864.0000\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 419317448704.0000 - val_loss: 416714915840.0000\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 419027681280.0000 - val_loss: 416423149568.0000\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 418734342144.0000 - val_loss: 416124534784.0000\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 418435301376.0000 - val_loss: 415822938112.0000\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 418133409792.0000 - val_loss: 415516983296.0000\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 417826439168.0000 - val_loss: 415207882752.0000\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 417515831296.0000 - val_loss: 414893080576.0000\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 417199095808.0000 - val_loss: 414573854720.0000\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 416878690304.0000 - val_loss: 414249156608.0000\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 416553435136.0000 - val_loss: 413920559104.0000\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 416224018432.0000 - val_loss: 413587275776.0000\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 415889653760.0000 - val_loss: 413248421888.0000\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 415551160320.0000 - val_loss: 412907339776.0000\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 415209160704.0000 - val_loss: 412562030592.0000\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 414863130624.0000 - val_loss: 412211511296.0000\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 414511235072.0000 - val_loss: 411856764928.0000\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 414154784768.0000 - val_loss: 411498348544.0000\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 413795811328.0000 - val_loss: 411133181952.0000\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 413429661696.0000 - val_loss: 410765262848.0000\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 413061775360.0000 - val_loss: 410390855680.0000\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 412686155776.0000 - val_loss: 410013925376.0000\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 412307685376.0000 - val_loss: 409632931840.0000\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 411926921216.0000 - val_loss: 409245253632.0000\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 411538194432.0000 - val_loss: 408855281664.0000\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 411145764864.0000 - val_loss: 408459935744.0000\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 410749861888.0000 - val_loss: 408059379712.0000\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 410350026752.0000 - val_loss: 407653974016.0000\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 409942720512.0000 - val_loss: 407245586432.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 409534857216.0000 - val_loss: 406830907392.0000\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 409120440320.0000 - val_loss: 406413574144.0000\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 408701403136.0000 - val_loss: 405992407040.0000\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 408279941120.0000 - val_loss: 405566750720.0000\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 407852941312.0000 - val_loss: 405137391616.0000\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 407421386752.0000 - val_loss: 404701773824.0000\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 406986588160.0000 - val_loss: 404261437440.0000\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 406546022400.0000 - val_loss: 403815628800.0000\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 406100115456.0000 - val_loss: 403367002112.0000\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 405649293312.0000 - val_loss: 402914574336.0000\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 405196996608.0000 - val_loss: 402456936448.0000\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 404739063808.0000 - val_loss: 401994514432.0000\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 404275298304.0000 - val_loss: 401527439360.0000\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 403807567872.0000 - val_loss: 401055907840.0000\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 403336298496.0000 - val_loss: 400580771840.0000\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 402859556864.0000 - val_loss: 400102129664.0000\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 402379767808.0000 - val_loss: 399618408448.0000\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 401895555072.0000 - val_loss: 399127478272.0000\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 401405313024.0000 - val_loss: 398633762816.0000\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 400909500416.0000 - val_loss: 398136410112.0000\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 400412082176.0000 - val_loss: 397633585152.0000\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 399911288832.0000 - val_loss: 397127024640.0000\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 399402926080.0000 - val_loss: 396617351168.0000\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 398892990464.0000 - val_loss: 396101943296.0000\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 398377484288.0000 - val_loss: 395581095936.0000\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 397855588352.0000 - val_loss: 395058675712.0000\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 397331628032.0000 - val_loss: 394529144832.0000\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 396802523136.0000 - val_loss: 393993093120.0000\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 396266962944.0000 - val_loss: 393454878720.0000\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 395728715776.0000 - val_loss: 392914599936.0000\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 395186601984.0000 - val_loss: 392368652288.0000\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 394639474688.0000 - val_loss: 391816642560.0000\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 394088972288.0000 - val_loss: 391259914240.0000\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 393532276736.0000 - val_loss: 390700990464.0000\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 392972566528.0000 - val_loss: 390135513088.0000\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 392407187456.0000 - val_loss: 389565579264.0000\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 391835942912.0000 - val_loss: 388993384448.0000\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 391261847552.0000 - val_loss: 388415586304.0000\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 390684082176.0000 - val_loss: 387832872960.0000\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 390102056960.0000 - val_loss: 387245768704.0000\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 389516984320.0000 - val_loss: 386653487104.0000\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 388925095936.0000 - val_loss: 386060124160.0000\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 388330684416.0000 - val_loss: 385462239232.0000\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 387732963328.0000 - val_loss: 384858193920.0000\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 387128852480.0000 - val_loss: 384255066112.0000\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 386523725824.0000 - val_loss: 383643353088.0000\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 385911390208.0000 - val_loss: 383028068352.0000\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 385297252352.0000 - val_loss: 382405935104.0000\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 384676265984.0000 - val_loss: 381783932928.0000\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 384054165504.0000 - val_loss: 381158424576.0000\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 383428395008.0000 - val_loss: 380526100480.0000\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 382794235904.0000 - val_loss: 379890991104.0000\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 382158929920.0000 - val_loss: 379250802688.0000\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 381520543744.0000 - val_loss: 378603929600.0000\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 380873441280.0000 - val_loss: 377955581952.0000\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 380225191936.0000 - val_loss: 377303728128.0000\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 379572322304.0000 - val_loss: 376647680000.0000\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 378916569088.0000 - val_loss: 375987011584.0000\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 378256523264.0000 - val_loss: 375322378240.0000\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 377591595008.0000 - val_loss: 374656761856.0000\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 376923881472.0000 - val_loss: 373983346688.0000\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 376255119360.0000 - val_loss: 373303836672.0000\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 375575740416.0000 - val_loss: 372627013632.0000\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 374898196480.0000 - val_loss: 371941933056.0000\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 374214590464.0000 - val_loss: 371256393728.0000\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 373528657920.0000 - val_loss: 370566299648.0000\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 372837842944.0000 - val_loss: 369870176256.0000\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 372142866432.0000 - val_loss: 369172381696.0000\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 371447627776.0000 - val_loss: 368466264064.0000\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 370740264960.0000 - val_loss: 367762178048.0000\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 370037948416.0000 - val_loss: 367052193792.0000\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 369327177728.0000 - val_loss: 366341423104.0000\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 368616931328.0000 - val_loss: 365622329344.0000\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 367898460160.0000 - val_loss: 364902645760.0000\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 348354674688.00 - 0s 2ms/step - loss: 367179988992.0000 - val_loss: 364178243584.0000\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 366456963072.0000 - val_loss: 363450433536.0000\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 365729021952.0000 - val_loss: 362720002048.0000\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 364997410816.0000 - val_loss: 361985507328.0000\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 364263014400.0000 - val_loss: 361243901952.0000\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 363522490368.0000 - val_loss: 360501051392.0000\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 362783178752.0000 - val_loss: 359753121792.0000\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 362035052544.0000 - val_loss: 359005683712.0000\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 361289547776.0000 - val_loss: 358249201664.0000\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 360532148224.0000 - val_loss: 357494456320.0000\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 359777042432.0000 - val_loss: 356732370944.0000\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 359016464384.0000 - val_loss: 355970908160.0000\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 358254051328.0000 - val_loss: 355203317760.0000\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 357489049600.0000 - val_loss: 354431172608.0000\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 356715364352.0000 - val_loss: 353658601472.0000\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 355941711872.0000 - val_loss: 352878460928.0000\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 355162357760.0000 - val_loss: 352094552064.0000\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 354381103104.0000 - val_loss: 351310577664.0000\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 353596440576.0000 - val_loss: 350525030400.0000\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 352813252608.0000 - val_loss: 349733912576.0000\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 352025411584.0000 - val_loss: 348939812864.0000\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 351230033920.0000 - val_loss: 348144959488.0000\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 350436065280.0000 - val_loss: 347345551360.0000\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 349637738496.0000 - val_loss: 346541817856.0000\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 348836823040.0000 - val_loss: 345733496832.0000\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 348032172032.0000 - val_loss: 344925863936.0000\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 347226570752.0000 - val_loss: 344115412992.0000\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 346413891584.0000 - val_loss: 343304667136.0000\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 345600393216.0000 - val_loss: 342489333760.0000\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 344785289216.0000 - val_loss: 341664006144.0000\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 343964024832.0000 - val_loss: 340838252544.0000\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 343138533376.0000 - val_loss: 340012924928.0000\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 342316449792.0000 - val_loss: 339183239168.0000\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 341489876992.0000 - val_loss: 338352144384.0000\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 340661764096.0000 - val_loss: 337516429312.0000\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 339825000448.0000 - val_loss: 336676552704.0000\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 338987319296.0000 - val_loss: 335836250112.0000\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 338147803136.0000 - val_loss: 334992146432.0000\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 337306320896.0000 - val_loss: 334145355776.0000\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 336459792384.0000 - val_loss: 333299548160.0000\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 335611265024.0000 - val_loss: 332448563200.0000\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 334759723008.0000 - val_loss: 331592990720.0000\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 333906771968.0000 - val_loss: 330732929024.0000\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 333048053760.0000 - val_loss: 329871589376.0000\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 332190056448.0000 - val_loss: 329007529984.0000\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 331327438848.0000 - val_loss: 328141340672.0000\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 330464493568.0000 - val_loss: 327270039552.0000\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 329596698624.0000 - val_loss: 326401032192.0000\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 328728838144.0000 - val_loss: 325534646272.0000\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 327862878208.0000 - val_loss: 324659118080.0000\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 326988857344.0000 - val_loss: 323784212480.0000\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 326114377728.0000 - val_loss: 322907504640.0000\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 325238226944.0000 - val_loss: 322023981056.0000\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 324354932736.0000 - val_loss: 321138556928.0000\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 323472752640.0000 - val_loss: 320253657088.0000\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 322590736384.0000 - val_loss: 319364628480.0000\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 321702494208.0000 - val_loss: 318478155776.0000\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 320818151424.0000 - val_loss: 317589618688.0000\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 319929778176.0000 - val_loss: 316697640960.0000\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 319039438848.0000 - val_loss: 315802517504.0000\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 318146379776.0000 - val_loss: 314902249472.0000\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 317247422464.0000 - val_loss: 314003292160.0000\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 316346925056.0000 - val_loss: 313099059200.0000\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 315445510144.0000 - val_loss: 312188207104.0000\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 314535837696.0000 - val_loss: 311280795648.0000\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 313630556160.0000 - val_loss: 310369583104.0000\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 312722718720.0000 - val_loss: 309454307328.0000\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 311810785280.0000 - val_loss: 308542603264.0000\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 310902751232.0000 - val_loss: 307626475520.0000\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 309990260736.0000 - val_loss: 306714836992.0000\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 309075607552.0000 - val_loss: 305798152192.0000\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 308163739648.0000 - val_loss: 304871702528.0000\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 307240108032.0000 - val_loss: 303953444864.0000\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 306325159936.0000 - val_loss: 303030894592.0000\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 305403461632.0000 - val_loss: 302107000832.0000\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 304480714752.0000 - val_loss: 301184450560.0000\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 303560163328.0000 - val_loss: 300260524032.0000\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 302641348608.0000 - val_loss: 299332960256.0000\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 301715193856.0000 - val_loss: 298407395328.0000\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 300792086528.0000 - val_loss: 297477177344.0000\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 299861475328.0000 - val_loss: 296544993280.0000\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 298930143232.0000 - val_loss: 295615397888.0000\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 298004480000.0000 - val_loss: 294676332544.0000\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 297070460928.0000 - val_loss: 293742379008.0000\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 296135065600.0000 - val_loss: 292806557696.0000\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 295203831808.0000 - val_loss: 291864215552.0000\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 294264799232.0000 - val_loss: 290922659840.0000\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 293325602816.0000 - val_loss: 289983823872.0000\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 292387291136.0000 - val_loss: 289044201472.0000\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291450159104.0000 - val_loss: 288103432192.0000\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 290510635008.0000 - val_loss: 287166660608.0000\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 289574715392.0000 - val_loss: 286220222464.0000\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 288631685120.0000 - val_loss: 285272309760.0000\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 287687180288.0000 - val_loss: 284328132608.0000\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 286745886720.0000 - val_loss: 283376943104.0000\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 285799415808.0000 - val_loss: 282426671104.0000\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 284851142656.0000 - val_loss: 281479184384.0000\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 283904212992.0000 - val_loss: 280531992576.0000\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 282957381632.0000 - val_loss: 279577624576.0000\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 282004848640.0000 - val_loss: 278628302848.0000\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 281057689600.0000 - val_loss: 277672919040.0000\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 280104304640.0000 - val_loss: 276718616576.0000\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 279153573888.0000 - val_loss: 275759693824.0000\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 278201270272.0000 - val_loss: 274807406592.0000\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 277251031040.0000 - val_loss: 273854644224.0000\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 276299251712.0000 - val_loss: 272896065536.0000\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 275342786560.0000 - val_loss: 271942467584.0000\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 274393579520.0000 - val_loss: 270987526144.0000\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 273439408128.0000 - val_loss: 270036205568.0000\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 272492511232.0000 - val_loss: 269080870912.0000\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 271538651136.0000 - val_loss: 268123734016.0000\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 270584659968.0000 - val_loss: 267160141824.0000\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 269627228160.0000 - val_loss: 266203643904.0000\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 268668485632.0000 - val_loss: 265254207488.0000\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 267723931648.0000 - val_loss: 264294694912.0000\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 266768842752.0000 - val_loss: 263337590784.0000\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 265817047040.0000 - val_loss: 262379044864.0000\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 264860958720.0000 - val_loss: 261428822016.0000\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 263911948288.0000 - val_loss: 260469981184.0000\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 262954827776.0000 - val_loss: 259518660608.0000\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 262002475008.0000 - val_loss: 258557526016.0000\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 261046812672.0000 - val_loss: 257601028096.0000\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 260091412480.0000 - val_loss: 256642039808.0000\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 259136126976.0000 - val_loss: 255687507968.0000\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 258185510912.0000 - val_loss: 254729060352.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 257230585856.0000 - val_loss: 253773578240.0000\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 256277823488.0000 - val_loss: 252816162816.0000\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 255324127232.0000 - val_loss: 251858223104.0000\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 254372577280.0000 - val_loss: 250902429696.0000\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 253419143168.0000 - val_loss: 249953812480.0000\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 252468477952.0000 - val_loss: 249004343296.0000\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 251523121152.0000 - val_loss: 248044191744.0000\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 250563395584.0000 - val_loss: 247090675712.0000\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 249615138816.0000 - val_loss: 246134325248.0000\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 248662818816.0000 - val_loss: 245181038592.0000\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 247712481280.0000 - val_loss: 244231340032.0000\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 246762962944.0000 - val_loss: 243278610432.0000\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 245815443456.0000 - val_loss: 242325274624.0000\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 244865777664.0000 - val_loss: 241380573184.0000\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 243924271104.0000 - val_loss: 240427843584.0000\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 242975637504.0000 - val_loss: 239479390208.0000\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 242031083520.0000 - val_loss: 238533591040.0000\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 241090838528.0000 - val_loss: 237590839296.0000\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 240147136512.0000 - val_loss: 236647776256.0000\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 239207268352.0000 - val_loss: 235704500224.0000\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 238267613184.0000 - val_loss: 234763173888.0000\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 237330251776.0000 - val_loss: 233822273536.0000\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 236392448000.0000 - val_loss: 232886403072.0000\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 235459641344.0000 - val_loss: 231946125312.0000\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 234525786112.0000 - val_loss: 231009009664.0000\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 233587933184.0000 - val_loss: 230071123968.0000\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 232655568896.0000 - val_loss: 229134024704.0000\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 231719649280.0000 - val_loss: 228206329856.0000\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 230795034624.0000 - val_loss: 227265495040.0000\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 229856395264.0000 - val_loss: 226335670272.0000\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 228930748416.0000 - val_loss: 225401569280.0000\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 228003184640.0000 - val_loss: 224469319680.0000\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 227075014656.0000 - val_loss: 223550685184.0000\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 226159198208.0000 - val_loss: 222625087488.0000\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 225237286912.0000 - val_loss: 221703602176.0000\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 224320503808.0000 - val_loss: 220784885760.0000\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 223407407104.0000 - val_loss: 219865628672.0000\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 222489575424.0000 - val_loss: 218954366976.0000\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 221578395648.0000 - val_loss: 218040139776.0000\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 220668198912.0000 - val_loss: 217122144256.0000\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 219756773376.0000 - val_loss: 216210489344.0000\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 218847887360.0000 - val_loss: 215301357568.0000\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 217940246528.0000 - val_loss: 214399401984.0000\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 217040617472.0000 - val_loss: 213485699072.0000\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 216135696384.0000 - val_loss: 212583120896.0000\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 215238098944.0000 - val_loss: 211686064128.0000\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 214341124096.0000 - val_loss: 210793791488.0000\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 213452472320.0000 - val_loss: 209894424576.0000\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 212558807040.0000 - val_loss: 208997810176.0000\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 211666698240.0000 - val_loss: 208108257280.0000\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 210782208000.0000 - val_loss: 207221506048.0000\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 209898815488.0000 - val_loss: 206335688704.0000\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 209017012224.0000 - val_loss: 205454999552.0000\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 208138944512.0000 - val_loss: 204573097984.0000\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 207255470080.0000 - val_loss: 203696144384.0000\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 206378926080.0000 - val_loss: 202815455232.0000\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 205501480960.0000 - val_loss: 201929097216.0000\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 204617236480.0000 - val_loss: 201051406336.0000\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 203752407040.0000 - val_loss: 200172879872.0000\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 202879188992.0000 - val_loss: 199306051584.0000\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 202017701888.0000 - val_loss: 198439829504.0000\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 201151774720.0000 - val_loss: 197579096064.0000\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 200294596608.0000 - val_loss: 196722556928.0000\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 199442923520.0000 - val_loss: 195864150016.0000\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 198582681600.0000 - val_loss: 195015688192.0000\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 197742559232.0000 - val_loss: 194158526464.0000\n",
      "Epoch 400/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 196888543232.0000 - val_loss: 193312456704.0000\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 196042948608.0000 - val_loss: 192467648512.0000\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 195201204224.0000 - val_loss: 191612846080.0000\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 194355527680.0000 - val_loss: 190771871744.0000\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 193518682112.0000 - val_loss: 189940269056.0000\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 192689094656.0000 - val_loss: 189108617216.0000\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 191861178368.0000 - val_loss: 188280078336.0000\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 191032819712.0000 - val_loss: 187451555840.0000\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 190206935040.0000 - val_loss: 186618527744.0000\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 189383278592.0000 - val_loss: 185790906368.0000\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 188560998400.0000 - val_loss: 184974295040.0000\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 187748171776.0000 - val_loss: 184154456064.0000\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 186930921472.0000 - val_loss: 183343300608.0000\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 186123698176.0000 - val_loss: 182535471104.0000\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 185319800832.0000 - val_loss: 181726789632.0000\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 184516329472.0000 - val_loss: 180918894592.0000\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 183714430976.0000 - val_loss: 180118208512.0000\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 182913908736.0000 - val_loss: 179325779968.0000\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 182123102208.0000 - val_loss: 178533761024.0000\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 181335818240.0000 - val_loss: 177745608704.0000\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 180555808768.0000 - val_loss: 176950984704.0000\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 179761725440.0000 - val_loss: 176173776896.0000\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 178986663936.0000 - val_loss: 175387099136.0000\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 178206965760.0000 - val_loss: 174608760832.0000\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 177433067520.0000 - val_loss: 173832470528.0000\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 176662740992.0000 - val_loss: 173063782400.0000\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 175896346624.0000 - val_loss: 172301418496.0000\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 175139356672.0000 - val_loss: 171539808256.0000\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 174383726592.0000 - val_loss: 170787979264.0000\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 173634928640.0000 - val_loss: 170031316992.0000\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 172882362368.0000 - val_loss: 169287024640.0000\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 172139233280.0000 - val_loss: 168540602368.0000\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 171396530176.0000 - val_loss: 167796736000.0000\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 170655367168.0000 - val_loss: 167057833984.0000\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 169925050368.0000 - val_loss: 166323929088.0000\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 169196191744.0000 - val_loss: 165597134848.0000\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 168471986176.0000 - val_loss: 164866490368.0000\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 167747207168.0000 - val_loss: 164147134464.0000\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 167030243328.0000 - val_loss: 163429924864.0000\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 166313459712.0000 - val_loss: 162718580736.0000\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 165610192896.0000 - val_loss: 162005303296.0000\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 164899176448.0000 - val_loss: 161305231360.0000\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 164202430464.0000 - val_loss: 160601473024.0000\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 163506454528.0000 - val_loss: 159900598272.0000\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 162807742464.0000 - val_loss: 159212257280.0000\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 162120269824.0000 - val_loss: 158523801600.0000\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 161440169984.0000 - val_loss: 157834248192.0000\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 160750403584.0000 - val_loss: 157154033664.0000\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 160072220672.0000 - val_loss: 156469805056.0000\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 159396102144.0000 - val_loss: 155796881408.0000\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 158724587520.0000 - val_loss: 155130150912.0000\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 158058201088.0000 - val_loss: 154461913088.0000\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 157397139456.0000 - val_loss: 153796558848.0000\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 156738404352.0000 - val_loss: 153143246848.0000\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 156086665216.0000 - val_loss: 152489377792.0000\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 155433615360.0000 - val_loss: 151840522240.0000\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 154791739392.0000 - val_loss: 151187374080.0000\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 154145357824.0000 - val_loss: 150550937600.0000\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 153512820736.0000 - val_loss: 149919301632.0000\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 152883511296.0000 - val_loss: 149294104576.0000\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 152261083136.0000 - val_loss: 148666204160.0000\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 151638310912.0000 - val_loss: 148042694656.0000\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 151017570304.0000 - val_loss: 147427475456.0000\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 150405365760.0000 - val_loss: 146815746048.0000\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 149797470208.0000 - val_loss: 146203394048.0000\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 149192998912.0000 - val_loss: 145593745408.0000\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 148588691456.0000 - val_loss: 144999415808.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 147997065216.0000 - val_loss: 144407658496.0000\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 147407159296.0000 - val_loss: 143817605120.0000\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 146819760128.0000 - val_loss: 143228747776.0000\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 146236604416.0000 - val_loss: 142648508416.0000\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 145656627200.0000 - val_loss: 142071873536.0000\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 145087004672.0000 - val_loss: 141493993472.0000\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 144517152768.0000 - val_loss: 140926730240.0000\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 143954690048.0000 - val_loss: 140369788928.0000\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 143399895040.0000 - val_loss: 139812323328.0000\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 142843019264.0000 - val_loss: 139269488640.0000\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 142299840512.0000 - val_loss: 138714251264.0000\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 141748404224.0000 - val_loss: 138169614336.0000\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 141216612352.0000 - val_loss: 137627615232.0000\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 140672155648.0000 - val_loss: 137100271616.0000\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 140152717312.0000 - val_loss: 136566407168.0000\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 139622301696.0000 - val_loss: 136044216320.0000\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 139104370688.0000 - val_loss: 135526268928.0000\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 138592518144.0000 - val_loss: 135014195200.0000\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 138081255424.0000 - val_loss: 134504005632.0000\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 137573957632.0000 - val_loss: 134000123904.0000\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 137073033216.0000 - val_loss: 133499682816.0000\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 136578441216.0000 - val_loss: 133002092544.0000\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 136083046400.0000 - val_loss: 132511916032.0000\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 135596711936.0000 - val_loss: 132027850752.0000\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 135117316096.0000 - val_loss: 131548004352.0000\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 134640222208.0000 - val_loss: 131071139840.0000\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 134165897216.0000 - val_loss: 130595840000.0000\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 133695225856.0000 - val_loss: 130122858496.0000\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 133230092288.0000 - val_loss: 129656799232.0000\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 132765843456.0000 - val_loss: 129206960128.0000\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 132315496448.0000 - val_loss: 128750616576.0000\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 131864748032.0000 - val_loss: 128301752320.0000\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 131419455488.0000 - val_loss: 127859433472.0000\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 130978897920.0000 - val_loss: 127422013440.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23dfc362ee0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04428505175095643"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23dfab44f70>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model definitely did not train well with high batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
