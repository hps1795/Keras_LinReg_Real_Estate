{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors waterfront  view  ...          grade sqft_above  \\\n",
       "0      5650     1.0        NaN  NONE  ...      7 Average       1180   \n",
       "1      7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2     10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3      5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4      8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop irrelevant column 'id'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are planning to use MinMaxScaler for scaling. This scaling converts maximum value to 1 and minimum to 0 and distribute the values. Column 'zipcode' is not suitable to be applied to this scaler so we will drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('zipcode', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     19075\n",
       "YES      146\n",
       "Name: waterfront, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.waterfront.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NONE         19422\n",
       "AVERAGE        957\n",
       "GOOD           508\n",
       "FAIR           330\n",
       "EXCELLENT      317\n",
       "Name: view, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       17011\n",
       "2014.0       73\n",
       "2003.0       31\n",
       "2013.0       31\n",
       "2007.0       30\n",
       "          ...  \n",
       "1946.0        1\n",
       "1959.0        1\n",
       "1971.0        1\n",
       "1951.0        1\n",
       "1954.0        1\n",
       "Name: yr_renovated, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr_renovated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot find the strong correlation with the price for those columns because they have more than 80% of the rows with same value. Therefore, we will drop the columns above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['waterfront', 'view', 'yr_renovated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0  10/13/2014  221900.0         3       1.00         1180      5650     1.0   \n",
       "1   12/9/2014  538000.0         3       2.25         2570      7242     2.0   \n",
       "2   2/25/2015  180000.0         2       1.00          770     10000     1.0   \n",
       "3   12/9/2014  604000.0         4       3.00         1960      5000     1.0   \n",
       "4   2/18/2015  510000.0         3       2.00         1680      8080     1.0   \n",
       "\n",
       "   condition          grade  sqft_above sqft_basement  yr_built      lat  \\\n",
       "0    Average      7 Average        1180           0.0      1955  47.5112   \n",
       "1    Average      7 Average        2170         400.0      1951  47.7210   \n",
       "2    Average  6 Low Average         770           0.0      1933  47.7379   \n",
       "3  Very Good      7 Average        1050         910.0      1965  47.5208   \n",
       "4    Average         8 Good        1680           0.0      1987  47.6168   \n",
       "\n",
       "      long  sqft_living15  sqft_lot15  \n",
       "0 -122.257           1340        5650  \n",
       "1 -122.319           1690        7639  \n",
       "2 -122.233           2720        8062  \n",
       "3 -122.393           1360        5000  \n",
       "4 -122.045           1800        7503  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           21597 non-null  object \n",
      " 1   price          21597 non-null  float64\n",
      " 2   bedrooms       21597 non-null  int64  \n",
      " 3   bathrooms      21597 non-null  float64\n",
      " 4   sqft_living    21597 non-null  int64  \n",
      " 5   sqft_lot       21597 non-null  int64  \n",
      " 6   floors         21597 non-null  float64\n",
      " 7   condition      21597 non-null  object \n",
      " 8   grade          21597 non-null  object \n",
      " 9   sqft_above     21597 non-null  int64  \n",
      " 10  sqft_basement  21597 non-null  object \n",
      " 11  yr_built       21597 non-null  int64  \n",
      " 12  lat            21597 non-null  float64\n",
      " 13  long           21597 non-null  float64\n",
      " 14  sqft_living15  21597 non-null  int64  \n",
      " 15  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(5), int64(7), object(4)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets deal with the columns with object data type and convert them into int64 or float64 to pass it into keras model. Columns we will make a change are:\n",
    "- date\n",
    "- condition\n",
    "- grade\n",
    "- sqft_basement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert column 'date' into new columns 'month' and 'year'. After creating new columns, 'date' column is not needed so it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].apply(lambda date:date.month)\n",
    "df['year'] = df['date'].apply(lambda date:date.year)\n",
    "df = df.drop('date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'condition' and 'grade' has object entries. We will create the dictionary listing the original entries and the number entries that corresponds to the original entries. Then, we will replace the values in that column using the dictionary we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average      14020\n",
       "Good          5677\n",
       "Very Good     1701\n",
       "Fair           170\n",
       "Poor            29\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_replace = {'Poor': 1, 'Fair': 2, 'Average': 3, 'Good': 4, 'Very Good': 5}\n",
    "df[\"condition\"].replace(condition_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7 Average        8974\n",
       "8 Good           6065\n",
       "9 Better         2615\n",
       "6 Low Average    2038\n",
       "10 Very Good     1134\n",
       "11 Excellent      399\n",
       "5 Fair            242\n",
       "12 Luxury          89\n",
       "4 Low              27\n",
       "13 Mansion         13\n",
       "3 Poor              1\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_replace = {'3 Poor': 3, '4 Low': 4, '5 Fair': 5, '6 Low Average': 6, \n",
    "                 '7 Average': 7, '8 Good': 8, '9 Better': 9 ,'10 Very Good': 10, \n",
    "                 '11 Excellent':11, '12 Luxury': 12, '13 Mansion': 13}\n",
    "df[\"grade\"].replace(grade_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will convert the data type of 'sqft basement' into int64 or float64. Lets first check the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       12826\n",
       "?           454\n",
       "600.0       217\n",
       "500.0       209\n",
       "700.0       208\n",
       "          ...  \n",
       "2580.0        1\n",
       "862.0         1\n",
       "506.0         1\n",
       "1960.0        1\n",
       "2810.0        1\n",
       "Name: sqft_basement, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sqft_basement.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a value '?' which will prevent us from converting the data type. We will replace the '?' to 0 and then convert the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_basement'].replace({'?': 0},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['sqft_basement'] = df['sqft_basement'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if every change has been made properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  condition  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0          3   \n",
       "1  538000.0         3       2.25         2570      7242     2.0          3   \n",
       "2  180000.0         2       1.00          770     10000     1.0          3   \n",
       "3  604000.0         4       3.00         1960      5000     1.0          5   \n",
       "4  510000.0         3       2.00         1680      8080     1.0          3   \n",
       "\n",
       "   grade  sqft_above  sqft_basement  yr_built      lat     long  \\\n",
       "0      7        1180            0.0      1955  47.5112 -122.257   \n",
       "1      7        2170          400.0      1951  47.7210 -122.319   \n",
       "2      6         770            0.0      1933  47.7379 -122.233   \n",
       "3      7        1050          910.0      1965  47.5208 -122.393   \n",
       "4      8        1680            0.0      1987  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  month  year  \n",
       "0           1340        5650     10  2014  \n",
       "1           1690        7639     12  2014  \n",
       "2           2720        8062      2  2015  \n",
       "3           1360        5000     12  2014  \n",
       "4           1800        7503      2  2015  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          21597 non-null  float64\n",
      " 1   bedrooms       21597 non-null  int64  \n",
      " 2   bathrooms      21597 non-null  float64\n",
      " 3   sqft_living    21597 non-null  int64  \n",
      " 4   sqft_lot       21597 non-null  int64  \n",
      " 5   floors         21597 non-null  float64\n",
      " 6   condition      21597 non-null  int64  \n",
      " 7   grade          21597 non-null  int64  \n",
      " 8   sqft_above     21597 non-null  int64  \n",
      " 9   sqft_basement  21597 non-null  float64\n",
      " 10  yr_built       21597 non-null  int64  \n",
      " 11  lat            21597 non-null  float64\n",
      " 12  long           21597 non-null  float64\n",
      " 13  sqft_living15  21597 non-null  int64  \n",
      " 14  sqft_lot15     21597 non-null  int64  \n",
      " 15  month          21597 non-null  int64  \n",
      " 16  year           21597 non-null  int64  \n",
      "dtypes: float64(6), int64(11)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD! Now we have everything set. We will move on to next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first set the X and y. y will be our target variable and the X will be the rest. In my phase 2 project from flatiron school, 'price' was our target object. Therefore, we will set 'price' as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the train test split from the scikit learn library. to split the X and y into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use MinMaxScaler from sklearn library to scale the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scaling, fit applies only for train set while transform applies to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11337, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6480, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3780, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a model using keras from tensorflow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (16,))) \n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(1))             \n",
    "    model.compile(optimizer='adam',loss='mean_squared_error') \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modeling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 430355513344.0000 - val_loss: 427944312832.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 430335590400.0000 - val_loss: 427904073728.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430263140352.0000 - val_loss: 427792203776.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 430102872064.0000 - val_loss: 427575541760.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429820674048.0000 - val_loss: 427215781888.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429375225856.0000 - val_loss: 426677141504.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 428739330048.0000 - val_loss: 425936977920.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 427894439936.0000 - val_loss: 424974483456.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 426823188480.0000 - val_loss: 423778025472.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 425509289984.0000 - val_loss: 422329778176.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 423935279104.0000 - val_loss: 420620075008.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 422089916416.0000 - val_loss: 418628468736.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 419967107072.0000 - val_loss: 416357875712.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 417563738112.0000 - val_loss: 413795647488.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 909us/step - loss: 414870044672.0000 - val_loss: 410952138752.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 411885305856.0000 - val_loss: 407807787008.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 408607490048.0000 - val_loss: 404369211392.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 405031092224.0000 - val_loss: 400636051456.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 401164566528.0000 - val_loss: 396603162624.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 397012336640.0000 - val_loss: 392305278976.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 392565555200.0000 - val_loss: 387703013376.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 387850862592.0000 - val_loss: 382826283008.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 382860754944.0000 - val_loss: 377693274112.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 377594478592.0000 - val_loss: 372281475072.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 372087783424.0000 - val_loss: 366642790400.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 366333067264.0000 - val_loss: 360744222720.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 360344551424.0000 - val_loss: 354608316416.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 354125119488.0000 - val_loss: 348263022592.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 347695841280.0000 - val_loss: 341723938816.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 341071724544.0000 - val_loss: 334955806720.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 334250377216.0000 - val_loss: 328056635392.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 327256014848.0000 - val_loss: 320940900352.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 320109871104.0000 - val_loss: 313697992704.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 312822562816.0000 - val_loss: 306321817600.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 305417486336.0000 - val_loss: 298853433344.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 297905356800.0000 - val_loss: 291269246976.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 290293350400.0000 - val_loss: 283615854592.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 282626457600.0000 - val_loss: 275911344128.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 274914607104.0000 - val_loss: 268125732864.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 267180703744.0000 - val_loss: 260356980736.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 259437002752.0000 - val_loss: 252595453952.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 251704524800.0000 - val_loss: 244850753536.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243996491776.0000 - val_loss: 237154140160.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 236336381952.0000 - val_loss: 229505515520.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 228751802368.0000 - val_loss: 221956128768.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 221271228416.0000 - val_loss: 214480420864.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 213904801792.0000 - val_loss: 207151382528.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 206667071488.0000 - val_loss: 199997702144.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 199584727040.0000 - val_loss: 192983171072.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 192684376064.0000 - val_loss: 186108395520.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 185969934336.0000 - val_loss: 179541983232.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 179479609344.0000 - val_loss: 173101105152.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 173195689984.0000 - val_loss: 166936756224.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 167178502144.0000 - val_loss: 161035124736.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 161420787712.0000 - val_loss: 155353710592.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 155932655616.0000 - val_loss: 150020997120.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 150746038272.0000 - val_loss: 144979132416.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 145846992896.0000 - val_loss: 140217466880.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 141250740224.0000 - val_loss: 135790321664.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 136954896384.0000 - val_loss: 131637231616.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 132988698624.0000 - val_loss: 127797600256.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 129352957952.0000 - val_loss: 124314984448.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 126038458368.0000 - val_loss: 121144942592.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 123027709952.0000 - val_loss: 118275235840.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 120320401408.0000 - val_loss: 115711057920.0000\n",
      "Epoch 66/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 817us/step - loss: 117922603008.0000 - val_loss: 113445527552.0000\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 115809820672.0000 - val_loss: 111482232832.0000\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 113942929408.0000 - val_loss: 109744078848.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 112341991424.0000 - val_loss: 108239372288.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 110975803392.0000 - val_loss: 106972995584.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 109812539392.0000 - val_loss: 105931259904.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 108837519360.0000 - val_loss: 105033162752.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 108037562368.0000 - val_loss: 104307957760.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 107380170752.0000 - val_loss: 103707631616.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 106838458368.0000 - val_loss: 103217463296.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 106393255936.0000 - val_loss: 102813843456.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 106026852352.0000 - val_loss: 102484213760.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 105721315328.0000 - val_loss: 102198124544.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 105468239872.0000 - val_loss: 101959098368.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 105248694272.0000 - val_loss: 101752840192.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 105053208576.0000 - val_loss: 101571239936.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 104874369024.0000 - val_loss: 101403467776.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 746us/step - loss: 104702304256.0000 - val_loss: 101234204672.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 104539275264.0000 - val_loss: 101070561280.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 104375754752.0000 - val_loss: 100912046080.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 104217640960.0000 - val_loss: 100748869632.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 104057372672.0000 - val_loss: 100588716032.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 103896309760.0000 - val_loss: 100427866112.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 103732174848.0000 - val_loss: 100259971072.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 103563370496.0000 - val_loss: 100092387328.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 103392665600.0000 - val_loss: 99920961536.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 103219306496.0000 - val_loss: 99744858112.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 103044857856.0000 - val_loss: 99570974720.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 102868983808.0000 - val_loss: 99390685184.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 102686613504.0000 - val_loss: 99213877248.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 102506381312.0000 - val_loss: 99029565440.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 102325600256.0000 - val_loss: 98845704192.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 102138994688.0000 - val_loss: 98661679104.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 101953830912.0000 - val_loss: 98476204032.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 101766127616.0000 - val_loss: 98286911488.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 101580087296.0000 - val_loss: 98103590912.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 101378842624.0000 - val_loss: 97905025024.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 101191942144.0000 - val_loss: 97712996352.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 101001027584.0000 - val_loss: 97524514816.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 100808900608.0000 - val_loss: 97332469760.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 100614922240.0000 - val_loss: 97135493120.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 100424507392.0000 - val_loss: 96940892160.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 100222025728.0000 - val_loss: 96745291776.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 100025032704.0000 - val_loss: 96547315712.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99829006336.0000 - val_loss: 96348225536.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99629293568.0000 - val_loss: 96148733952.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99430498304.0000 - val_loss: 95949316096.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 99229622272.0000 - val_loss: 95748808704.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 99025911808.0000 - val_loss: 95547064320.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 98825814016.0000 - val_loss: 95341019136.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 98622095360.0000 - val_loss: 95141101568.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 98420121600.0000 - val_loss: 94939226112.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 98217836544.0000 - val_loss: 94736752640.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 98016059392.0000 - val_loss: 94536368128.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 97821286400.0000 - val_loss: 94335066112.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 97614323712.0000 - val_loss: 94129520640.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 97412161536.0000 - val_loss: 93931143168.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 97206648832.0000 - val_loss: 93726621696.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 96998137856.0000 - val_loss: 93520945152.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 96795729920.0000 - val_loss: 93313753088.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 96588324864.0000 - val_loss: 93104644096.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 96378380288.0000 - val_loss: 92895887360.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 96169771008.0000 - val_loss: 92688187392.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 95962226688.0000 - val_loss: 92478291968.0000\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 95752683520.0000 - val_loss: 92269223936.0000\n",
      "Epoch 131/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 825us/step - loss: 95544385536.0000 - val_loss: 92061286400.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 95332573184.0000 - val_loss: 91849187328.0000\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 95120711680.0000 - val_loss: 91639111680.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 94914863104.0000 - val_loss: 91431026688.0000\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 94700773376.0000 - val_loss: 91218386944.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 94489354240.0000 - val_loss: 91004764160.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 94275125248.0000 - val_loss: 90790674432.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 94063443968.0000 - val_loss: 90576297984.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 93845856256.0000 - val_loss: 90364461056.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 777us/step - loss: 93636239360.0000 - val_loss: 90146119680.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 93417472000.0000 - val_loss: 89934372864.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 93206224896.0000 - val_loss: 89718071296.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 92985942016.0000 - val_loss: 89500712960.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 92770746368.0000 - val_loss: 89282928640.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 92554878976.0000 - val_loss: 89068519424.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 92335226880.0000 - val_loss: 88850939904.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 92115812352.0000 - val_loss: 88631386112.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 91897626624.0000 - val_loss: 88413732864.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 91681644544.0000 - val_loss: 88192180224.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 91461910528.0000 - val_loss: 87974199296.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 91241332736.0000 - val_loss: 87753900032.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 91022401536.0000 - val_loss: 87535730688.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 90801954816.0000 - val_loss: 87313645568.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 90580697088.0000 - val_loss: 87091576832.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 90358702080.0000 - val_loss: 86871744512.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 90140000256.0000 - val_loss: 86650429440.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 89919373312.0000 - val_loss: 86430081024.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 87591485440.000 - 0s 799us/step - loss: 89696780288.0000 - val_loss: 86210650112.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 89479602176.0000 - val_loss: 85988548608.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 89252151296.0000 - val_loss: 85763899392.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 89031090176.0000 - val_loss: 85545312256.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 88809832448.0000 - val_loss: 85318811648.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 88583364608.0000 - val_loss: 85094162432.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 88360108032.0000 - val_loss: 84869259264.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 88134221824.0000 - val_loss: 84643512320.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 87910064128.0000 - val_loss: 84418387968.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 87688470528.0000 - val_loss: 84193304576.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 87458750464.0000 - val_loss: 83968827392.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 87232413696.0000 - val_loss: 83739820032.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 87004864512.0000 - val_loss: 83512279040.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 86779215872.0000 - val_loss: 83281379328.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 86552657920.0000 - val_loss: 83053608960.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 86323265536.0000 - val_loss: 82825306112.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 86090612736.0000 - val_loss: 82591891456.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 85855690752.0000 - val_loss: 82359042048.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 85624143872.0000 - val_loss: 82126880768.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 85393399808.0000 - val_loss: 81890992128.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 85159493632.0000 - val_loss: 81660354560.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 84925087744.0000 - val_loss: 81427939328.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 84693311488.0000 - val_loss: 81194786816.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 84456955904.0000 - val_loss: 80965353472.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 84225007616.0000 - val_loss: 80726376448.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 83992059904.0000 - val_loss: 80495140864.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83758268416.0000 - val_loss: 80256540672.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83523788800.0000 - val_loss: 80021553152.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83286016000.0000 - val_loss: 79786246144.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 83047317504.0000 - val_loss: 79546122240.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 82809331712.0000 - val_loss: 79306334208.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 82570469376.0000 - val_loss: 79070093312.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 82331410432.0000 - val_loss: 78829207552.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 82091696128.0000 - val_loss: 78588239872.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 81858527232.0000 - val_loss: 78347296768.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 81612840960.0000 - val_loss: 78110556160.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 81376796672.0000 - val_loss: 77868064768.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 81135648768.0000 - val_loss: 77630062592.0000\n",
      "Epoch 196/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 817us/step - loss: 80895148032.0000 - val_loss: 77389725696.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 80657121280.0000 - val_loss: 77152706560.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 80417980416.0000 - val_loss: 76911353856.0000\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 80181256192.0000 - val_loss: 76671959040.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 79940960256.0000 - val_loss: 76432941056.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 79698681856.0000 - val_loss: 76192989184.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 79460679680.0000 - val_loss: 75951333376.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 79218401280.0000 - val_loss: 75711717376.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 78972690432.0000 - val_loss: 75466448896.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 78729936896.0000 - val_loss: 75224915968.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 78485700608.0000 - val_loss: 74979205120.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 78242365440.0000 - val_loss: 74738589696.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 77988429824.0000 - val_loss: 74482737152.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 77747019776.0000 - val_loss: 74243334144.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 77504241664.0000 - val_loss: 73998508032.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 77260611584.0000 - val_loss: 73756368896.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 77019693056.0000 - val_loss: 73513230336.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 76777185280.0000 - val_loss: 73267331072.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 76532523008.0000 - val_loss: 73026568192.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 76287131648.0000 - val_loss: 72780251136.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 76042682368.0000 - val_loss: 72534810624.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 75795218432.0000 - val_loss: 72285274112.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 75551916032.0000 - val_loss: 72042856448.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 75303190528.0000 - val_loss: 71794237440.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 75058733056.0000 - val_loss: 71549894656.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 74810703872.0000 - val_loss: 71298965504.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 74557603840.0000 - val_loss: 71049576448.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 74307944448.0000 - val_loss: 70800105472.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 74059300864.0000 - val_loss: 70547636224.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 73809674240.0000 - val_loss: 70300295168.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 73560121344.0000 - val_loss: 70051184640.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 73314828288.0000 - val_loss: 69803163648.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 73063620608.0000 - val_loss: 69553258496.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 72813936640.0000 - val_loss: 69308301312.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 72566054912.0000 - val_loss: 69059387392.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 72315445248.0000 - val_loss: 68808638464.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 72066113536.0000 - val_loss: 68560220160.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 71821598720.0000 - val_loss: 68315721728.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 71574577152.0000 - val_loss: 68065898496.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 71325220864.0000 - val_loss: 67819802624.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 71076708352.0000 - val_loss: 67575808000.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 70830850048.0000 - val_loss: 67322060800.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 70581075968.0000 - val_loss: 67077177344.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 70332882944.0000 - val_loss: 66825891840.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 70085263360.0000 - val_loss: 66580000768.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 69836734464.0000 - val_loss: 66333663232.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 69589753856.0000 - val_loss: 66084990976.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 69344215040.0000 - val_loss: 65835855872.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 69096898560.0000 - val_loss: 65594421248.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 68856233984.0000 - val_loss: 65349005312.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 816us/step - loss: 68610732032.0000 - val_loss: 65107968000.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 68372897792.0000 - val_loss: 64870182912.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 68130361344.0000 - val_loss: 64631635968.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 67892908032.0000 - val_loss: 64393998336.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 67653537792.0000 - val_loss: 64156000256.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 67415404544.0000 - val_loss: 63915786240.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 67173588992.0000 - val_loss: 63682719744.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 66936602624.0000 - val_loss: 63444492288.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 66695667712.0000 - val_loss: 63206809600.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 66462810112.0000 - val_loss: 62970716160.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 66231009280.0000 - val_loss: 62737477632.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 65998278656.0000 - val_loss: 62508261376.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 65766100992.0000 - val_loss: 62278242304.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 65540431872.0000 - val_loss: 62047203328.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 65308479488.0000 - val_loss: 61825257472.0000\n",
      "Epoch 261/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 817us/step - loss: 65078886400.0000 - val_loss: 61596262400.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 64856944640.0000 - val_loss: 61369565184.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 64625385472.0000 - val_loss: 61146046464.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 64403709952.0000 - val_loss: 60923527168.0000\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 64178954240.0000 - val_loss: 60703055872.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 63958740992.0000 - val_loss: 60485079040.0000\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 63739899904.0000 - val_loss: 60268576768.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 777us/step - loss: 63522402304.0000 - val_loss: 60052144128.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 63303393280.0000 - val_loss: 59835731968.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 63088570368.0000 - val_loss: 59621707776.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 62876295168.0000 - val_loss: 59410706432.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 62657765376.0000 - val_loss: 59203858432.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 62447738880.0000 - val_loss: 58990686208.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 62246125568.0000 - val_loss: 58785910784.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 62035050496.0000 - val_loss: 58583588864.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 61832962048.0000 - val_loss: 58383282176.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 61632438272.0000 - val_loss: 58184491008.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 61439516672.0000 - val_loss: 57994579968.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 61246111744.0000 - val_loss: 57807032320.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 61056557056.0000 - val_loss: 57620541440.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 60873003008.0000 - val_loss: 57439174656.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 60686528512.0000 - val_loss: 57259200512.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 60503597056.0000 - val_loss: 57079738368.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 60329189376.0000 - val_loss: 56898027520.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 60144951296.0000 - val_loss: 56725561344.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 59969638400.0000 - val_loss: 56551481344.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 59799248896.0000 - val_loss: 56381812736.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 59631001600.0000 - val_loss: 56217063424.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 59459530752.0000 - val_loss: 56051200000.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 59296768000.0000 - val_loss: 55889543168.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 59127226368.0000 - val_loss: 55728881664.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 58962935808.0000 - val_loss: 55566249984.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 58801696768.0000 - val_loss: 55408447488.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 58640007168.0000 - val_loss: 55254134784.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 58483638272.0000 - val_loss: 55097528320.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 58325049344.0000 - val_loss: 54946295808.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 58177269760.0000 - val_loss: 54795694080.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 58022928384.0000 - val_loss: 54649171968.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 57879511040.0000 - val_loss: 54509813760.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 57727852544.0000 - val_loss: 54366781440.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 57585291264.0000 - val_loss: 54225612800.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 57445625856.0000 - val_loss: 54093426688.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 57313878016.0000 - val_loss: 53959888896.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 57174265856.0000 - val_loss: 53826863104.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 57042870272.0000 - val_loss: 53700169728.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 56915685376.0000 - val_loss: 53570715648.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 56781389824.0000 - val_loss: 53447426048.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 56665419776.0000 - val_loss: 53326123008.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 56534626304.0000 - val_loss: 53211013120.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 56413569024.0000 - val_loss: 53090447360.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 56295645184.0000 - val_loss: 52977991680.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 56181542912.0000 - val_loss: 52865679360.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 56067334144.0000 - val_loss: 52757483520.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 55956303872.0000 - val_loss: 52652490752.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 55850967040.0000 - val_loss: 52546990080.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 55744823296.0000 - val_loss: 52446355456.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 55641149440.0000 - val_loss: 52345581568.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 55538565120.0000 - val_loss: 52245561344.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 55438925824.0000 - val_loss: 52150341632.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 55343095808.0000 - val_loss: 52057026560.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 55246073856.0000 - val_loss: 51965378560.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 55151693824.0000 - val_loss: 51877953536.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 55059148800.0000 - val_loss: 51792695296.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54968274944.0000 - val_loss: 51705937920.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 54879240192.0000 - val_loss: 51622715392.0000\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 755us/step - loss: 54794817536.0000 - val_loss: 51541721088.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 54711590912.0000 - val_loss: 51461595136.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 54630268928.0000 - val_loss: 51382390784.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54547628032.0000 - val_loss: 51304386560.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 54472581120.0000 - val_loss: 51228995584.0000\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54392487936.0000 - val_loss: 51152035840.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54317416448.0000 - val_loss: 51078295552.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 54241263616.0000 - val_loss: 51006582784.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 54170238976.0000 - val_loss: 50941595648.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 54095564800.0000 - val_loss: 50874167296.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 54026981376.0000 - val_loss: 50805972992.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 53956444160.0000 - val_loss: 50739814400.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 55305449472.000 - 0s 773us/step - loss: 53891473408.0000 - val_loss: 50678063104.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53820280832.0000 - val_loss: 50612920320.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 53761327104.0000 - val_loss: 50550079488.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 53692596224.0000 - val_loss: 50492391424.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53632450560.0000 - val_loss: 50428059648.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53567299584.0000 - val_loss: 50375106560.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 53509324800.0000 - val_loss: 50316345344.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 53448429568.0000 - val_loss: 50262790144.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53391544320.0000 - val_loss: 50210430976.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53334704128.0000 - val_loss: 50158882816.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53283160064.0000 - val_loss: 50107260928.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 53225320448.0000 - val_loss: 50056716288.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 53173985280.0000 - val_loss: 50005565440.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 53117124608.0000 - val_loss: 49958727680.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 53068738560.0000 - val_loss: 49910636544.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 53016465408.0000 - val_loss: 49862787072.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52969107456.0000 - val_loss: 49818492928.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52920688640.0000 - val_loss: 49773096960.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52870098944.0000 - val_loss: 49726709760.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52823478272.0000 - val_loss: 49683775488.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52778172416.0000 - val_loss: 49642119168.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52734312448.0000 - val_loss: 49601425408.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 52700188672.0000 - val_loss: 49562763264.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52650405888.0000 - val_loss: 49523277824.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 52608618496.0000 - val_loss: 49485406208.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 52563197952.0000 - val_loss: 49451200512.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 52523380736.0000 - val_loss: 49405235200.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52483637248.0000 - val_loss: 49374052352.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 52444631040.0000 - val_loss: 49335365632.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 52409946112.0000 - val_loss: 49299435520.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 52364296192.0000 - val_loss: 49262997504.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 52330389504.0000 - val_loss: 49226723328.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 52294176768.0000 - val_loss: 49197850624.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 52257890304.0000 - val_loss: 49165774848.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 52217159680.0000 - val_loss: 49130381312.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 52181467136.0000 - val_loss: 49094209536.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52146446336.0000 - val_loss: 49062461440.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 52118433792.0000 - val_loss: 49033265152.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 52081704960.0000 - val_loss: 49001185280.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 52044673024.0000 - val_loss: 48975282176.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 52012228608.0000 - val_loss: 48945623040.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 51979083776.0000 - val_loss: 48914206720.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51947536384.0000 - val_loss: 48882724864.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 51914620928.0000 - val_loss: 48855441408.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51885793280.0000 - val_loss: 48826195968.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 51852312576.0000 - val_loss: 48797523968.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 51823202304.0000 - val_loss: 48770752512.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51797671936.0000 - val_loss: 48739913728.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51762458624.0000 - val_loss: 48718012416.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 51734126592.0000 - val_loss: 48689680384.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 51706564608.0000 - val_loss: 48667336704.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51675217920.0000 - val_loss: 48640421888.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 51643625472.0000 - val_loss: 48617242624.0000\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 817us/step - loss: 51617869824.0000 - val_loss: 48590127104.0000\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51589140480.0000 - val_loss: 48562147328.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 786us/step - loss: 51562971136.0000 - val_loss: 48537579520.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51535843328.0000 - val_loss: 48515764224.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51510579200.0000 - val_loss: 48491929600.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51481337856.0000 - val_loss: 48467648512.0000\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 51454988288.0000 - val_loss: 48439185408.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 51430985728.0000 - val_loss: 48421593088.0000\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51399221248.0000 - val_loss: 48392531968.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 51381829632.0000 - val_loss: 48368578560.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 51354398720.0000 - val_loss: 48344137728.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 51324547072.0000 - val_loss: 48328908800.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 51298734080.0000 - val_loss: 48307109888.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 51274936320.0000 - val_loss: 48284123136.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51249500160.0000 - val_loss: 48263712768.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 51224936448.0000 - val_loss: 48239534080.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 51203227648.0000 - val_loss: 48214728704.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51180912640.0000 - val_loss: 48198094848.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 51150852096.0000 - val_loss: 48179560448.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 51127914496.0000 - val_loss: 48157872128.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51104567296.0000 - val_loss: 48131567616.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 51082801152.0000 - val_loss: 48112074752.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 51056812032.0000 - val_loss: 48091344896.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 816us/step - loss: 51035541504.0000 - val_loss: 48072155136.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 51017244672.0000 - val_loss: 48053026816.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50990809088.0000 - val_loss: 48034381824.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50966552576.0000 - val_loss: 48014397440.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 50944495616.0000 - val_loss: 47993663488.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50923343872.0000 - val_loss: 47972892672.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 50901618688.0000 - val_loss: 47952683008.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50878042112.0000 - val_loss: 47929118720.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50860310528.0000 - val_loss: 47913779200.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50836168704.0000 - val_loss: 47896485888.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50810920960.0000 - val_loss: 47874805760.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50793635840.0000 - val_loss: 47854149632.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50769195008.0000 - val_loss: 47838195712.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50746150912.0000 - val_loss: 47816105984.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50725343232.0000 - val_loss: 47800504320.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50702680064.0000 - val_loss: 47776432128.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 50680434688.0000 - val_loss: 47759802368.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50659721216.0000 - val_loss: 47740112896.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50636214272.0000 - val_loss: 47717748736.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50615468032.0000 - val_loss: 47698190336.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50594250752.0000 - val_loss: 47682076672.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 50572763136.0000 - val_loss: 47665131520.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50549186560.0000 - val_loss: 47645413376.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 50525884416.0000 - val_loss: 47623397376.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50504302592.0000 - val_loss: 47606898688.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50485063680.0000 - val_loss: 47589851136.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50464055296.0000 - val_loss: 47564619776.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50444218368.0000 - val_loss: 47546089472.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50415124480.0000 - val_loss: 47522873344.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50393354240.0000 - val_loss: 47507562496.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50368729088.0000 - val_loss: 47481552896.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50346471424.0000 - val_loss: 47461171200.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50325639168.0000 - val_loss: 47448555520.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50306105344.0000 - val_loss: 47430602752.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50276741120.0000 - val_loss: 47402950656.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 50256691200.0000 - val_loss: 47381118976.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50230112256.0000 - val_loss: 47357550592.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 50204180480.0000 - val_loss: 47343591424.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 808us/step - loss: 50182762496.0000 - val_loss: 47321452544.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50154905600.0000 - val_loss: 47303696384.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 50130239488.0000 - val_loss: 47276404736.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50107904000.0000 - val_loss: 47252246528.0000\n",
      "Epoch 456/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 773us/step - loss: 50080555008.0000 - val_loss: 47232798720.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 50054459392.0000 - val_loss: 47211220992.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50031329280.0000 - val_loss: 47188979712.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 50001338368.0000 - val_loss: 47163121664.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 49975984128.0000 - val_loss: 47139217408.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49950097408.0000 - val_loss: 47108526080.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49923141632.0000 - val_loss: 47088197632.0000\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - 0s 790us/step - loss: 49890299904.0000 - val_loss: 47062769664.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 49862787072.0000 - val_loss: 47036682240.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 49833553920.0000 - val_loss: 47010123776.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49802317824.0000 - val_loss: 46982221824.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 49774432256.0000 - val_loss: 46958288896.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 49740181504.0000 - val_loss: 46934003712.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 746us/step - loss: 49707401216.0000 - val_loss: 46900899840.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 49676623872.0000 - val_loss: 46869520384.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49651281920.0000 - val_loss: 46839644160.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49614290944.0000 - val_loss: 46811226112.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49578758144.0000 - val_loss: 46776930304.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 49544081408.0000 - val_loss: 46748323840.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 49509916672.0000 - val_loss: 46721736704.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 49475985408.0000 - val_loss: 46688591872.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 49441443840.0000 - val_loss: 46650945536.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 49407016960.0000 - val_loss: 46615171072.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 773us/step - loss: 49369337856.0000 - val_loss: 46583181312.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 764us/step - loss: 49335640064.0000 - val_loss: 46550491136.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 49302302720.0000 - val_loss: 46525362176.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 49263534080.0000 - val_loss: 46484844544.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49225666560.0000 - val_loss: 46451859456.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 49186381824.0000 - val_loss: 46427004928.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 817us/step - loss: 49148256256.0000 - val_loss: 46390464512.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 49114124288.0000 - val_loss: 46360018944.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 799us/step - loss: 49075425280.0000 - val_loss: 46324985856.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 843us/step - loss: 49041031168.0000 - val_loss: 46295724032.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 49005309952.0000 - val_loss: 46260641792.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 48969322496.0000 - val_loss: 46229889024.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48928505856.0000 - val_loss: 46197534720.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48894926848.0000 - val_loss: 46161862656.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 48856915968.0000 - val_loss: 46129856512.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 755us/step - loss: 48824922112.0000 - val_loss: 46099099648.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48789037056.0000 - val_loss: 46069481472.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 48754130944.0000 - val_loss: 46041772032.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48720326656.0000 - val_loss: 46009479168.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 48683991040.0000 - val_loss: 45978722304.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 825us/step - loss: 48653815808.0000 - val_loss: 45945901056.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 781us/step - loss: 48622874624.0000 - val_loss: 45920649216.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23df5db64c0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are planning to conduct multiple training, defining a function for creating a model will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.303555e+11</td>\n",
       "      <td>4.279443e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.303356e+11</td>\n",
       "      <td>4.279041e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.302631e+11</td>\n",
       "      <td>4.277922e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.301029e+11</td>\n",
       "      <td>4.275755e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.298207e+11</td>\n",
       "      <td>4.272158e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4.875413e+10</td>\n",
       "      <td>4.604177e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4.872033e+10</td>\n",
       "      <td>4.600948e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4.868399e+10</td>\n",
       "      <td>4.597872e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4.865382e+10</td>\n",
       "      <td>4.594590e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4.862287e+10</td>\n",
       "      <td>4.592065e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss      val_loss\n",
       "0    4.303555e+11  4.279443e+11\n",
       "1    4.303356e+11  4.279041e+11\n",
       "2    4.302631e+11  4.277922e+11\n",
       "3    4.301029e+11  4.275755e+11\n",
       "4    4.298207e+11  4.272158e+11\n",
       "..            ...           ...\n",
       "495  4.875413e+10  4.604177e+10\n",
       "496  4.872033e+10  4.600948e+10\n",
       "497  4.868399e+10  4.597872e+10\n",
       "498  4.865382e+10  4.594590e+10\n",
       "499  4.862287e+10  4.592065e+10\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows that our loss stabilizes around epoch = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first find out the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the price using the model we created using a X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133171.32541578315"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE is the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight. This shows that our prediction has average difference of $ 133171.33 from the actual price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6291026515034247"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has fair r2 score of 0.629."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23df93d65e0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows that the there are outliers that does not follow the y_test line. Our scatter points are closely aligned with the linear line up to around 2e-6 to 3e-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just for fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is more unit better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I did not understand fully on choosing number of unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "  1/114 [..............................] - ETA: 0s - loss: 369385603072.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 430345355264.0000 - val_loss: 427899420672.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 430131871744.0000 - val_loss: 427424186368.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 429204406272.0000 - val_loss: 425921314816.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 953us/step - loss: 426976411648.0000 - val_loss: 422835650560.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 422918127616.0000 - val_loss: 417682325504.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416610680832.0000 - val_loss: 410109018112.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 407729602560.0000 - val_loss: 399820029952.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 396134678528.0000 - val_loss: 386787409920.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 381849698304.0000 - val_loss: 371142295552.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 364974637056.0000 - val_loss: 352964411392.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345765904384.0000 - val_loss: 332664864768.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 324641619968.0000 - val_loss: 310672293888.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 302088093696.0000 - val_loss: 287506890752.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278660153344.0000 - val_loss: 263798374400.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254962024448.0000 - val_loss: 240069378048.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 231735394304.0000 - val_loss: 217215582208.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 209552244736.0000 - val_loss: 195660185600.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 189015572480.0000 - val_loss: 176058793984.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 170548674560.0000 - val_loss: 158827511808.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 154518011904.0000 - val_loss: 144027860992.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 141129007104.0000 - val_loss: 131972464640.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 130405941248.0000 - val_loss: 122564952064.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 122242334720.0000 - val_loss: 115501105152.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 116213334016.0000 - val_loss: 110518247424.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 112031571968.0000 - val_loss: 107037302784.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 109266313216.0000 - val_loss: 104834228224.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 107486838784.0000 - val_loss: 103436632064.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 106353680384.0000 - val_loss: 102521659392.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 105631268864.0000 - val_loss: 101951823872.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 105133350912.0000 - val_loss: 101525544960.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 104740241408.0000 - val_loss: 101163868160.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 104416231424.0000 - val_loss: 100853235712.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 104096227328.0000 - val_loss: 100539244544.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 103788781568.0000 - val_loss: 100228882432.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103478829056.0000 - val_loss: 99912736768.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103159930880.0000 - val_loss: 99585728512.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102828441600.0000 - val_loss: 99254681600.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 102489186304.0000 - val_loss: 98909306880.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 102137077760.0000 - val_loss: 98553233408.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 101777752064.0000 - val_loss: 98180284416.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 101408481280.0000 - val_loss: 97809170432.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 101032542208.0000 - val_loss: 97429053440.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 100643168256.0000 - val_loss: 97043283968.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 100250992640.0000 - val_loss: 96639852544.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 99848658944.0000 - val_loss: 96235167744.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 99436617728.0000 - val_loss: 95816679424.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 99020136448.0000 - val_loss: 95395160064.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 98592382976.0000 - val_loss: 94968930304.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 98154176512.0000 - val_loss: 94520786944.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 97709834240.0000 - val_loss: 94070915072.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 97259126784.0000 - val_loss: 93619666944.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 96807854080.0000 - val_loss: 93160472576.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 96348930048.0000 - val_loss: 92704292864.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 95878897664.0000 - val_loss: 92229271552.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 95397502976.0000 - val_loss: 91755995136.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 94920957952.0000 - val_loss: 91276410880.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 94438416384.0000 - val_loss: 90778214400.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 93941170176.0000 - val_loss: 90286628864.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 93436141568.0000 - val_loss: 89775071232.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 92929499136.0000 - val_loss: 89267331072.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 92417728512.0000 - val_loss: 88754069504.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 91901550592.0000 - val_loss: 88235458560.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 91379867648.0000 - val_loss: 87701651456.0000\n",
      "Epoch 64/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 887us/step - loss: 90852204544.0000 - val_loss: 87183400960.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 90331209728.0000 - val_loss: 86647873536.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 89791545344.0000 - val_loss: 86114115584.0000\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 89255059456.0000 - val_loss: 85572386816.0000\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 88709038080.0000 - val_loss: 85030494208.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 88160894976.0000 - val_loss: 84472258560.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 87606411264.0000 - val_loss: 83918495744.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 87054229504.0000 - val_loss: 83360899072.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 86499328000.0000 - val_loss: 82810363904.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 85939871744.0000 - val_loss: 82244378624.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 85377376256.0000 - val_loss: 81671421952.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 84809015296.0000 - val_loss: 81097965568.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 84225728512.0000 - val_loss: 80523280384.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 83645243392.0000 - val_loss: 79934136320.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 83060547584.0000 - val_loss: 79352750080.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 82470035456.0000 - val_loss: 78759460864.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 81868783616.0000 - val_loss: 78164369408.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 81280286720.0000 - val_loss: 77557948416.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 80662552576.0000 - val_loss: 76942024704.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 80052969472.0000 - val_loss: 76330844160.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 79431049216.0000 - val_loss: 75700903936.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 78805794816.0000 - val_loss: 75085389824.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 78181277696.0000 - val_loss: 74458071040.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 77560463360.0000 - val_loss: 73823551488.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 76927533056.0000 - val_loss: 73189482496.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 76289212416.0000 - val_loss: 72555544576.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 75655233536.0000 - val_loss: 71935541248.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 75024482304.0000 - val_loss: 71300390912.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 74401824768.0000 - val_loss: 70664265728.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 73767444480.0000 - val_loss: 70040338432.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 73144164352.0000 - val_loss: 69425618944.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 72535613440.0000 - val_loss: 68795179008.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 71909842944.0000 - val_loss: 68184375296.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 71284785152.0000 - val_loss: 67555323904.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 70668034048.0000 - val_loss: 66949435392.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 70053240832.0000 - val_loss: 66331115520.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 69438464000.0000 - val_loss: 65728335872.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 68842864640.0000 - val_loss: 65134587904.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 68244316160.0000 - val_loss: 64537133056.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 67652526080.0000 - val_loss: 63966474240.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 67069612032.0000 - val_loss: 63382044672.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 66497503232.0000 - val_loss: 62813122560.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 65934598144.0000 - val_loss: 62253232128.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 65368018944.0000 - val_loss: 61707915264.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 64815656960.0000 - val_loss: 61152202752.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 64276742144.0000 - val_loss: 60609142784.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 63738458112.0000 - val_loss: 60081987584.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 63222145024.0000 - val_loss: 59577905152.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 62693330944.0000 - val_loss: 59071746048.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 62197071872.0000 - val_loss: 58581700608.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 61707231232.0000 - val_loss: 58104811520.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 882us/step - loss: 61233893376.0000 - val_loss: 57638830080.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 60766003200.0000 - val_loss: 57179152384.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 60314923008.0000 - val_loss: 56746057728.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 59877765120.0000 - val_loss: 56324722688.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 59443830784.0000 - val_loss: 55910936576.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 59041185792.0000 - val_loss: 55508922368.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 58633031680.0000 - val_loss: 55111942144.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 58243911680.0000 - val_loss: 54750633984.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 57876258816.0000 - val_loss: 54392356864.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 57529950208.0000 - val_loss: 54040457216.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 57180418048.0000 - val_loss: 53730938880.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56869130240.0000 - val_loss: 53414125568.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56559034368.0000 - val_loss: 53127897088.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56248401920.0000 - val_loss: 52843536384.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55974944768.0000 - val_loss: 52584001536.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 55729393664.0000 - val_loss: 52340076544.0000\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55460683776.0000 - val_loss: 52093005824.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 55228166144.0000 - val_loss: 51869245440.0000\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 54997409792.0000 - val_loss: 51651735552.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 54792609792.0000 - val_loss: 51471908864.0000\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54587039744.0000 - val_loss: 51269668864.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 54391476224.0000 - val_loss: 51084111872.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 54204719104.0000 - val_loss: 50915282944.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 54030098432.0000 - val_loss: 50756558848.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 53859536896.0000 - val_loss: 50607919104.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53708914688.0000 - val_loss: 50448564224.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 53554831360.0000 - val_loss: 50313019392.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53405036544.0000 - val_loss: 50179342336.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53266509824.0000 - val_loss: 50060279808.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53139140608.0000 - val_loss: 49949507584.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 53009420288.0000 - val_loss: 49819111424.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52878700544.0000 - val_loss: 49694392320.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52766449664.0000 - val_loss: 49586925568.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52661706752.0000 - val_loss: 49491582976.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52546174976.0000 - val_loss: 49388228608.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 52443660288.0000 - val_loss: 49300357120.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 52343250944.0000 - val_loss: 49212411904.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 52242530304.0000 - val_loss: 49113616384.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 52148244480.0000 - val_loss: 49026904064.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 52045713408.0000 - val_loss: 48941187072.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 51950252032.0000 - val_loss: 48850509824.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 51861377024.0000 - val_loss: 48767881216.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 51771195392.0000 - val_loss: 48689545216.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 51681431552.0000 - val_loss: 48619806720.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51594153984.0000 - val_loss: 48535900160.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51505770496.0000 - val_loss: 48460701696.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51428233216.0000 - val_loss: 48382242816.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 51334995968.0000 - val_loss: 48304418816.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51264086016.0000 - val_loss: 48235339776.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51182977024.0000 - val_loss: 48168890368.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 51097767936.0000 - val_loss: 48098365440.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 51029049344.0000 - val_loss: 48037576704.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 50960105472.0000 - val_loss: 47955050496.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50888744960.0000 - val_loss: 47901294592.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 50809241600.0000 - val_loss: 47857287168.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 50742505472.0000 - val_loss: 47778062336.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 50674016256.0000 - val_loss: 47723429888.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50606669824.0000 - val_loss: 47656767488.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 50374524928.000 - 0s 1ms/step - loss: 50537279488.0000 - val_loss: 47594532864.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50462515200.0000 - val_loss: 47541809152.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50390523904.0000 - val_loss: 47462555648.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50323546112.0000 - val_loss: 47392931840.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 50252771328.0000 - val_loss: 47341178880.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 50180476928.0000 - val_loss: 47275696128.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 50100629504.0000 - val_loss: 47222349824.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 50029694976.0000 - val_loss: 47129223168.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 49941176320.0000 - val_loss: 47069081600.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49866170368.0000 - val_loss: 46990716928.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 49783328768.0000 - val_loss: 46917349376.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 49714442240.0000 - val_loss: 46842900480.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49624760320.0000 - val_loss: 46787969024.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 49551691776.0000 - val_loss: 46717480960.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 49465032704.0000 - val_loss: 46645727232.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 49391788032.0000 - val_loss: 46580006912.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 49312993280.0000 - val_loss: 46496464896.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49238269952.0000 - val_loss: 46426464256.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 49168396288.0000 - val_loss: 46383288320.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 49097785344.0000 - val_loss: 46295203840.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 49023029248.0000 - val_loss: 46239793152.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 48948445184.0000 - val_loss: 46195015680.0000\n",
      "Epoch 195/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 913us/step - loss: 48879321088.0000 - val_loss: 46105309184.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 48822214656.0000 - val_loss: 46039904256.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 48741167104.0000 - val_loss: 45984468992.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 48666341376.0000 - val_loss: 45906821120.0000\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 48585162752.0000 - val_loss: 45836673024.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48513363968.0000 - val_loss: 45782147072.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 48433246208.0000 - val_loss: 45720903680.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48366686208.0000 - val_loss: 45650853888.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 48285474816.0000 - val_loss: 45582471168.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 48213831680.0000 - val_loss: 45515796480.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 48136085504.0000 - val_loss: 45441302528.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 48052719616.0000 - val_loss: 45373808640.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 47976943616.0000 - val_loss: 45318647808.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 47906553856.0000 - val_loss: 45237534720.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 47833321472.0000 - val_loss: 45220659200.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47770222592.0000 - val_loss: 45122441216.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47707471872.0000 - val_loss: 45063880704.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 47632494592.0000 - val_loss: 45004132352.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 47576535040.0000 - val_loss: 44938502144.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 47511207936.0000 - val_loss: 44886609920.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 47442632704.0000 - val_loss: 44854927360.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 47381827584.0000 - val_loss: 44788899840.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 47322251264.0000 - val_loss: 44731199488.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 47255494656.0000 - val_loss: 44667056128.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 47198822400.0000 - val_loss: 44621606912.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 47139536896.0000 - val_loss: 44563652608.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 47071019008.0000 - val_loss: 44515151872.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 917us/step - loss: 47011819520.0000 - val_loss: 44446806016.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 46946201600.0000 - val_loss: 44405829632.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 46875103232.0000 - val_loss: 44321906688.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 46811979776.0000 - val_loss: 44282200064.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 46754648064.0000 - val_loss: 44221358080.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 46686752768.0000 - val_loss: 44154249216.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 46621405184.0000 - val_loss: 44110143488.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 46558105600.0000 - val_loss: 44047925248.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 46494973952.0000 - val_loss: 43983798272.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 46435049472.0000 - val_loss: 43923644416.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 46378737664.0000 - val_loss: 43871043584.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 46307995648.0000 - val_loss: 43822231552.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46241931264.0000 - val_loss: 43773927424.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 46179360768.0000 - val_loss: 43714060288.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 46121943040.0000 - val_loss: 43647107072.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 46059274240.0000 - val_loss: 43595194368.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 45984415744.0000 - val_loss: 43530629120.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 45919133696.0000 - val_loss: 43492810752.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 45855531008.0000 - val_loss: 43412713472.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 45781336064.0000 - val_loss: 43344093184.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 45716713472.0000 - val_loss: 43288301568.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 45652357120.0000 - val_loss: 43223302144.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 45575376896.0000 - val_loss: 43165564928.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 45507817472.0000 - val_loss: 43104964608.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 45434925056.0000 - val_loss: 43053912064.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 45368651776.0000 - val_loss: 42970611712.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45309530112.0000 - val_loss: 42916712448.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45228376064.0000 - val_loss: 42854449152.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45146398720.0000 - val_loss: 42787557376.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 45081231360.0000 - val_loss: 42701029376.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 45012332544.0000 - val_loss: 42658156544.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 44928950272.0000 - val_loss: 42608254976.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 44859392000.0000 - val_loss: 42522775552.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 895us/step - loss: 44788473856.0000 - val_loss: 42462109696.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44706226176.0000 - val_loss: 42403577856.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44636221440.0000 - val_loss: 42352427008.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 44559269888.0000 - val_loss: 42257309696.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 44488409088.0000 - val_loss: 42219802624.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 44415774720.0000 - val_loss: 42129235968.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 44343521280.0000 - val_loss: 42073690112.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 44272214016.0000 - val_loss: 42028572672.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44198744064.0000 - val_loss: 41950257152.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 44130336768.0000 - val_loss: 41890942976.0000\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 44071473152.0000 - val_loss: 41829466112.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 44011122688.0000 - val_loss: 41768103936.0000\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43937607680.0000 - val_loss: 41713156096.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43880300544.0000 - val_loss: 41660133376.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 43804913664.0000 - val_loss: 41619283968.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 43747549184.0000 - val_loss: 41568522240.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43691876352.0000 - val_loss: 41508110336.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43631931392.0000 - val_loss: 41467756544.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43574042624.0000 - val_loss: 41409093632.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43519623168.0000 - val_loss: 41365237760.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 43465154560.0000 - val_loss: 41332097024.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 43407474688.0000 - val_loss: 41266286592.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 43353997312.0000 - val_loss: 41209643008.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 43304669184.0000 - val_loss: 41194262528.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 43257409536.0000 - val_loss: 41131577344.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 43200524288.0000 - val_loss: 41076240384.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43145969664.0000 - val_loss: 41025994752.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 43106385920.0000 - val_loss: 40973299712.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 43050754048.0000 - val_loss: 40949911552.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 42992852992.0000 - val_loss: 40898859008.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 42943115264.0000 - val_loss: 40855957504.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42888896512.0000 - val_loss: 40798769152.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42852298752.0000 - val_loss: 40750948352.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42788007936.0000 - val_loss: 40717119488.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 42738774016.0000 - val_loss: 40674271232.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 42693828608.0000 - val_loss: 40631377920.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42638102528.0000 - val_loss: 40578330624.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 42591637504.0000 - val_loss: 40550588416.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42533507072.0000 - val_loss: 40506994688.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42491510784.0000 - val_loss: 40478343168.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42444144640.0000 - val_loss: 40425545728.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42377945088.0000 - val_loss: 40362008576.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 42332385280.0000 - val_loss: 40338915328.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42285981696.0000 - val_loss: 40272015360.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42239414272.0000 - val_loss: 40233549824.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42177949696.0000 - val_loss: 40209575936.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 42131398656.0000 - val_loss: 40145350656.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 42078388224.0000 - val_loss: 40114495488.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42032668672.0000 - val_loss: 40067985408.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41981210624.0000 - val_loss: 40032776192.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41928323072.0000 - val_loss: 39965351936.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 41875775488.0000 - val_loss: 39960379392.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 41830121472.0000 - val_loss: 39890698240.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41777852416.0000 - val_loss: 39828217856.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41734205440.0000 - val_loss: 39798259712.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 41685012480.0000 - val_loss: 39776837632.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41620705280.0000 - val_loss: 39715917824.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 41571151872.0000 - val_loss: 39661391872.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 41516740608.0000 - val_loss: 39638134784.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 41472684032.0000 - val_loss: 39608442880.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 38775971840.000 - 0s 983us/step - loss: 41423257600.0000 - val_loss: 39549325312.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 41364570112.0000 - val_loss: 39493156864.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 41320968192.0000 - val_loss: 39452389376.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 41270472704.0000 - val_loss: 39417475072.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41229004800.0000 - val_loss: 39361560576.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41170509824.0000 - val_loss: 39330873344.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 41126645760.0000 - val_loss: 39291506688.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41069096960.0000 - val_loss: 39251357696.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 41026830336.0000 - val_loss: 39210692608.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 40979042304.0000 - val_loss: 39179153408.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 40937136128.0000 - val_loss: 39122472960.0000\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 904us/step - loss: 40892284928.0000 - val_loss: 39086379008.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 40836816896.0000 - val_loss: 39054819328.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 40788451328.0000 - val_loss: 39033159680.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40735780864.0000 - val_loss: 38973788160.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 40686448640.0000 - val_loss: 38932373504.0000\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 40639483904.0000 - val_loss: 38881767424.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 900us/step - loss: 40595619840.0000 - val_loss: 38861778944.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40547454976.0000 - val_loss: 38827954176.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 40502861824.0000 - val_loss: 38778372096.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 40468901888.0000 - val_loss: 38742962176.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40423665664.0000 - val_loss: 38710652928.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40377802752.0000 - val_loss: 38686007296.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40336424960.0000 - val_loss: 38645399552.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40289144832.0000 - val_loss: 38611292160.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 40251129856.0000 - val_loss: 38583468032.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40206557184.0000 - val_loss: 38547673088.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40169578496.0000 - val_loss: 38542102528.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 40129818624.0000 - val_loss: 38492053504.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 40080375808.0000 - val_loss: 38441529344.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 40049647616.0000 - val_loss: 38400237568.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 40008200192.0000 - val_loss: 38370721792.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39967301632.0000 - val_loss: 38334545920.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39926800384.0000 - val_loss: 38327287808.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39906123776.0000 - val_loss: 38289092608.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39849897984.0000 - val_loss: 38273650688.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 39810691072.0000 - val_loss: 38232813568.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39780933632.0000 - val_loss: 38200283136.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 39739568128.0000 - val_loss: 38181347328.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 39712538624.0000 - val_loss: 38140235776.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 39666524160.0000 - val_loss: 38150856704.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39643901952.0000 - val_loss: 38115037184.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 39600943104.0000 - val_loss: 38074400768.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39560163328.0000 - val_loss: 38041874432.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39537786880.0000 - val_loss: 38018293760.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 39495610368.0000 - val_loss: 37982666752.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 39468105728.0000 - val_loss: 37975343104.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39431405568.0000 - val_loss: 37948170240.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39401869312.0000 - val_loss: 37933371392.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39369670656.0000 - val_loss: 37906518016.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39341182976.0000 - val_loss: 37886017536.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39312912384.0000 - val_loss: 37862735872.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 39272325120.0000 - val_loss: 37842669568.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 39246065664.0000 - val_loss: 37823332352.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 948us/step - loss: 39216107520.0000 - val_loss: 37788708864.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39189544960.0000 - val_loss: 37761114112.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39154450432.0000 - val_loss: 37756456960.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 39137300480.0000 - val_loss: 37717262336.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 39109890048.0000 - val_loss: 37696409600.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 39074209792.0000 - val_loss: 37681856512.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 39051558912.0000 - val_loss: 37685026816.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39022604288.0000 - val_loss: 37668175872.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38988267520.0000 - val_loss: 37623033856.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 38961229824.0000 - val_loss: 37601189888.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38931714048.0000 - val_loss: 37610844160.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38906916864.0000 - val_loss: 37564112896.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38882938880.0000 - val_loss: 37555130368.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38866264064.0000 - val_loss: 37559029760.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38833606656.0000 - val_loss: 37515153408.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38812839936.0000 - val_loss: 37509734400.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38782980096.0000 - val_loss: 37489356800.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38767058944.0000 - val_loss: 37456723968.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 38733565952.0000 - val_loss: 37443031040.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38706098176.0000 - val_loss: 37444390912.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 38685024256.0000 - val_loss: 37410283520.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38662287360.0000 - val_loss: 37407711232.0000\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38640226304.0000 - val_loss: 37369061376.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 38618722304.0000 - val_loss: 37378736128.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38597246976.0000 - val_loss: 37375660032.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 38579195904.0000 - val_loss: 37357969408.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38552657920.0000 - val_loss: 37331681280.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 38525431808.0000 - val_loss: 37300400128.0000\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38510325760.0000 - val_loss: 37301489664.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38488899584.0000 - val_loss: 37311762432.0000\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 38461751296.0000 - val_loss: 37250641920.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 38446219264.0000 - val_loss: 37267062784.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38429278208.0000 - val_loss: 37250670592.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38401081344.0000 - val_loss: 37234458624.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 38380376064.0000 - val_loss: 37219594240.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38373601280.0000 - val_loss: 37202423808.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38344523776.0000 - val_loss: 37195243520.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 966us/step - loss: 38338031616.0000 - val_loss: 37186703360.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38302937088.0000 - val_loss: 37155696640.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 38281977856.0000 - val_loss: 37134454784.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38270197760.0000 - val_loss: 37147873280.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38243278848.0000 - val_loss: 37120434176.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38225592320.0000 - val_loss: 37103198208.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 38210912256.0000 - val_loss: 37093478400.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38195851264.0000 - val_loss: 37083709440.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38166556672.0000 - val_loss: 37067870208.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 38159331328.0000 - val_loss: 37099552768.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 38134251520.0000 - val_loss: 37051838464.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38111449088.0000 - val_loss: 37031759872.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 38094336000.0000 - val_loss: 37004582912.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38081552384.0000 - val_loss: 37004316672.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 38061588480.0000 - val_loss: 36981071872.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 38038253568.0000 - val_loss: 36986826752.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 38026399744.0000 - val_loss: 36972277760.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 38010978304.0000 - val_loss: 36957245440.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 37995859968.0000 - val_loss: 36941615104.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37984514048.0000 - val_loss: 36949807104.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37959045120.0000 - val_loss: 36935163904.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37943537664.0000 - val_loss: 36940451840.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37926735872.0000 - val_loss: 36929904640.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37903306752.0000 - val_loss: 36878942208.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37891137536.0000 - val_loss: 36869529600.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37873123328.0000 - val_loss: 36888514560.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37865607168.0000 - val_loss: 36831186944.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37842554880.0000 - val_loss: 36853743616.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37825560576.0000 - val_loss: 36835246080.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37807714304.0000 - val_loss: 36827041792.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37794648064.0000 - val_loss: 36807692288.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37777252352.0000 - val_loss: 36825952256.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37765095424.0000 - val_loss: 36790296576.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 900us/step - loss: 37750259712.0000 - val_loss: 36793757696.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37732995072.0000 - val_loss: 36761817088.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37722988544.0000 - val_loss: 36767436800.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37701332992.0000 - val_loss: 36751577088.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37687607296.0000 - val_loss: 36730757120.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37674332160.0000 - val_loss: 36748038144.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37660475392.0000 - val_loss: 36684365824.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37657935872.0000 - val_loss: 36698099712.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37626650624.0000 - val_loss: 36667297792.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37617577984.0000 - val_loss: 36679487488.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37601005568.0000 - val_loss: 36662431744.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37591158784.0000 - val_loss: 36657569792.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37579395072.0000 - val_loss: 36645945344.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37560078336.0000 - val_loss: 36627828736.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37545435136.0000 - val_loss: 36623048704.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37530906624.0000 - val_loss: 36618772480.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 37520072704.0000 - val_loss: 36601311232.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37499580416.0000 - val_loss: 36579803136.0000\n",
      "Epoch 457/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 913us/step - loss: 37487591424.0000 - val_loss: 36566544384.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37481189376.0000 - val_loss: 36555055104.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37460398080.0000 - val_loss: 36556902400.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37450219520.0000 - val_loss: 36566700032.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37432913920.0000 - val_loss: 36542337024.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37416448000.0000 - val_loss: 36524728320.0000\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 37404372992.0000 - val_loss: 36517904384.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37396254720.0000 - val_loss: 36510294016.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37392109568.0000 - val_loss: 36488810496.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 37368967168.0000 - val_loss: 36485169152.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37357228032.0000 - val_loss: 36474425344.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37348122624.0000 - val_loss: 36463284224.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 939us/step - loss: 37328965632.0000 - val_loss: 36453007360.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37321031680.0000 - val_loss: 36446855168.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 931us/step - loss: 37306314752.0000 - val_loss: 36448710656.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37289242624.0000 - val_loss: 36453167104.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37273526272.0000 - val_loss: 36430848000.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37263065088.0000 - val_loss: 36434583552.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37252849664.0000 - val_loss: 36425424896.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37247410176.0000 - val_loss: 36391170048.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 922us/step - loss: 37233766400.0000 - val_loss: 36369846272.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 37220188160.0000 - val_loss: 36381384704.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37207068672.0000 - val_loss: 36400627712.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 957us/step - loss: 37191933952.0000 - val_loss: 36360916992.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37194702848.0000 - val_loss: 36369281024.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37174710272.0000 - val_loss: 36367716352.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37157138432.0000 - val_loss: 36353036288.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 860us/step - loss: 37140373504.0000 - val_loss: 36341006336.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37132869632.0000 - val_loss: 36319162368.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37119307776.0000 - val_loss: 36316262400.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 37118529536.0000 - val_loss: 36310052864.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37102030848.0000 - val_loss: 36295479296.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37086691328.0000 - val_loss: 36298772480.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37084012544.0000 - val_loss: 36282929152.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 37062451200.0000 - val_loss: 36282118144.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 37059432448.0000 - val_loss: 36273659904.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 878us/step - loss: 37039853568.0000 - val_loss: 36259708928.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 904us/step - loss: 37030043648.0000 - val_loss: 36248801280.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37016338432.0000 - val_loss: 36241100800.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 37008646144.0000 - val_loss: 36202774528.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 36998324224.0000 - val_loss: 36213379072.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 36990083072.0000 - val_loss: 36194205696.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 869us/step - loss: 36980477952.0000 - val_loss: 36184068096.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 896us/step - loss: 36962418688.0000 - val_loss: 36180631552.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23df9425490>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7119090025111907"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23df9725d60>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 430311899136.0000 - val_loss: 427755438080.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429480542208.0000 - val_loss: 425884155904.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 425842671616.0000 - val_loss: 420030447616.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417258078208.0000 - val_loss: 408319295488.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402239520768.0000 - val_loss: 389626167296.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379972091904.0000 - val_loss: 363747311616.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 350630510592.0000 - val_loss: 330922917888.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315392589824.0000 - val_loss: 293367119872.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276630077440.0000 - val_loss: 253618536448.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237172113408.0000 - val_loss: 214778855424.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 200230240256.0000 - val_loss: 179919306752.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 168451424256.0000 - val_loss: 151533076480.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 143607267328.0000 - val_loss: 130413355008.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 126363287552.0000 - val_loss: 116745011200.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 115713769472.0000 - val_loss: 108789399552.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 109917134848.0000 - val_loss: 104709496832.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 107046330368.0000 - val_loss: 102796312576.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 105675038720.0000 - val_loss: 101810733056.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104913846272.0000 - val_loss: 101218336768.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104391786496.0000 - val_loss: 100748959744.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103923941376.0000 - val_loss: 100297809920.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103467933696.0000 - val_loss: 99839893504.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103012417536.0000 - val_loss: 99381010432.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102537404416.0000 - val_loss: 98881757184.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102046375936.0000 - val_loss: 98381955072.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101551628288.0000 - val_loss: 97869807616.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101020270592.0000 - val_loss: 97344495616.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 100488265728.0000 - val_loss: 96804888576.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99937107968.0000 - val_loss: 96234422272.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99366412288.0000 - val_loss: 95660310528.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98773409792.0000 - val_loss: 95064064000.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98179751936.0000 - val_loss: 94454956032.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 97559805952.0000 - val_loss: 93840449536.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96924532736.0000 - val_loss: 93182738432.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96278552576.0000 - val_loss: 92522921984.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 95612067840.0000 - val_loss: 91858501632.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94948352000.0000 - val_loss: 91171946496.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94244093952.0000 - val_loss: 90473488384.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93548912640.0000 - val_loss: 89755639808.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92811542528.0000 - val_loss: 89028493312.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92079587328.0000 - val_loss: 88279334912.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91331436544.0000 - val_loss: 87525007360.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90558423040.0000 - val_loss: 86745063424.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89785057280.0000 - val_loss: 85960589312.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89002205184.0000 - val_loss: 85166563328.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88196956160.0000 - val_loss: 84367458304.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 87413702656.0000 - val_loss: 83543760896.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 86556327936.0000 - val_loss: 82710151168.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 85711413248.0000 - val_loss: 81860837376.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 84863967232.0000 - val_loss: 80983703552.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 83987275776.0000 - val_loss: 80115286016.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 83115884544.0000 - val_loss: 79249940480.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 82225586176.0000 - val_loss: 78327627776.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 81328128000.0000 - val_loss: 77426614272.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 80391438336.0000 - val_loss: 76513001472.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 79476449280.0000 - val_loss: 75577966592.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 78538145792.0000 - val_loss: 74630152192.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 77589405696.0000 - val_loss: 73678299136.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 76628172800.0000 - val_loss: 72715952128.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 75675320320.0000 - val_loss: 71746748416.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 74703110144.0000 - val_loss: 70779666432.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 73733816320.0000 - val_loss: 69818572800.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 72767225856.0000 - val_loss: 68863713280.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 71803723776.0000 - val_loss: 67866750976.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 70819004416.0000 - val_loss: 66899283968.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 69854437376.0000 - val_loss: 65938956288.0000\n",
      "Epoch 67/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 68889755648.0000 - val_loss: 64992866304.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67941163008.0000 - val_loss: 64053780480.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67006062592.0000 - val_loss: 63137726464.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 66107879424.0000 - val_loss: 62250262528.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 65227014144.0000 - val_loss: 61378990080.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 64370155520.0000 - val_loss: 60551823360.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 63532072960.0000 - val_loss: 59730034688.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 62724300800.0000 - val_loss: 58961940480.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 61969825792.0000 - val_loss: 58217447424.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 61210595328.0000 - val_loss: 57487179776.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 60518895616.0000 - val_loss: 56814436352.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 59836456960.0000 - val_loss: 56181477376.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 59199004672.0000 - val_loss: 55536259072.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58589442048.0000 - val_loss: 54974582784.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58006122496.0000 - val_loss: 54418300928.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57479438336.0000 - val_loss: 53900439552.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56969719808.0000 - val_loss: 53435531264.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56499916800.0000 - val_loss: 52977598464.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56065900544.0000 - val_loss: 52575158272.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55644442624.0000 - val_loss: 52198207488.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55281614848.0000 - val_loss: 51853500416.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54898098176.0000 - val_loss: 51501998080.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54572109824.0000 - val_loss: 51188035584.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54269288448.0000 - val_loss: 50912002048.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54011359232.0000 - val_loss: 50661691392.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53748477952.0000 - val_loss: 50420097024.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53485535232.0000 - val_loss: 50199535616.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53265453056.0000 - val_loss: 49998004224.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53059002368.0000 - val_loss: 49816776704.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52861771776.0000 - val_loss: 49640755200.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52672307200.0000 - val_loss: 49476071424.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52489486336.0000 - val_loss: 49302032384.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52343627776.0000 - val_loss: 49155592192.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52181311488.0000 - val_loss: 49050914816.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52028121088.0000 - val_loss: 48884649984.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51916386304.0000 - val_loss: 48776929280.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51762089984.0000 - val_loss: 48690675712.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 51665448960.0000 - val_loss: 48558948352.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51529072640.0000 - val_loss: 48465383424.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51407155200.0000 - val_loss: 48334184448.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51312336896.0000 - val_loss: 48244850688.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51185967104.0000 - val_loss: 48157798400.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51078696960.0000 - val_loss: 48054382592.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50974883840.0000 - val_loss: 47958593536.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50872504320.0000 - val_loss: 47857401856.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50774831104.0000 - val_loss: 47775477760.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50660397056.0000 - val_loss: 47685722112.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50556686336.0000 - val_loss: 47604760576.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50456039424.0000 - val_loss: 47530291200.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50343800832.0000 - val_loss: 47411830784.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50242121728.0000 - val_loss: 47313854464.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50144485376.0000 - val_loss: 47214473216.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50026868736.0000 - val_loss: 47115571200.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49919078400.0000 - val_loss: 47012884480.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49813221376.0000 - val_loss: 46924656640.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49697353728.0000 - val_loss: 46809411584.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49578438656.0000 - val_loss: 46748737536.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49477300224.0000 - val_loss: 46610952192.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49363443712.0000 - val_loss: 46526210048.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49254354944.0000 - val_loss: 46421286912.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49130094592.0000 - val_loss: 46309154816.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49023840256.0000 - val_loss: 46235815936.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48921149440.0000 - val_loss: 46121615360.0000\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48798486528.0000 - val_loss: 46011588608.0000\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48691228672.0000 - val_loss: 45933117440.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48582983680.0000 - val_loss: 45843894272.0000\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48468852736.0000 - val_loss: 45718351872.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48355205120.0000 - val_loss: 45622812672.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48252604416.0000 - val_loss: 45508743168.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48139943936.0000 - val_loss: 45435297792.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48004980736.0000 - val_loss: 45402927104.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47894962176.0000 - val_loss: 45185662976.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47761211392.0000 - val_loss: 45080264704.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47641546752.0000 - val_loss: 44983136256.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47508594688.0000 - val_loss: 44853579776.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47373774848.0000 - val_loss: 44724203520.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47265673216.0000 - val_loss: 44603604992.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47114326016.0000 - val_loss: 44506554368.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46992617472.0000 - val_loss: 44384370688.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46866608128.0000 - val_loss: 44262936576.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46737596416.0000 - val_loss: 44189634560.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46616072192.0000 - val_loss: 44042379264.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46497484800.0000 - val_loss: 43949039616.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46376071168.0000 - val_loss: 43829456896.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46258061312.0000 - val_loss: 43735306240.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46135406592.0000 - val_loss: 43621117952.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46028193792.0000 - val_loss: 43520954368.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45907619840.0000 - val_loss: 43406462976.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45782315008.0000 - val_loss: 43306307584.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45679284224.0000 - val_loss: 43224924160.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45539631104.0000 - val_loss: 43107991552.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45428043776.0000 - val_loss: 42988376064.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45320916992.0000 - val_loss: 42882990080.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45187166208.0000 - val_loss: 42789773312.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45059530752.0000 - val_loss: 42674167808.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44941914112.0000 - val_loss: 42566225920.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44833902592.0000 - val_loss: 42470481920.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44716748800.0000 - val_loss: 42357977088.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44602572800.0000 - val_loss: 42282287104.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44476444672.0000 - val_loss: 42149531648.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44359057408.0000 - val_loss: 42045562880.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44254212096.0000 - val_loss: 41950896128.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44129705984.0000 - val_loss: 41888579584.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44033945600.0000 - val_loss: 41804382208.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 43912364032.0000 - val_loss: 41649831936.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43829178368.0000 - val_loss: 41564635136.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43702738944.0000 - val_loss: 41474908160.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43598729216.0000 - val_loss: 41374281728.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43496067072.0000 - val_loss: 41299140608.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43392937984.0000 - val_loss: 41220980736.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43295932416.0000 - val_loss: 41116405760.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43183288320.0000 - val_loss: 41017786368.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43082604544.0000 - val_loss: 40935600128.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 42995609600.0000 - val_loss: 40860057600.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 42877489152.0000 - val_loss: 40781844480.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 42785337344.0000 - val_loss: 40703426560.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42678448128.0000 - val_loss: 40606302208.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42570735616.0000 - val_loss: 40541229056.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42484047872.0000 - val_loss: 40415145984.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42385440768.0000 - val_loss: 40396554240.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42277675008.0000 - val_loss: 40251518976.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42191732736.0000 - val_loss: 40156807168.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42095767552.0000 - val_loss: 40090750976.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42006405120.0000 - val_loss: 39992139776.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41924567040.0000 - val_loss: 39995617280.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41819881472.0000 - val_loss: 39864041472.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41748135936.0000 - val_loss: 39811149824.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41653891072.0000 - val_loss: 39759036416.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41574879232.0000 - val_loss: 39651057664.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41498664960.0000 - val_loss: 39614672896.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41422168064.0000 - val_loss: 39576305664.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41346318336.0000 - val_loss: 39487676416.0000\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41279873024.0000 - val_loss: 39420383232.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41202577408.0000 - val_loss: 39350751232.0000\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 41134219264.0000 - val_loss: 39302164480.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41102016512.0000 - val_loss: 39274758144.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40997609472.0000 - val_loss: 39174504448.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40936669184.0000 - val_loss: 39143460864.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40865161216.0000 - val_loss: 39076044800.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40799772672.0000 - val_loss: 39047307264.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40746430464.0000 - val_loss: 38991585280.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40706076672.0000 - val_loss: 38923173888.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40641495040.0000 - val_loss: 38902124544.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40563351552.0000 - val_loss: 38838460416.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40509190144.0000 - val_loss: 38800728064.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40450772992.0000 - val_loss: 38750289920.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40385769472.0000 - val_loss: 38681894912.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40341405696.0000 - val_loss: 38631034880.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40286162944.0000 - val_loss: 38594727936.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 40225046528.0000 - val_loss: 38566248448.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40166367232.0000 - val_loss: 38509686784.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40122466304.0000 - val_loss: 38466686976.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40062750720.0000 - val_loss: 38433120256.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40009580544.0000 - val_loss: 38431494144.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39958937600.0000 - val_loss: 38367301632.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39902105600.0000 - val_loss: 38316785664.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39849869312.0000 - val_loss: 38275682304.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39812190208.0000 - val_loss: 38237138944.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39760982016.0000 - val_loss: 38201888768.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39710986240.0000 - val_loss: 38182936576.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39683104768.0000 - val_loss: 38137950208.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39620464640.0000 - val_loss: 38092169216.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39579705344.0000 - val_loss: 38068686848.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39521112064.0000 - val_loss: 38022594560.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39500120064.0000 - val_loss: 37997314048.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39448842240.0000 - val_loss: 37962379264.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39397740544.0000 - val_loss: 37915762688.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39353774080.0000 - val_loss: 37912748032.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39314272256.0000 - val_loss: 37887602688.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39270875136.0000 - val_loss: 37826547712.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39228551168.0000 - val_loss: 37809094656.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39197868032.0000 - val_loss: 37817860096.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39150571520.0000 - val_loss: 37774696448.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39107637248.0000 - val_loss: 37711486976.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39093719040.0000 - val_loss: 37692964864.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39043383296.0000 - val_loss: 37692878848.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38995218432.0000 - val_loss: 37637935104.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38956937216.0000 - val_loss: 37632856064.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38919315456.0000 - val_loss: 37604941824.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38890213376.0000 - val_loss: 37559984128.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38859186176.0000 - val_loss: 37510938624.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38811475968.0000 - val_loss: 37532565504.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38783823872.0000 - val_loss: 37562757120.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38753140736.0000 - val_loss: 37512306688.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38709936128.0000 - val_loss: 37455810560.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38677975040.0000 - val_loss: 37400764416.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38629318656.0000 - val_loss: 37458411520.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38605185024.0000 - val_loss: 37393182720.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38585634816.0000 - val_loss: 37341392896.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38534156288.0000 - val_loss: 37314154496.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38512279552.0000 - val_loss: 37305237504.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38484357120.0000 - val_loss: 37272969216.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38437191680.0000 - val_loss: 37245333504.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38398087168.0000 - val_loss: 37301448704.0000\n",
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38406467584.0000 - val_loss: 37214007296.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38342844416.0000 - val_loss: 37200908288.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38311079936.0000 - val_loss: 37168975872.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38289666048.0000 - val_loss: 37174767616.0000\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38252384256.0000 - val_loss: 37116174336.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38242754560.0000 - val_loss: 37201158144.0000\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 38233792512.0000 - val_loss: 37099245568.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38166712320.0000 - val_loss: 37063385088.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38152638464.0000 - val_loss: 37036331008.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38114234368.0000 - val_loss: 37037301760.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38096986112.0000 - val_loss: 37017325568.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38080155648.0000 - val_loss: 36999454720.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38052585472.0000 - val_loss: 36955652096.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38029627392.0000 - val_loss: 36984520704.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37997531136.0000 - val_loss: 36980146176.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37956419584.0000 - val_loss: 36901789696.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37941809152.0000 - val_loss: 36895510528.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37922156544.0000 - val_loss: 36873752576.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37900017664.0000 - val_loss: 36835385344.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37875118080.0000 - val_loss: 36837773312.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37847691264.0000 - val_loss: 36847239168.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37821878272.0000 - val_loss: 36793262080.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37798223872.0000 - val_loss: 36794392576.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37770207232.0000 - val_loss: 36762447872.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37763239936.0000 - val_loss: 36779094016.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37727395840.0000 - val_loss: 36774506496.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37704441856.0000 - val_loss: 36759662592.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37684224000.0000 - val_loss: 36765155328.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37670998016.0000 - val_loss: 36678299648.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37637484544.0000 - val_loss: 36651995136.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37618266112.0000 - val_loss: 36649279488.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37588631552.0000 - val_loss: 36663980032.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37584850944.0000 - val_loss: 36628602880.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37557465088.0000 - val_loss: 36647256064.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37535154176.0000 - val_loss: 36592480256.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37511327744.0000 - val_loss: 36568584192.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37504724992.0000 - val_loss: 36576468992.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37467643904.0000 - val_loss: 36538908672.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37453172736.0000 - val_loss: 36568850432.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37427077120.0000 - val_loss: 36516028416.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37406023680.0000 - val_loss: 36513107968.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37395640320.0000 - val_loss: 36499144704.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37375852544.0000 - val_loss: 36485390336.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37351071744.0000 - val_loss: 36451430400.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37325152256.0000 - val_loss: 36455833600.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37315981312.0000 - val_loss: 36410855424.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37292707840.0000 - val_loss: 36390428672.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37285470208.0000 - val_loss: 36396113920.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37253865472.0000 - val_loss: 36420509696.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37245227008.0000 - val_loss: 36397203456.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37210578944.0000 - val_loss: 36338286592.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37197721600.0000 - val_loss: 36344004608.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37181526016.0000 - val_loss: 36327448576.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37158268928.0000 - val_loss: 36314132480.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37145759744.0000 - val_loss: 36285739008.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37123092480.0000 - val_loss: 36271878144.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37118005248.0000 - val_loss: 36252889088.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37110124544.0000 - val_loss: 36232028160.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37074796544.0000 - val_loss: 36225335296.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37052166144.0000 - val_loss: 36252102656.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37035188224.0000 - val_loss: 36248195072.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37011664896.0000 - val_loss: 36230864896.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37017026560.0000 - val_loss: 36183662592.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36981665792.0000 - val_loss: 36196360192.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36960186368.0000 - val_loss: 36176642048.0000\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36958851072.0000 - val_loss: 36130684928.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36940320768.0000 - val_loss: 36135694336.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36908867584.0000 - val_loss: 36110970880.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36899168256.0000 - val_loss: 36196802560.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36885458944.0000 - val_loss: 36096675840.0000\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36882710528.0000 - val_loss: 36070612992.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36850151424.0000 - val_loss: 36065992704.0000\n",
      "Epoch 333/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 36836696064.0000 - val_loss: 36042293248.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36827385856.0000 - val_loss: 36054298624.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36804378624.0000 - val_loss: 36013166592.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36804710400.0000 - val_loss: 35993628672.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36791267328.0000 - val_loss: 35993452544.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36765691904.0000 - val_loss: 36017029120.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36776165376.0000 - val_loss: 35981598720.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36737327104.0000 - val_loss: 36005265408.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36721012736.0000 - val_loss: 35998515200.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36703035392.0000 - val_loss: 35938697216.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36692561920.0000 - val_loss: 35941625856.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36675092480.0000 - val_loss: 35938406400.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36663177216.0000 - val_loss: 35939323904.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36645961728.0000 - val_loss: 35922567168.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36636827648.0000 - val_loss: 35885830144.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36607004672.0000 - val_loss: 35934769152.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36623872000.0000 - val_loss: 35957252096.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36601286656.0000 - val_loss: 35871961088.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36575797248.0000 - val_loss: 35853545472.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36566626304.0000 - val_loss: 35864301568.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 35350368256.000 - 0s 1ms/step - loss: 36552847360.0000 - val_loss: 35878707200.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36545478656.0000 - val_loss: 35844108288.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36516519936.0000 - val_loss: 35842551808.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36511588352.0000 - val_loss: 35791253504.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36497362944.0000 - val_loss: 35755495424.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36497494016.0000 - val_loss: 35743903744.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36480925696.0000 - val_loss: 35748634624.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36460335104.0000 - val_loss: 35724484608.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36449034240.0000 - val_loss: 35748261888.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36423770112.0000 - val_loss: 35722907648.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36445581312.0000 - val_loss: 35721682944.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36404584448.0000 - val_loss: 35706871808.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 37305171968.000 - 0s 1ms/step - loss: 36404260864.0000 - val_loss: 35681894400.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36389109760.0000 - val_loss: 35681005568.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36375470080.0000 - val_loss: 35637542912.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36357197824.0000 - val_loss: 35684814848.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36342321152.0000 - val_loss: 35630755840.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36344438784.0000 - val_loss: 35646394368.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36329553920.0000 - val_loss: 35624951808.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36301930496.0000 - val_loss: 35601956864.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36281937920.0000 - val_loss: 35685228544.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36290416640.0000 - val_loss: 35629211648.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36272709632.0000 - val_loss: 35587751936.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36280836096.0000 - val_loss: 35560402944.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36244221952.0000 - val_loss: 35571564544.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36235247616.0000 - val_loss: 35554418688.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36224225280.0000 - val_loss: 35523170304.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36218015744.0000 - val_loss: 35487797248.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36197900288.0000 - val_loss: 35519500288.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36179525632.0000 - val_loss: 35535110144.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36177047552.0000 - val_loss: 35484958720.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36161433600.0000 - val_loss: 35502968832.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36154707968.0000 - val_loss: 35451826176.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36135952384.0000 - val_loss: 35471347712.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36129935360.0000 - val_loss: 35418759168.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36135190528.0000 - val_loss: 35436871680.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36096913408.0000 - val_loss: 35429543936.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36083400704.0000 - val_loss: 35369353216.0000\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36106760192.0000 - val_loss: 35370881024.0000\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36076564480.0000 - val_loss: 35375624192.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36049842176.0000 - val_loss: 35384348672.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36040867840.0000 - val_loss: 35364356096.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36038520832.0000 - val_loss: 35334709248.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36025389056.0000 - val_loss: 35335483392.0000\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36017283072.0000 - val_loss: 35314397184.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35997290496.0000 - val_loss: 35304615936.0000\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 35983847424.0000 - val_loss: 35326926848.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35978493952.0000 - val_loss: 35284365312.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35973316608.0000 - val_loss: 35279052800.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35949436928.0000 - val_loss: 35263229952.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35942903808.0000 - val_loss: 35267121152.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35932565504.0000 - val_loss: 35288571904.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35922804736.0000 - val_loss: 35258843136.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35910610944.0000 - val_loss: 35226812416.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35906502656.0000 - val_loss: 35239636992.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35886534656.0000 - val_loss: 35202588672.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35879301120.0000 - val_loss: 35251343360.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35867152384.0000 - val_loss: 35201097728.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35880570880.0000 - val_loss: 35191037952.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35838869504.0000 - val_loss: 35159306240.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35838181376.0000 - val_loss: 35185442816.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35818565632.0000 - val_loss: 35186663424.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35811721216.0000 - val_loss: 35107901440.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35810791424.0000 - val_loss: 35167031296.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35792556032.0000 - val_loss: 35125141504.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35779358720.0000 - val_loss: 35147493376.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35781980160.0000 - val_loss: 35153227776.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35766923264.0000 - val_loss: 35089481728.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35756756992.0000 - val_loss: 35079852032.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35744251904.0000 - val_loss: 35074617344.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35735785472.0000 - val_loss: 35074662400.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35714928640.0000 - val_loss: 35060625408.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35721895936.0000 - val_loss: 35047575552.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35694321664.0000 - val_loss: 35037741056.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35686670336.0000 - val_loss: 35014193152.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35676336128.0000 - val_loss: 35060862976.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35677474816.0000 - val_loss: 35046600704.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35655045120.0000 - val_loss: 35038040064.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35653623808.0000 - val_loss: 34990137344.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35639173120.0000 - val_loss: 35022856192.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35619139584.0000 - val_loss: 34951225344.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35633233920.0000 - val_loss: 35017334784.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35627515904.0000 - val_loss: 34915950592.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35600453632.0000 - val_loss: 34961649664.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35594416128.0000 - val_loss: 34976296960.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35606806528.0000 - val_loss: 34927775744.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35587944448.0000 - val_loss: 34940567552.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35565924352.0000 - val_loss: 34927296512.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35564298240.0000 - val_loss: 34979528704.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35552866304.0000 - val_loss: 34932232192.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35550269440.0000 - val_loss: 34966360064.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35534442496.0000 - val_loss: 34880024576.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35525758976.0000 - val_loss: 34886914048.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35523862528.0000 - val_loss: 34828746752.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35504410624.0000 - val_loss: 34850250752.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35497684992.0000 - val_loss: 34885574656.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35488337920.0000 - val_loss: 34842324992.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35482054656.0000 - val_loss: 34810982400.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35470172160.0000 - val_loss: 34831876096.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35454939136.0000 - val_loss: 34875150336.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35452071936.0000 - val_loss: 34791542784.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35442110464.0000 - val_loss: 34846466048.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35443437568.0000 - val_loss: 34788630528.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35426291712.0000 - val_loss: 34797928448.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35440271360.0000 - val_loss: 34781904896.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35406831616.0000 - val_loss: 34771898368.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35400683520.0000 - val_loss: 34788171776.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35390595072.0000 - val_loss: 34780962816.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35413737472.0000 - val_loss: 34757128192.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35393662976.0000 - val_loss: 34794553344.0000\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 34931417088.000 - 0s 1ms/step - loss: 35382296576.0000 - val_loss: 34778247168.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35360903168.0000 - val_loss: 34775576576.0000\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 35348287488.0000 - val_loss: 34717233152.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35347062784.0000 - val_loss: 34737979392.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35342532608.0000 - val_loss: 34716356608.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35339116544.0000 - val_loss: 34684272640.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35325845504.0000 - val_loss: 34725781504.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35327229952.0000 - val_loss: 34721009664.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35317645312.0000 - val_loss: 34725326848.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35310546944.0000 - val_loss: 34648338432.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35283898368.0000 - val_loss: 34694086656.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35289235456.0000 - val_loss: 34725908480.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35281510400.0000 - val_loss: 34658861056.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35280674816.0000 - val_loss: 34638946304.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35263922176.0000 - val_loss: 34691051520.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35258724352.0000 - val_loss: 34603794432.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35248738304.0000 - val_loss: 34633392128.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35237715968.0000 - val_loss: 34605273088.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35232964608.0000 - val_loss: 34602610688.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35225149440.0000 - val_loss: 34622771200.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35220357120.0000 - val_loss: 34640293888.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35228786688.0000 - val_loss: 34574938112.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35206479872.0000 - val_loss: 34591657984.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35196203008.0000 - val_loss: 34566230016.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35198230528.0000 - val_loss: 34561949696.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35176816640.0000 - val_loss: 34513915904.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35184431104.0000 - val_loss: 34518695936.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35180658688.0000 - val_loss: 34496745472.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35171004416.0000 - val_loss: 34489745408.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35183001600.0000 - val_loss: 34527571968.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35152744448.0000 - val_loss: 34488008704.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35136303104.0000 - val_loss: 34532667392.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35141230592.0000 - val_loss: 34507845632.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35134365696.0000 - val_loss: 34489606144.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35132137472.0000 - val_loss: 34504404992.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35123040256.0000 - val_loss: 34451255296.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35117699072.0000 - val_loss: 34491686912.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 35116683264.0000 - val_loss: 34423992320.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23df9771e50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7244856442096482"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23dfab0c670>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result shows that as the number of unit increases the r2 score increases and the scatter points are more aligned with the y_test line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
