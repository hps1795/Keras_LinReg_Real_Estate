{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  10/13/2014  221900.0         3       1.00         1180   \n",
       "1  6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2  5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3  2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4  1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors waterfront  view  ...          grade sqft_above  \\\n",
       "0      5650     1.0        NaN  NONE  ...      7 Average       1180   \n",
       "1      7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2     10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3      5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4      8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "\n",
       "   sqft_basement yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0            0.0     1955           0.0    98178  47.5112 -122.257   \n",
       "1          400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2            0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3          910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4            0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop irrelevant column 'id'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are planning to use MinMaxScaler for scaling. This scaling converts maximum value to 1 and minimum to 0 and distribute the values. Column 'zipcode' is not suitable to be applied to this scaler so we will drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('zipcode', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     19075\n",
       "YES      146\n",
       "Name: waterfront, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.waterfront.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NONE         19422\n",
       "AVERAGE        957\n",
       "GOOD           508\n",
       "FAIR           330\n",
       "EXCELLENT      317\n",
       "Name: view, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       17011\n",
       "2014.0       73\n",
       "2003.0       31\n",
       "2013.0       31\n",
       "2007.0       30\n",
       "          ...  \n",
       "1946.0        1\n",
       "1959.0        1\n",
       "1971.0        1\n",
       "1951.0        1\n",
       "1954.0        1\n",
       "Name: yr_renovated, Length: 70, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.yr_renovated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot find the strong correlation with the price for those columns because they have more than 80% of the rows with same value. Therefore, we will drop the columns above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['waterfront', 'view', 'yr_renovated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "0  10/13/2014  221900.0         3       1.00         1180      5650     1.0   \n",
       "1   12/9/2014  538000.0         3       2.25         2570      7242     2.0   \n",
       "2   2/25/2015  180000.0         2       1.00          770     10000     1.0   \n",
       "3   12/9/2014  604000.0         4       3.00         1960      5000     1.0   \n",
       "4   2/18/2015  510000.0         3       2.00         1680      8080     1.0   \n",
       "\n",
       "   condition          grade  sqft_above sqft_basement  yr_built      lat  \\\n",
       "0    Average      7 Average        1180           0.0      1955  47.5112   \n",
       "1    Average      7 Average        2170         400.0      1951  47.7210   \n",
       "2    Average  6 Low Average         770           0.0      1933  47.7379   \n",
       "3  Very Good      7 Average        1050         910.0      1965  47.5208   \n",
       "4    Average         8 Good        1680           0.0      1987  47.6168   \n",
       "\n",
       "      long  sqft_living15  sqft_lot15  \n",
       "0 -122.257           1340        5650  \n",
       "1 -122.319           1690        7639  \n",
       "2 -122.233           2720        8062  \n",
       "3 -122.393           1360        5000  \n",
       "4 -122.045           1800        7503  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 16 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           21597 non-null  object \n",
      " 1   price          21597 non-null  float64\n",
      " 2   bedrooms       21597 non-null  int64  \n",
      " 3   bathrooms      21597 non-null  float64\n",
      " 4   sqft_living    21597 non-null  int64  \n",
      " 5   sqft_lot       21597 non-null  int64  \n",
      " 6   floors         21597 non-null  float64\n",
      " 7   condition      21597 non-null  object \n",
      " 8   grade          21597 non-null  object \n",
      " 9   sqft_above     21597 non-null  int64  \n",
      " 10  sqft_basement  21597 non-null  object \n",
      " 11  yr_built       21597 non-null  int64  \n",
      " 12  lat            21597 non-null  float64\n",
      " 13  long           21597 non-null  float64\n",
      " 14  sqft_living15  21597 non-null  int64  \n",
      " 15  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(5), int64(7), object(4)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets deal with the columns with object data type and convert them into int64 or float64 to pass it into keras model. Columns we will make a change are:\n",
    "- date\n",
    "- condition\n",
    "- grade\n",
    "- sqft_basement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert column 'date' into new columns 'month' and 'year'. After creating new columns, 'date' column is not needed so it can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].apply(lambda date:date.month)\n",
    "df['year'] = df['date'].apply(lambda date:date.year)\n",
    "df = df.drop('date',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns 'condition' and 'grade' has object entries. We will create the dictionary listing the original entries and the number entries that corresponds to the original entries. Then, we will replace the values in that column using the dictionary we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Average      14020\n",
       "Good          5677\n",
       "Very Good     1701\n",
       "Fair           170\n",
       "Poor            29\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_replace = {'Poor': 1, 'Fair': 2, 'Average': 3, 'Good': 4, 'Very Good': 5}\n",
    "df[\"condition\"].replace(condition_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7 Average        8974\n",
       "8 Good           6065\n",
       "9 Better         2615\n",
       "6 Low Average    2038\n",
       "10 Very Good     1134\n",
       "11 Excellent      399\n",
       "5 Fair            242\n",
       "12 Luxury          89\n",
       "4 Low              27\n",
       "13 Mansion         13\n",
       "3 Poor              1\n",
       "Name: grade, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_replace = {'3 Poor': 3, '4 Low': 4, '5 Fair': 5, '6 Low Average': 6, \n",
    "                 '7 Average': 7, '8 Good': 8, '9 Better': 9 ,'10 Very Good': 10, \n",
    "                 '11 Excellent':11, '12 Luxury': 12, '13 Mansion': 13}\n",
    "df[\"grade\"].replace(grade_replace, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will convert the data type of 'sqft basement' into int64 or float64. Lets first check the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       12826\n",
       "?           454\n",
       "600.0       217\n",
       "500.0       209\n",
       "700.0       208\n",
       "          ...  \n",
       "906.0         1\n",
       "935.0         1\n",
       "295.0         1\n",
       "1481.0        1\n",
       "1284.0        1\n",
       "Name: sqft_basement, Length: 304, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sqft_basement.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a value '?' which will prevent us from converting the data type. We will replace the '?' to 0 and then convert the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sqft_basement'].replace({'?': 0},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['sqft_basement'] = df['sqft_basement'].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if every change has been made properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  condition  \\\n",
       "0  221900.0         3       1.00         1180      5650     1.0          3   \n",
       "1  538000.0         3       2.25         2570      7242     2.0          3   \n",
       "2  180000.0         2       1.00          770     10000     1.0          3   \n",
       "3  604000.0         4       3.00         1960      5000     1.0          5   \n",
       "4  510000.0         3       2.00         1680      8080     1.0          3   \n",
       "\n",
       "   grade  sqft_above  sqft_basement  yr_built      lat     long  \\\n",
       "0      7        1180            0.0      1955  47.5112 -122.257   \n",
       "1      7        2170          400.0      1951  47.7210 -122.319   \n",
       "2      6         770            0.0      1933  47.7379 -122.233   \n",
       "3      7        1050          910.0      1965  47.5208 -122.393   \n",
       "4      8        1680            0.0      1987  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  month  year  \n",
       "0           1340        5650     10  2014  \n",
       "1           1690        7639     12  2014  \n",
       "2           2720        8062      2  2015  \n",
       "3           1360        5000     12  2014  \n",
       "4           1800        7503      2  2015  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   price          21597 non-null  float64\n",
      " 1   bedrooms       21597 non-null  int64  \n",
      " 2   bathrooms      21597 non-null  float64\n",
      " 3   sqft_living    21597 non-null  int64  \n",
      " 4   sqft_lot       21597 non-null  int64  \n",
      " 5   floors         21597 non-null  float64\n",
      " 6   condition      21597 non-null  int64  \n",
      " 7   grade          21597 non-null  int64  \n",
      " 8   sqft_above     21597 non-null  int64  \n",
      " 9   sqft_basement  21597 non-null  float64\n",
      " 10  yr_built       21597 non-null  int64  \n",
      " 11  lat            21597 non-null  float64\n",
      " 12  long           21597 non-null  float64\n",
      " 13  sqft_living15  21597 non-null  int64  \n",
      " 14  sqft_lot15     21597 non-null  int64  \n",
      " 15  month          21597 non-null  int64  \n",
      " 16  year           21597 non-null  int64  \n",
      "dtypes: float64(6), int64(11)\n",
      "memory usage: 2.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD! Now we have everything set. We will move on to next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first set the X and y. y will be our target variable and the X will be the rest. In my phase 2 project from flatiron school, 'price' was our target object. Therefore, we will set 'price' as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price',axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the train test split from the scikit learn library. to split the X and y into train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use MinMaxScaler from sklearn library to scale the X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scaling, fit applies only for train set while transform applies to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11337, 16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6480, 16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3780, 16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a model using keras from tensorflow library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (16,))) \n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dense(1))             \n",
    "    model.compile(optimizer='adam',loss='mean_squared_error') \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 426329112576.0000 - val_loss: 440019517440.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 426302701568.0000 - val_loss: 439964139520.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 426202529792.0000 - val_loss: 439803052032.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 425972629504.0000 - val_loss: 439483924480.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 425565028352.0000 - val_loss: 438961537024.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 424939651072.0000 - val_loss: 438196928512.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 424061075456.0000 - val_loss: 437156642816.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 422898958336.0000 - val_loss: 435812630528.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 421429936128.0000 - val_loss: 434132746240.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 419591356416.0000 - val_loss: 432050536448.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417355825152.0000 - val_loss: 429558890496.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 414728159232.0000 - val_loss: 426672914432.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411666055168.0000 - val_loss: 423282704384.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 408117936128.0000 - val_loss: 419417358336.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 404103299072.0000 - val_loss: 415034310656.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 399548678144.0000 - val_loss: 410131955712.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 394502668288.0000 - val_loss: 404723531776.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 388991844352.0000 - val_loss: 398863564800.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383043665920.0000 - val_loss: 392529018880.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 376656723968.0000 - val_loss: 385785364480.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 369856217088.0000 - val_loss: 378630438912.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 362652958720.0000 - val_loss: 371051397120.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 355073916928.0000 - val_loss: 363106566144.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 347145732096.0000 - val_loss: 354837233664.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338900615168.0000 - val_loss: 346239696896.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 330355539968.0000 - val_loss: 337319460864.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 321558675456.0000 - val_loss: 328189247488.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 312539906048.0000 - val_loss: 318847287296.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 303327248384.0000 - val_loss: 309326315520.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293932662784.0000 - val_loss: 299617189888.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284439871488.0000 - val_loss: 289850458112.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 274872844288.0000 - val_loss: 279988207616.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 265258205184.0000 - val_loss: 270124056576.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 255623331840.0000 - val_loss: 260230791168.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 246045638656.0000 - val_loss: 250429472768.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236563021824.0000 - val_loss: 240720969728.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 227193667584.0000 - val_loss: 231124140032.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 217959710720.0000 - val_loss: 221712760832.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 208942022656.0000 - val_loss: 212582957056.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 200154808320.0000 - val_loss: 203647008768.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 191628034048.0000 - val_loss: 194931900416.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 183448256512.0000 - val_loss: 186646413312.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 175612116992.0000 - val_loss: 178723078144.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 168151646208.0000 - val_loss: 171185324032.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 161053573120.0000 - val_loss: 164057956352.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 154400571392.0000 - val_loss: 157345824768.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 148211564544.0000 - val_loss: 151091757056.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 142455554048.0000 - val_loss: 145377804288.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 137169805312.0000 - val_loss: 140082331648.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 132352368640.0000 - val_loss: 135285776384.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 128023412736.0000 - val_loss: 131001819136.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 124133400576.0000 - val_loss: 127111307264.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 120723759104.0000 - val_loss: 123703074816.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 117768830976.0000 - val_loss: 120731803648.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 115205890048.0000 - val_loss: 118205546496.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 113039753216.0000 - val_loss: 116034863104.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 111205359616.0000 - val_loss: 114239184896.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 109697613824.0000 - val_loss: 112692207616.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 108466405376.0000 - val_loss: 111460098048.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 107479441408.0000 - val_loss: 110474207232.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 106692370432.0000 - val_loss: 109643358208.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 106067755008.0000 - val_loss: 108996476928.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 105569517568.0000 - val_loss: 108481830912.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 105166036992.0000 - val_loss: 108026675200.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104846114816.0000 - val_loss: 107669364736.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104588582912.0000 - val_loss: 107377385472.0000\n",
      "Epoch 67/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 104368234496.0000 - val_loss: 107121418240.0000\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104154013696.0000 - val_loss: 106872102912.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103977385984.0000 - val_loss: 106651836416.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103795220480.0000 - val_loss: 106454196224.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 103620902912.0000 - val_loss: 106253893632.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103449346048.0000 - val_loss: 106055278592.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 103275364352.0000 - val_loss: 105864462336.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103100203008.0000 - val_loss: 105656901632.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102919299072.0000 - val_loss: 105458008064.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102738968576.0000 - val_loss: 105257361408.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102548946944.0000 - val_loss: 105050046464.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102360604672.0000 - val_loss: 104842649600.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102165438464.0000 - val_loss: 104626724864.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101972557824.0000 - val_loss: 104414109696.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 101770149888.0000 - val_loss: 104197054464.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 101567479808.0000 - val_loss: 103984898048.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101371297792.0000 - val_loss: 103763263488.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 101158469632.0000 - val_loss: 103531446272.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 100949172224.0000 - val_loss: 103321075712.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 100728004608.0000 - val_loss: 103065788416.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 100518731776.0000 - val_loss: 102842720256.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 100307845120.0000 - val_loss: 102624641024.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 100094992384.0000 - val_loss: 102394503168.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99875643392.0000 - val_loss: 102168223744.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 99656007680.0000 - val_loss: 101918638080.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99431481344.0000 - val_loss: 101676933120.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 99206635520.0000 - val_loss: 101431312384.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98980995072.0000 - val_loss: 101194776576.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 98755796992.0000 - val_loss: 100954415104.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98526298112.0000 - val_loss: 100702289920.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 98296045568.0000 - val_loss: 100450983936.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 98066382848.0000 - val_loss: 100206526464.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 97838596096.0000 - val_loss: 99968729088.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 97602527232.0000 - val_loss: 99715956736.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 97373790208.0000 - val_loss: 99462193152.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 97134551040.0000 - val_loss: 99205726208.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 96901414912.0000 - val_loss: 98952372224.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 96662552576.0000 - val_loss: 98697093120.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 96422625280.0000 - val_loss: 98444836864.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 96185237504.0000 - val_loss: 98194358272.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 95950774272.0000 - val_loss: 97931149312.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 95705120768.0000 - val_loss: 97683046400.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 95462506496.0000 - val_loss: 97421533184.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 95223136256.0000 - val_loss: 97156153344.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 94973116416.0000 - val_loss: 96889544704.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 94732034048.0000 - val_loss: 96633135104.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 94488715264.0000 - val_loss: 96378658816.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94244929536.0000 - val_loss: 96095133696.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93996974080.0000 - val_loss: 95839313920.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93746102272.0000 - val_loss: 95585615872.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93495926784.0000 - val_loss: 95303032832.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93243744256.0000 - val_loss: 95030296576.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92993323008.0000 - val_loss: 94776696832.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92744359936.0000 - val_loss: 94504697856.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92492906496.0000 - val_loss: 94230659072.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 92239609856.0000 - val_loss: 93955424256.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 91985117184.0000 - val_loss: 93697097728.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91729100800.0000 - val_loss: 93427712000.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91474165760.0000 - val_loss: 93143515136.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91220729856.0000 - val_loss: 92877750272.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90963836928.0000 - val_loss: 92606005248.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90714570752.0000 - val_loss: 92333064192.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90453082112.0000 - val_loss: 92050604032.0000\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90191257600.0000 - val_loss: 91773329408.0000\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89928728576.0000 - val_loss: 91504664576.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89670336512.0000 - val_loss: 91205468160.0000\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 89413681152.0000 - val_loss: 90933829632.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89148645376.0000 - val_loss: 90657366016.0000\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88886059008.0000 - val_loss: 90379747328.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88619409408.0000 - val_loss: 90083426304.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88355315712.0000 - val_loss: 89803636736.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88094490624.0000 - val_loss: 89526632448.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 87828873216.0000 - val_loss: 89252134912.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 87558496256.0000 - val_loss: 88961835008.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 87290085376.0000 - val_loss: 88682168320.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 87018823680.0000 - val_loss: 88378966016.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 86754254848.0000 - val_loss: 88080465920.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 86479904768.0000 - val_loss: 87807344640.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 86212837376.0000 - val_loss: 87514456064.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 85939085312.0000 - val_loss: 87207231488.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 85661081600.0000 - val_loss: 86936993792.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 85390213120.0000 - val_loss: 86627311616.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 85109964800.0000 - val_loss: 86332571648.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 84831690752.0000 - val_loss: 86031646720.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 84555137024.0000 - val_loss: 85733605376.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 84279099392.0000 - val_loss: 85448425472.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 84003528704.0000 - val_loss: 85145346048.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 83721674752.0000 - val_loss: 84855136256.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 83440721920.0000 - val_loss: 84549484544.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 83153289216.0000 - val_loss: 84240941056.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 82875129856.0000 - val_loss: 83936468992.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 82587787264.0000 - val_loss: 83639623680.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 82304729088.0000 - val_loss: 83342614528.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 82025013248.0000 - val_loss: 83025231872.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 81738588160.0000 - val_loss: 82717138944.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 81452015616.0000 - val_loss: 82417303552.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 81165049856.0000 - val_loss: 82117328896.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 80881082368.0000 - val_loss: 81809825792.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 80589414400.0000 - val_loss: 81487101952.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 80298131456.0000 - val_loss: 81177518080.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 80006193152.0000 - val_loss: 80865320960.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 79714861056.0000 - val_loss: 80557613056.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 79422029824.0000 - val_loss: 80238059520.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 79128838144.0000 - val_loss: 79925608448.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 78834065408.0000 - val_loss: 79624806400.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 78545608704.0000 - val_loss: 79294824448.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 78246445056.0000 - val_loss: 78983421952.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 77953089536.0000 - val_loss: 78664359936.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 77657358336.0000 - val_loss: 78355668992.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 77363363840.0000 - val_loss: 78030397440.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 77068468224.0000 - val_loss: 77716709376.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 76781338624.0000 - val_loss: 77414490112.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 76485099520.0000 - val_loss: 77099687936.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 76201967616.0000 - val_loss: 76792111104.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 75907899392.0000 - val_loss: 76484624384.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 75616526336.0000 - val_loss: 76170969088.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 75325841408.0000 - val_loss: 75860303872.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 75039006720.0000 - val_loss: 75552612352.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 74739490816.0000 - val_loss: 75231617024.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 74446413824.0000 - val_loss: 74907533312.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 74145447936.0000 - val_loss: 74594590720.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 73843949568.0000 - val_loss: 74266451968.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 73544949760.0000 - val_loss: 73948061696.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 73242107904.0000 - val_loss: 73616015360.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 72940142592.0000 - val_loss: 73283133440.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 72632991744.0000 - val_loss: 72960688128.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 72332992512.0000 - val_loss: 72640126976.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 72030650368.0000 - val_loss: 72314667008.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 71730044928.0000 - val_loss: 71991697408.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 71431864320.0000 - val_loss: 71672815616.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 71130644480.0000 - val_loss: 71344177152.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 70825189376.0000 - val_loss: 71028899840.0000\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 70524084224.0000 - val_loss: 70706388992.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 70223945728.0000 - val_loss: 70374047744.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 69918711808.0000 - val_loss: 70045245440.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 69617041408.0000 - val_loss: 69713608704.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 69314715648.0000 - val_loss: 69393211392.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 69014626304.0000 - val_loss: 69075984384.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 68716236800.0000 - val_loss: 68747755520.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 68423888896.0000 - val_loss: 68447879168.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 68126822400.0000 - val_loss: 68112367616.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67834548224.0000 - val_loss: 67800436736.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67546726400.0000 - val_loss: 67490283520.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67251564544.0000 - val_loss: 67179892736.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 66963648512.0000 - val_loss: 66872573952.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 66675073024.0000 - val_loss: 66553749504.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 66388512768.0000 - val_loss: 66249674752.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 66104553472.0000 - val_loss: 65934409728.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 65819328512.0000 - val_loss: 65639505920.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 65536475136.0000 - val_loss: 65334149120.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 65261740032.0000 - val_loss: 65021550592.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 64979767296.0000 - val_loss: 64724553728.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 64699539456.0000 - val_loss: 64428224512.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 64424419328.0000 - val_loss: 64128442368.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 64152825856.0000 - val_loss: 63829639168.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 63877718016.0000 - val_loss: 63535591424.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 63610949632.0000 - val_loss: 63239000064.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 63348490240.0000 - val_loss: 62959054848.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 63082037248.0000 - val_loss: 62674972672.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 62819897344.0000 - val_loss: 62384201728.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 62559997952.0000 - val_loss: 62097661952.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 62301011968.0000 - val_loss: 61817135104.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 62044602368.0000 - val_loss: 61548122112.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 61793632256.0000 - val_loss: 61271920640.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 61547708416.0000 - val_loss: 61002883072.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 61300563968.0000 - val_loss: 60743770112.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 61060968448.0000 - val_loss: 60482334720.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 60818636800.0000 - val_loss: 60220702720.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 60586778624.0000 - val_loss: 59954380800.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 60346998784.0000 - val_loss: 59701096448.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 60127055872.0000 - val_loss: 59461795840.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 59887796224.0000 - val_loss: 59195232256.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 59665178624.0000 - val_loss: 58955714560.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 59445329920.0000 - val_loss: 58714288128.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 59227156480.0000 - val_loss: 58473627648.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 59009757184.0000 - val_loss: 58236522496.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58799132672.0000 - val_loss: 58013908992.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58594177024.0000 - val_loss: 57776001024.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58388226048.0000 - val_loss: 57555427328.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 58192044032.0000 - val_loss: 57334259712.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57995632640.0000 - val_loss: 57116246016.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57807036416.0000 - val_loss: 56910630912.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57616330752.0000 - val_loss: 56709955584.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 57438154752.0000 - val_loss: 56506609664.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57262804992.0000 - val_loss: 56304623616.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57080389632.0000 - val_loss: 56117829632.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56909991936.0000 - val_loss: 55923683328.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56743051264.0000 - val_loss: 55733547008.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 56576491520.0000 - val_loss: 55553855488.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 56417906688.0000 - val_loss: 55382675456.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 56254205952.0000 - val_loss: 55201144832.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 56101842944.0000 - val_loss: 55022211072.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 55961382912.0000 - val_loss: 54848065536.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55799726080.0000 - val_loss: 54688612352.0000\n",
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55656022016.0000 - val_loss: 54532554752.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55516876800.0000 - val_loss: 54379560960.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 55384211456.0000 - val_loss: 54220025856.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55244292096.0000 - val_loss: 54068121600.0000\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 55114870784.0000 - val_loss: 53917147136.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54985326592.0000 - val_loss: 53773008896.0000\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54861021184.0000 - val_loss: 53630943232.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54740213760.0000 - val_loss: 53502951424.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54625472512.0000 - val_loss: 53367312384.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54500188160.0000 - val_loss: 53221781504.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54391316480.0000 - val_loss: 53091774464.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54277738496.0000 - val_loss: 52966019072.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54169190400.0000 - val_loss: 52846227456.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54063480832.0000 - val_loss: 52729679872.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53965303808.0000 - val_loss: 52606640128.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53865107456.0000 - val_loss: 52498247680.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53769535488.0000 - val_loss: 52384157696.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53673365504.0000 - val_loss: 52275924992.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53586022400.0000 - val_loss: 52170498048.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53500440576.0000 - val_loss: 52072439808.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53410054144.0000 - val_loss: 51969413120.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53320089600.0000 - val_loss: 51864780800.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53233647616.0000 - val_loss: 51771260928.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53152493568.0000 - val_loss: 51674411008.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53072728064.0000 - val_loss: 51575914496.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52994596864.0000 - val_loss: 51487809536.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52913856512.0000 - val_loss: 51405889536.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52838973440.0000 - val_loss: 51311931392.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52768407552.0000 - val_loss: 51225624576.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52690972672.0000 - val_loss: 51136811008.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52620492800.0000 - val_loss: 51052179456.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52547063808.0000 - val_loss: 50974760960.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52476698624.0000 - val_loss: 50893873152.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52409335808.0000 - val_loss: 50807943168.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52337999872.0000 - val_loss: 50731814912.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52272123904.0000 - val_loss: 50658082816.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52202651648.0000 - val_loss: 50572034048.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52136177664.0000 - val_loss: 50492768256.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 887us/step - loss: 52073607168.0000 - val_loss: 50426388480.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52010258432.0000 - val_loss: 50340294656.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51944398848.0000 - val_loss: 50273685504.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51878199296.0000 - val_loss: 50200862720.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51814227968.0000 - val_loss: 50126942208.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51754074112.0000 - val_loss: 50052419584.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51691339776.0000 - val_loss: 49975865344.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51627085824.0000 - val_loss: 49904410624.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51565494272.0000 - val_loss: 49839521792.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51503616000.0000 - val_loss: 49767047168.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51438657536.0000 - val_loss: 49696542720.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51380150272.0000 - val_loss: 49626411008.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51317047296.0000 - val_loss: 49555333120.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51256999936.0000 - val_loss: 49483755520.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51198107648.0000 - val_loss: 49410904064.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51131293696.0000 - val_loss: 49350426624.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51074260992.0000 - val_loss: 49282752512.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51010699264.0000 - val_loss: 49208508416.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50950410240.0000 - val_loss: 49144025088.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50888966144.0000 - val_loss: 49073082368.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50831716352.0000 - val_loss: 49001508864.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50771042304.0000 - val_loss: 48934772736.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50706894848.0000 - val_loss: 48862355456.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50648510464.0000 - val_loss: 48789852160.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50588901376.0000 - val_loss: 48732114944.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50525343744.0000 - val_loss: 48658829312.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50470842368.0000 - val_loss: 48593911808.0000\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50410807296.0000 - val_loss: 48532533248.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50358427648.0000 - val_loss: 48468254720.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50296463360.0000 - val_loss: 48403013632.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50236997632.0000 - val_loss: 48343564288.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50185568256.0000 - val_loss: 48282058752.0000\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 50134007808.0000 - val_loss: 48215371776.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50078691328.0000 - val_loss: 48158892032.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50022285312.0000 - val_loss: 48103202816.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49971699712.0000 - val_loss: 48045580288.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49917202432.0000 - val_loss: 47985225728.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49872412672.0000 - val_loss: 47923572736.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49814724608.0000 - val_loss: 47862472704.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49762967552.0000 - val_loss: 47804084224.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49713704960.0000 - val_loss: 47757377536.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49662259200.0000 - val_loss: 47695585280.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49612533760.0000 - val_loss: 47632539648.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49560481792.0000 - val_loss: 47583780864.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49514835968.0000 - val_loss: 47528206336.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49469865984.0000 - val_loss: 47469477888.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49416019968.0000 - val_loss: 47419133952.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49378942976.0000 - val_loss: 47371526144.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49330114560.0000 - val_loss: 47314235392.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49279782912.0000 - val_loss: 47259742208.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49239678976.0000 - val_loss: 47214473216.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49192628224.0000 - val_loss: 47162515456.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49143533568.0000 - val_loss: 47112392704.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49104277504.0000 - val_loss: 47063908352.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49059356672.0000 - val_loss: 47020945408.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49016254464.0000 - val_loss: 46966300672.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48971501568.0000 - val_loss: 46926823424.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48928968704.0000 - val_loss: 46874980352.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48891211776.0000 - val_loss: 46828732416.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48844750848.0000 - val_loss: 46790103040.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48810680320.0000 - val_loss: 46737256448.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48762568704.0000 - val_loss: 46687260672.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48730333184.0000 - val_loss: 46650372096.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48687796224.0000 - val_loss: 46590967808.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 48635461632.0000 - val_loss: 46545367040.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48594374656.0000 - val_loss: 46502232064.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48552996864.0000 - val_loss: 46452183040.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48509468672.0000 - val_loss: 46404009984.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48470028288.0000 - val_loss: 46354370560.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48427827200.0000 - val_loss: 46307246080.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48386007040.0000 - val_loss: 46261862400.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48344567808.0000 - val_loss: 46209593344.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48297029632.0000 - val_loss: 46167781376.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48255643648.0000 - val_loss: 46121586688.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48207835136.0000 - val_loss: 46067105792.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48169320448.0000 - val_loss: 46018658304.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48124407808.0000 - val_loss: 45970751488.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48080424960.0000 - val_loss: 45921767424.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48035573760.0000 - val_loss: 45877444608.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47993233408.0000 - val_loss: 45828259840.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47951208448.0000 - val_loss: 45784481792.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47907221504.0000 - val_loss: 45737656320.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47865131008.0000 - val_loss: 45695266816.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47826526208.0000 - val_loss: 45649633280.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47780106240.0000 - val_loss: 45601226752.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47739105280.0000 - val_loss: 45554290688.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47699054592.0000 - val_loss: 45499326464.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47655280640.0000 - val_loss: 45453688832.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47612182528.0000 - val_loss: 45415604224.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47572303872.0000 - val_loss: 45364121600.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47535247360.0000 - val_loss: 45320318976.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47495057408.0000 - val_loss: 45280428032.0000\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47458058240.0000 - val_loss: 45238820864.0000\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47419273216.0000 - val_loss: 45202006016.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47380291584.0000 - val_loss: 45157593088.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47342968832.0000 - val_loss: 45110681600.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47305056256.0000 - val_loss: 45071187968.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47270891520.0000 - val_loss: 45034590208.0000\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 47231754240.0000 - val_loss: 44995952640.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47197425664.0000 - val_loss: 44960927744.0000\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47158669312.0000 - val_loss: 44914098176.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47131033600.0000 - val_loss: 44875878400.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47094456320.0000 - val_loss: 44845174784.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47062585344.0000 - val_loss: 44805263360.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47029354496.0000 - val_loss: 44776046592.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46992924672.0000 - val_loss: 44724875264.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46962176000.0000 - val_loss: 44690202624.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46929117184.0000 - val_loss: 44661280768.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46901170176.0000 - val_loss: 44628758528.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46872702976.0000 - val_loss: 44592029696.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46841360384.0000 - val_loss: 44559183872.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46812114944.0000 - val_loss: 44530954240.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46779875328.0000 - val_loss: 44488282112.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46752210944.0000 - val_loss: 44454359040.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46726537216.0000 - val_loss: 44425203712.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46704144384.0000 - val_loss: 44395044864.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46672863232.0000 - val_loss: 44364963840.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46648479744.0000 - val_loss: 44334043136.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46623838208.0000 - val_loss: 44304166912.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46590943232.0000 - val_loss: 44274982912.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46565744640.0000 - val_loss: 44247396352.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46539481088.0000 - val_loss: 44217741312.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46511685632.0000 - val_loss: 44195127296.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46487957504.0000 - val_loss: 44162682880.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46461399040.0000 - val_loss: 44132036608.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46436560896.0000 - val_loss: 44100206592.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46408704000.0000 - val_loss: 44075032576.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46386483200.0000 - val_loss: 44046336000.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46360776704.0000 - val_loss: 44018319360.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46338179072.0000 - val_loss: 43989307392.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46310981632.0000 - val_loss: 43963867136.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46285008896.0000 - val_loss: 43933585408.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46258601984.0000 - val_loss: 43907088384.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46237593600.0000 - val_loss: 43881758720.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46212218880.0000 - val_loss: 43851636736.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46187835392.0000 - val_loss: 43828383744.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46162702336.0000 - val_loss: 43796574208.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46139002880.0000 - val_loss: 43774287872.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46115606528.0000 - val_loss: 43750035456.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46091280384.0000 - val_loss: 43716472832.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46066769920.0000 - val_loss: 43694964736.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46043025408.0000 - val_loss: 43664691200.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46021111808.0000 - val_loss: 43640209408.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45995937792.0000 - val_loss: 43613110272.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45971111936.0000 - val_loss: 43589050368.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45951397888.0000 - val_loss: 43563286528.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45931335680.0000 - val_loss: 43541835776.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45904433152.0000 - val_loss: 43515867136.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45880778752.0000 - val_loss: 43490201600.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45858394112.0000 - val_loss: 43459977216.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45835350016.0000 - val_loss: 43443032064.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45821276160.0000 - val_loss: 43414224896.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45793239040.0000 - val_loss: 43389673472.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45771780096.0000 - val_loss: 43359870976.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45745139712.0000 - val_loss: 43339739136.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45721624576.0000 - val_loss: 43314434048.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45697200128.0000 - val_loss: 43287478272.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45677461504.0000 - val_loss: 43260985344.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45651881984.0000 - val_loss: 43239919616.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45634543616.0000 - val_loss: 43215261696.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 834us/step - loss: 45605376000.0000 - val_loss: 43190702080.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 44897415168.000 - 0s 2ms/step - loss: 45585121280.0000 - val_loss: 43167072256.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45561708544.0000 - val_loss: 43140202496.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45539115008.0000 - val_loss: 43122176000.0000\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 45520695296.0000 - val_loss: 43096055808.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45495771136.0000 - val_loss: 43067518976.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45473132544.0000 - val_loss: 43048529920.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45456068608.0000 - val_loss: 43020275712.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45432094720.0000 - val_loss: 43006738432.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45414965248.0000 - val_loss: 42974740480.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45386285056.0000 - val_loss: 42952712192.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45369651200.0000 - val_loss: 42936946688.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45341483008.0000 - val_loss: 42901102592.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45325840384.0000 - val_loss: 42882195456.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45311709184.0000 - val_loss: 42855690240.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45281873920.0000 - val_loss: 42837364736.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45270753280.0000 - val_loss: 42810359808.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45243998208.0000 - val_loss: 42790084608.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45220380672.0000 - val_loss: 42770432000.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45200965632.0000 - val_loss: 42748243968.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45178912768.0000 - val_loss: 42727485440.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 852us/step - loss: 45158109184.0000 - val_loss: 42707292160.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 913us/step - loss: 45138264064.0000 - val_loss: 42684473344.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45114654720.0000 - val_loss: 42660368384.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45095456768.0000 - val_loss: 42641448960.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45078577152.0000 - val_loss: 42621046784.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45055709184.0000 - val_loss: 42593300480.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45034778624.0000 - val_loss: 42575978496.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45014740992.0000 - val_loss: 42555523072.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44993327104.0000 - val_loss: 42530709504.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44972044288.0000 - val_loss: 42509733888.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44951367680.0000 - val_loss: 42485727232.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44936355840.0000 - val_loss: 42469048320.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44912320512.0000 - val_loss: 42441834496.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44896161792.0000 - val_loss: 42422095872.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44871909376.0000 - val_loss: 42404413440.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44857311232.0000 - val_loss: 42382819328.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44836524032.0000 - val_loss: 42357899264.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44816637952.0000 - val_loss: 42341744640.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44801253376.0000 - val_loss: 42325233664.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44782469120.0000 - val_loss: 42298806272.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44757917696.0000 - val_loss: 42272690176.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21629800730>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are planning to conduct multiple training, defining a function for creating a model will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.263291e+11</td>\n",
       "      <td>4.400195e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.263027e+11</td>\n",
       "      <td>4.399641e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262025e+11</td>\n",
       "      <td>4.398031e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.259726e+11</td>\n",
       "      <td>4.394839e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.255650e+11</td>\n",
       "      <td>4.389615e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4.483652e+10</td>\n",
       "      <td>4.235790e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4.481664e+10</td>\n",
       "      <td>4.234174e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>4.480125e+10</td>\n",
       "      <td>4.232523e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4.478247e+10</td>\n",
       "      <td>4.229881e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4.475792e+10</td>\n",
       "      <td>4.227269e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss      val_loss\n",
       "0    4.263291e+11  4.400195e+11\n",
       "1    4.263027e+11  4.399641e+11\n",
       "2    4.262025e+11  4.398031e+11\n",
       "3    4.259726e+11  4.394839e+11\n",
       "4    4.255650e+11  4.389615e+11\n",
       "..            ...           ...\n",
       "495  4.483652e+10  4.235790e+10\n",
       "496  4.481664e+10  4.234174e+10\n",
       "497  4.480125e+10  4.232523e+10\n",
       "498  4.478247e+10  4.229881e+10\n",
       "499  4.475792e+10  4.227269e+10\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows that our loss stabilizes around epoch = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first find out the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the price using the model we created using a X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127507.92410585925"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE is the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight. This shows that our prediction has average difference of $ 127507.92 from the actual price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6549076030344501"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has fair r2 score of 0.654."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2162824e4c0>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAF9CAYAAAAQg/wSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7nElEQVR4nO3deXhU5f3+8fuTECCgGBRQCCJoFTcEJC6V1gq24i5VW7XaVmultVWrtVjs4vK1Viqt2p91Ke5aF1wAUVtxAZWqqMGALIJaRCGooBJcCBKS5/fHycxkwqzJzJxzJu/XdXnBczLLhwFz7jyrOecEAACAeCV+FwAAABBEhCQAAIAECEkAAAAJEJIAAAASICQBAAAkQEgCAABIIG8hycxuN7M1ZrYow8d/38yWmNliM7svX3UBAABkwvK1T5KZHSzpC0l3O+f2TvPYXSU9KGm0c26dmfVxzq3JS2EAAAAZyFtPknPuBUmftrxmZruY2ZNmNs/M5pjZ7s1fOkvSDc65dc3PJSABAABfFXpO0mRJ5zrnRkj6jaQbm6/vJmk3M3vRzOaa2eEFrgsAACBOp0K9kZltJekgSQ+ZWeRylxZ17CrpEEn9Jc0xs72dc3WFqg8AAKClgoUkeb1Wdc65YQm+tkrSXOdcg6R3zWyZvND0WgHrAwAAiCrYcJtz7jN5Aeh7kmSeoc1fni5pVPP1XvKG35YXqjYAAIDW8rkFwP2SXpY02MxWmdmZkk6VdKaZLZC0WNJxzQ+fKekTM1siabak8c65T/JVGwAAQDp52wIAAAAgzNhxGwAAIAFCEgAAQAJ5Wd3Wq1cvN3DgwHy8NAAAQE7NmzfvY+dc79bX8xKSBg4cqOrq6ny8NAAAQE6Z2XuJrjPcBgAAkAAhCQAAIAFCEgAAQAKEJAAAgAQISQAAAAkQkgAAABIgJAEAACRASAIAAEiAkAQAAJAAIQkAACABQhIAAEAChCQAABA8770nzZnjawlpD7g1s8GSprS4tLOkS5xz1+WrKAAA0EF99ZU0YoS0eLHXds63UtL2JDnnljnnhjnnhkkaIWmDpGn5LgwAAHQwv/+91LVrLCA98ICv5aTtSWrlUEn/c869l49iAABAB/TMM9J3vhNr//CH0l13SWb+1aTsQ9LJku5P9AUzGydpnCQNGDCgnWUBAICi98EHUr9+sfY223hzkbbZxr+aWsh44raZdZZ0rKSHEn3dOTfZOVflnKvq3bt3ruoDAADFprFRGj06PiBVV0t1dYEJSFJ2q9uOkPS6c+6jfBUDAACK3LXXSp06SbNne+3rr/cmZ48Y4W9dCWQz3HaKkgy1AQAApPTqq9IBB8TaY8ZITzwhlZb6V1MaGYUkM+sm6TuSfpbfcgAAQFFZt07q29db2h/x4YfS9tv7V1OGMhpuc85tcM5t55xbn++CAABAEXBOOvlkadttYwHp2We96yEISBI7bgMAgFy7+26ppESa0rwX9SWXeOFo9Gh/68pStlsAAAAAJPbmm9Kee8baw4ZJc+dKXbr4VlJ7EJIAAED7bNjghaP3Wuw1vXy5NGiQfzXlAMNtAACg7c4/X+rePRaQpk71htZCHpAkepIAAEBbPP64dMwxsfbZZ0s33OD7USK5REgCAACZe+89aeDAWLtfP2nZMmmrrXwrKV8YbgMAAOk1NEj77x8fkBYulGprizIgSYQkAACQzpVXSp07S6+95rVvu82bd7T33v7WlWcMtwEAgMTmzJEOPjjWPuEE6cEHvT2QOgBCEgAAiLd2rdSnT6xdWip99JG03Xb+1eSDjhEFAQBAek1N3oq1lgHpxRelzZs7XECSCEkAAECSbr7Z6zF6/HGvPXGiN+/ooIP8rctHDLcBANCRzZ8vDR8ea3/zm9KsWVInIgKfAAAAHdHnn3u7Yn/ySezaypVS//7+1RQwDLcBANCROCedeabUo0csIP373951AlIcQhIAAB1FZPn+7bd77d/8xgtHRxzhb10BxXAbAADF7p13pF13jbV33VVasEAqL/evphCgJwkAgGK1caO0557xAWnpUumttwhIGSAkAQBQjH73Oy8Ivfmm177vPm9obfBgf+sKEYbbAAAoJk8/LR12WKz94x9Ld9whmflXU0gRkgAAKAarV0uVlbH2NttI773n/Yo2YbgNAIAwa2yURo+OD0jV1VJdHQGpnQhJAACE1TXXeDtjz57ttf/xD2/e0YgR/tZVJBhuAwAgbF55RTrwwFj7iCOkxx7zzl5DzhCSAAAIi3XrpL59pa++il378ENp++39q6mIMdwGAEDQOSedfLK07baxgDRrlnedgJQ3hCQAAILsrru8o0SmTPHal17qhaNRo/ytqwNguA0AgCBaskTaa69Ye/hwae5cqXNn/2rqYAhJAAAEyZdfSnvsIa1cGbu2fLk0aJB/NXVQDLcBABAU550nbbVVLCBNm+YNrRGQfEFPEgAAfnvsMenYY2PtX/7S2/MIviIkAQDgl/fekwYOjLUrK6Vly6Tu3X0rCTEMtwEAUGibNklVVfEBaeFCadUqAlKAZBSSzKzCzB42s6Vm9qaZfT3fhQEAUJSuuELq0kWaN89r33abN+9o7739rQtbyHS47e+SnnTOnWhmnSV1y2NNAAAUnxdekL71rVj7hBOkhx6SzPyrCSmlDUlm1kPSwZJOlyTn3CZJm/JbFgAARWLtWqlPn1i7UyfvKJHttvOvJmQkk+G2nSWtlXSHmdWY2a1mtsWAqZmNM7NqM6teu3ZtzgsFACBUmpqko4+OD0gvvSQ1NBCQQiKTkNRJ0r6SbnLODZf0paQJrR/knJvsnKtyzlX17t07x2UCABAiN98slZZKTzzhta++2pt39HWm9IZJJnOSVkla5Zx7pbn9sBKEJAAAOrz5873jQyK++U3vINpO7LgTRmn/1pxzH5rZSjMb7JxbJulQSUvyXxoAACHx2WfSzjtLn3wSu7ZqlbfvEUIr032SzpV0r5m9IWmYpD/nrSIAAMLCOeknP5G22SYWkJ580rtOQAq9jPr/nHPzJVXltxQAAEJkyhTp5JNj7fHjvblHKBoMkgIAkI133pF23TXWHjzYm4vUtatvJSE/OJYEAIBMbNwo7blnfEBatkxaupSAVKQISQAApDNhglReLr35pte+7z5v3tFuu/lbF/KK4TYAAJJ56ilpzJhY+8c/lu64g6NEOghCEgAAra1eHb86raJCWrHCW8WGDoPhNgAAIjZvlg45JD4gzZsnrVtHQOqACEkAAEjSNddIZWXS88977Rtu8OYd7buvv3XBNwy3AQA6tldekQ48MNY+4gjp8celEvoROjpCEgCgY/r0U2mHHaSGhti1Dz+Utt/ev5oQKMRkAEDH4pz0/e9L220XC0izZ3vXCUhogZAEAOg47rzTG0Z76CGvffnlXjg65BA/q0JAMdwGACh+S5ZIe+0Va48YIb30ktS5s381IfAISQCA4vXll9Iee0grV8auvfuuNHCgbyUhPBhuAwAUp/POk7baKhaQpk3zhtYISMgQPUkAgOIyY4Z03HGx9jnnSNdf7189CC1CEgCgOLz3Xnwv0Y47egfSdu/uW0kIN4bbAADhtmmTVFUVH5AWLZLef5+AhHYhJAEAwuuKK6QuXbzz1STp9tu9eUctV7IBbcRwGwAgfJ5/Pn5vo+99T5oyRTLzrSQUH0ISACA81qyJ3xW7rMw7SmTbbf2rCUWL4TYAQPA1NUlHHhkfkF56yZuPREBCnhCSAADBdtNNUmmp9J//eO1Jk7x5R1//ur91oegx3AYACKaaGmnffWPtgw+Wnn1W6sStC4XBvzQAQLB89pm3nH/duti1VaukykrfSkLHxHAbACAYnJPOOEPaZptYQHrySe86AQk+ICQBAPz3wANSSYl0551e+6KLvHA0ZoyvZaFjY7gNAOCft9+Wdtst1h48WJo/X+ra1beSgAhCEgCg8DZulIYNk5Yti1176y1p1119KwlojeE2AEBhTZgglZfHAtIDD3hDawQkBAw9SQCAwpg5Uzr88Fj7jDOk227jKBEEFiEJAJBfq1fHr07r2VNasULq0cO3koBMMNwGAMiPzZu9Q2hbBqTXX5c+/ZSAhFAgJAEAcu+vf/UOn33+ea99443evKPhw/2tC8hCRsNtZrZC0ueSGiVtds5V5bMoAEBIzZ0bf6baUUdJM2Z4eyABIZPNnKRRzrmP81YJACC8Pv1U2mEHqaEhdu2jj6Q+ffyrCWgnoj0AoO2ck77/fWm77WIB6bnnvOsEJIRcpiHJSXrKzOaZ2bhEDzCzcWZWbWbVa9euzV2FAIBguuMObxjtoYe89uWXe+HoW9/yty4gRzIdbhvpnFttZn0kPW1mS51zL7R8gHNusqTJklRVVeVyXCcAICgWL5b23jvWHjFCeuklqXNn/2oC8iCjniTn3OrmX9dImiZp/3wWBQAIoC+/lPr3jw9I774rVVcTkFCU0oYkM+tuZltHfi/pMEmL8l0YACBAzjlH2morqbbWaz/6qDe0NnCgr2UB+ZTJcNv2kqaZt218J0n3OeeezGtVAIBgePRRaezYWPucc6Trr/etHKCQ0oYk59xySUMLUAsAIChWrJAGDYq1d9xRevNNqXt330oCCo0tAAAAMZs2SfvuGx+QFi2S3n+fgIQOh5AEAPBcfrnUpYtUU+O177jDm3e0117+1gX4JJsdtwEAxei556RRo2Ltk06S7r9f8uaiAh0WIQkAOqo1a6Ttt4+1u3SRVq+Wtt3Wv5qAAGG4DQA6mqYm6cgj4wPSyy9LGzcSkIAWCEkA0JHceKNUWir95z9e+69/9eYdHXigv3UBAcRwGwB0BDU13qq1iEMOkZ5+WurEbQBIhv87AKCYrV8v7bST92tEba3Ur59/NQEhwXAbABQj56TTT5cqKmIBaeZM7zoBCcgIIQkAis0DD0glJdJdd3ntCRO8cHTYYf7WBYQMw20AUCzeflvabbdYe489pNdfl7p29a8mIMQISQAQdvX10tChXkiKeOstaddd/asJKAIMtwFAmF10kdStWywgPfCAN7RGQALajZ4kAAijJ5+Ujjgi1j7jDOm22zhKBMghQhIAhEltrdS/f6y97bbSu+9KPXr4VxNQpBhuA4Aw2LxZOvjg+ID0+uvSJ58QkIA8ISQBQND99a9SWZk0Z47XvvFGb97R8OH+1gUUOYbbACCoXn5ZOuigWPuoo6QZM7w9kADkHSEJAILmk0+k7beXGhtj1z76SOrTx7+agA6IH0cAICick048UerVKxaQnn/eu05AAgqOkAQAQXD77d4w2iOPeO0rrvDC0cEH+1sX0IEx3AYAflq0SBoyJNbebz/pv/+VOnf2ryYAkghJAOCPL7+UBg/29j2KWLFC2mkn30oCEI/hNgAotHPOkbbaKhaQHn3UG1ojIAGBQkgCgEKZPt07NuSGG7z2ued64ejYY30tC0BiDLcBQL6tWCENGhRr77STtGSJdzAtgMCiJwkA8mXTJmnffeMD0uLFXmgiIAGBR0gCgHy4/HKpSxeppsZr33mnN7S2556+lgUgcwy3AUAuzZ4tjR4da590knT//d5cJAChQkgCgFz46CNphx1i7S5dpA8+kHr29K8mAO3CcBsAtEdjo3T44fEBae5caeNGAhIQcoQkAGirG26QOnWSZs702n/7mzfv6IAD/K0LQE4w3AYA2Xr9dWnEiFh71Cjpqae8wASgaGT8f7SZlUqqllTrnDs6fyUBQECtX+/tcbR+fexaba3Ur59/NQHIm2yG234l6c18FQIAgeWc9OMfSxUVsYA0c6Z3nYAEFK2MQpKZ9Zd0lKRb81sOAATM/fdLJSXS3Xd77QkTvHB02GH+1gUg7zIdbrtO0kWStk72ADMbJ2mcJA0YMKDdhQGAr956Sxo8ONbeay+pulrq2tW/mgAUVNqeJDM7WtIa59y8VI9zzk12zlU556p69+6dswIBoKDq66XddosPSG+/LS1aREACOphMhttGSjrWzFZIekDSaDP7V16rAgA/XHSRd6ba22977SlTvKG1r33N37oA+CJtSHLOXeyc6++cGyjpZEmznHOn5b0yACiUJ5/0jg2ZNMlrn3mm1NQkff/7/tYFwFds6gGg46qtlfr3j7W3205avlzq0cO/mgAERlY7bjvnnmOPJACht3mz9I1vxAekmhrp448JSACiOJYEQMdy9dVSWZn04ote++abvXlHw4b5WhaA4GG4DUDH8PLL0kEHxdrHHCNNn+7tgQQACRCSABS3Tz6R+vTxJmJHrFkjsVUJgDT4EQpAcWpqko4/XurVKxaQnn/eG1ojIAHIACEJQPG57TaptFSaNs1rX3GFF44OPtjfugCECsNtAIrHokXSkCGx9n77eRO0y8r8qwlAaBGSAITfF194R4l88EHs2ooV0k47+VYSgPBjuA1AeDkn/eIX0tZbxwLSjBnedQISgHYiJAEIp2nTvOX7N93ktc87zwtHxxzjb10AigbDbQDC5d13pZ13jrV32klassQ7mBYAcoieJADhsGmTNHx4fEBavNibe0RAApAHhCQAwXfppVKXLtL8+V77rru8obU99/S1LADFjeE2AME1e7Y0enSsfcop0r33Smb+1QSgwyAkAQiejz6Sdtgh1i4vl2prpZ49/asJQIfDcBuA4GhslA4/PD4gvfKKtGEDAQlAwRGSAATDP/4hdeokzZzpta+5xpt3tP/+/tYFoMNiuA2Av+bNk6qqYu1Ro6SnnvICEwD4iO9CAPyxfr20447S55/Hrq1eLfXt619NANACw20ACss56Uc/kioqYgHp6ae96wQkAAFCSAJQOPfd5x0lcs89Xvt3v/PC0be/7W9dAJAAw20A8m/ZMmn33WPtvfby5iJ16eJfTQCQBiEJQP7U10tDhkj/+1/s2ttvS1/7mn81AUCGGG4DkB+/+Y13plokID34oDe0RkACEBL0JAHIrf/8RzryyFj7pz+VJk/mKBEAoUNIApAbq1Z5S/ojevf2epG23tq/mgCgHRhuA9A+mzdL3/hGfECaP19as4aABCDUCEkA2u7qq6WyMunFF732zTd7846GDvW3LgDIAYbbAGTvpZekkSNj7WOPlaZN8/ZAAoAiQUgCkLlPPvHmGjkXu7ZmjXcNAIoMP/YBSK+pSTr+eKlXr1hAeuEF7/cEJABFipAEILXbbpNKS73hNEm68kovHH3zm/7WBQB5xnAbgMQWLpT22SfWPuAAac4cb6I2AHQAhCQA8b74Qtp1V+nDD2PX3ntPGjDAv5oAwAdph9vMrKuZvWpmC8xssZldXojCABSYc9LPf+7tbRQJSDNmeNcJSAA6oEzmJH0labRzbqikYZION7MD81oVgMKaOtVbvv/Pf3rtX/3KC0fHHONvXQDgo7TDbc45J+mL5mZZ838u+TMAhMa770o77xxrDxokLVrkHUwLAB1cRqvbzKzUzOZLWiPpaefcKwkeM87Mqs2seu3atTkuE0BOffWVNGxYfEBaskRavpyABADNMgpJzrlG59wwSf0l7W9meyd4zGTnXJVzrqo3+6YAwXXJJVLXrtKCBV777ru9obU99vC3LgAImKxWtznn6szsOUmHS1qUl4oA5MesWdKhh8bap5wi3XuvZOZfTQAQYGlDkpn1ltTQHJDKJX1b0l/yXhmA3PjwQ6lv31i7vFyqrZV69vSvJgAIgUyG2/pKmm1mb0h6Td6cpMfzWxaAdmtslA47LD4gvfqqtGEDAQkAMpDJ6rY3JA0vQC0AcuX666Xzzos2/2/0WZr5nZM1vlM/jfWvKgAd1PSaWk2auUyr6+rVr6Jc48cM1tjhlX6XlRY7bgPFZN48qaoq2nx54DCd+r3L1VRSKtXV6+KpCyUpFN+cABSH6TW1unjqQtU3NEqSakP0vYgDboFisH691KNHXEA69uIHdcpJf/ICUrP6hkZNmrnMjwoBdFCTZi6LBqSIsHwvIiQBYeac9KMfSRUV0uefe9eeeUZyTgubEu93tLquvnD1Aejwkn3PCcP3IkISEFb33usdJXLPPV7797/3QlPzMv9+FeUJn5bsOgDkQ1u+F02vqdXIibM0aMITGjlxlqbX1OarvJQISUDYLFvm7W102mlee8gQaeNG6U9/invY+DGDVV5WGnetvKxU48cMLlSlAJD196LIHKbauno5xeYw+RGUCElAWNTXS1/7mrT77rFr77wjvfGG1KXLFg8fO7xSVx0/RJUV5TJJlRXluur4IYGfKAmguGT7vShIc5hY3QaEwYUXStdcE2s/9JB04olpnzZ2eCWhCIDvsvleFKQ5TPQkAUH27397Q2uRgHTWWVJTU0YBCQDCKEjzKQlJQBCtXOmFo6OO8tq9e0uffSZNnsxZawCKWpDmUxKSgCBpaJAOOkgaMCB2bf58ac0aaeutfSsLAAolSPMpmZMEBMVf/iJNmBBr//Of0rhx/tUDAD4JynxKQhLgtxdflL7xjVj7uOOkqVO9PZAAAL4hJAF++fhjb65RS2vXSr16+VMPACAOP6oChdbUJI0dGx+Q5szxdssmIAFAYBCSgEK65RaptFR69FGvfeWVXjhqOdwGAAgEhtuAQnjjDWno0Fj7wAOlF16Qysr8qwkAkBIhCcinL77wjhL56KPYtfffl3bc0b+aAAAZYbgNyAfnpJ//3NvbKBKQHnvMu14kASkop3QDQL7QkwTk2tSp0gknxNrnny9de61v5eRD5JTuyCGUkVO6JQVibxMAyAVCEpAry5dLu+wSa++8s7RwodStm3815UmqU7oJSQCKBcNtQHt99ZW0zz7xAenNN6X//a8oA5IUrFO6ASBfCElAe/zxj1LXrl6PkSTdc48372j33f2tK8+CdEo3AOQLIQloi2eflcykP/3Ja596qrdJ5Gmn+VtXgQTplG4AyBfmJAHZ+PBDqW/fWLt7d2nVKqmiwreS/BCZdzRp5jKtrqtXv4pyjR8zmPlIAIoKIQnIRGOjNGaM14MU8eqr0n77+VeTz4JySjcA5AvDbUA6/+//SZ06xQLSddd58446cEACMsV+WggzepKAZKqr44PQoYdKM2d6Z6+lMb2mNm4oatTuvTV76VqGptChsJ8Wwo6QBLRWVyf17y99+WXs2urV8XORUkh0Y/jX3PejX+dGgY6C/bQQdgy3ARHOeavTevaMBaRnnvGuZxiQpMQ3htYiN4pixRALJPbTQvgRkgBJuvdeqaTE+1WS/vAHLxwdemjWL5XpDaBYbxSRnrTauno5xXrOCEodD/tpIewISejYli719juK7G80ZIi0caN0xRVtfslMbwDFeqNINcSCjoX9tBB2hCSEWpuHdTZs8M5W22OP2LV33pHeeEPq0qVdNSW6MbRWzDcKhlgQMXZ4pa46fogqK8plkiorynXV8UOYj4TQYOI2cqL1aq5CrN5q88qZX/9auvbaWPvhh6UTTshZXYk2WuxIq9v6VZSrNkEgKtaeM6TGfloIs7Qhycx2lHS3pB0kNUma7Jz7e74Lgz/Boy38Wuab9cqZJ56Qjj461v7Zz6SbbvKG23KsI98Yxo8ZHPfvQSrunjMAxSuTnqTNki50zr1uZltLmmdmTzvnluS5tg4tTPuL+LXMN9nwTW1dvabX1Mbee+VKacCA2AO23156+21p663zVlsyYQm+7cGRJQCKRdqQ5Jz7QNIHzb//3MzelFQpiZCUR2HaXyQfc1AyCRPJhnUk6eKpC2UNDTru/B9IL78c+8KCBdI++7S5rvYIU/Btr47ckwageGQ1cdvMBkoaLumVBF8bZ2bVZla9du3aHJXXcYVp8muul/lmuoQ81QTp0+c8oOMOGBQLSJMne0v6fQpIEqu+ACBsMg5JZraVpEckne+c+6z1151zk51zVc65qt69e+eyxg4pTPuL5HqZb6ZhIrJypqWqVYu14i9H67fP3+Vd+O53vcNpzzqrTbXkUpiCL4KLjTqBwskoJJlZmbyAdK9zbmp+S4IUrv1Fcr3MN5swMXZ4pSorytVzw3qt+MvRevje30qSmmQ68g9TpalTvU0ifTa9plYlSSaIBzH4IpjYqBMorExWt5mk2yS96Zy7Jv8lQQrf5NdczkHJagl5U5Mennm1+j43M3rphFOv1pJBQ7boZfJL5MbW6NwWXwtq8EUwhWmuIlAMMlndNlLSDyUtNLP5zdd+55z7d96qgqSOO/k14yXkt9wijRunyKlqN485U38Z9l31qyjXVQEKlMnOcis1Y2M9ZIUhW6CwMlnd9l9Jud9IBoETlOXpaXvRFiyQhg2LPeHrX5eef14/LyvTzwtebXrJbmBNzhXs8w3K3y3ah406gcJix21I8n95eqKb+IsTRsc/6PPPpV12kVqunnz/fWnHHfNeX3vk48aWTejx++8WucNGnUBh+T+jFYHg5/L0tJNRnZPGjZN69IgFpMcf964HPCBJuZ+En+3kXbYeKB6chQYUFj1JkNT+uQ5tHc6ZXlOrCx9csMWk5uhk1OVzpRNPjH3hggukawq7fiDbP1uix191/JCcDXdlOnk3UkeyDTeZxxJOHXWuIuAHQhIktW9IKN1wTrKQkWrV1451H2rOX34au7DLLtLChVJ5YedeZDtUlezxVx0/ZMvhwzbKJNC2riMR5rGED3PLgMIiJBWJ9n7zzHSuQ6L3STeckyxkJHpe580NmnHX+dr94/ei1w796U3auMtuGr/004LfELJdcp3u8bm4yWUSaJOtqItgHkv4MLcMKDxCUhHIxTfPTPZlSvY+yW7Gq+vqU4aG1j0iF75wj859eUqsfcyFemTPUV7DpxtCtsOQqYa2cnWTyyTQphpKq2zVm0fPRDiwRxJQeISkIpCrb57p5joke59Ss4RDZiVmKUPDNuVlqqtv0MgV83XvlD9EvzZ9z0N0wdEXyrXaobq+oVEXT32joDf1bIYhp9fUyiRt+Ul4j8/l35OUOtAmq7uyojw67JePnol8h66OHOrYIwkoPEJSiCS7QWQ6R6W9N5dk79PoXMJwkCg4RfSrKFe3Tz7S/L/+IHrt887lGnn2Hfqs61ZJn1ff0BS9+RdiuCGbJdeTZi5LGJCs+XUumDI/4Xu05SaXLtBmUneueybyPRzU0Yeb2CMJKDy2APBRNgdVplr2ne4w3Fyd95Tqm3HyOLSlLtakadMu1dMtAtIxP7pWQy54KGVASiTfS9mzWXKdLOy45tcp5KHFmdSd656JfG810NG3MgjTeY5AsaAnySfZ/lSc6gaRrtcgVz0Gid4nW2dUP6pLn70l2r7s0HG6s+rYNr+elPymnquhmUyXXKca4pIKvxFgurpz3TOR7+Ggjj7cFLbzHIFiQEjySbbBJdUNIt03z1zdXBK9T7I5R63t88FbmnH3r2MXvvMdTf/zrZry6BKpHaFLSj4/qNBDM+lCUNBucrkObZmGrraGV4ab2CMJKDRCkk+yDS7pbhCpvnnm8ubS+n0GTngi5eN7bPxCL994uro3bIxe2++ce9TQq4/WP7xQXcvaN+Kban5QrufbpLuxZxKCIp9f5PUumDI/2htY6JtfrkNbJqGrPeGVIzkAFBohySfZBpf23CDGjxms8Q8tUENT/Myh2rp6jZw4K+25X6luoj27lWndhoYtn+ic/v7YX3Xcm89HL51y8pV6eaehXqO+ofmXprT1d+9cqg2bGtWvolyjdu+t2UvXpr2p53JoJpsbeyY/6Sd6vQumzFf1e5/qT2OHZF1fe+SyZyKT0NWe8Bq0njgAxY+Q5JNsQ0+6G0Tang5L9KreDXr8wwui7ZavMWr33npkXm3czXz8Qwt0+WOLVbehQf0qynXUPn11/6sr1dgigH130Sxd+0Ts6JC/H3Syrv3madl9QIrfzyeRlr0xrf/M2YbQVJ9frjeITPR6TtK9c99X1U7bhvqmny50tTe8MtwEoJAIST5pHXoqupXJOSUcfml9E772pGEZbfIYeZ9JM5epoTH5+rOGRqffT1uoJqe41/jX3Pe3fGyTi/Yc1dbV696578tJKjFp0Mcr9eytZ0cfu6TPII394TXa1Kks68+n5X4+ifxh+sLoe0dqaflnziaEpvv8Ut3Y23JsSbJ5XE4K1caAbZlbxLwiAGFiLsVeNm1VVVXlqqurc/66xWh6Ta0uf2zxFkNW5WWluup4b+il9c0+sidRpKcl2SGmFeVl6t6lU8aTq9uqa8NGPXXbLzVg/UfRa9/82a1aWbFDm14v8mdP1YN0wZT5CbcdaL1ZYiY38ZETZ6XceDHV16XEu2wnCnmZnKdmkt6deFTSrwdFoj9Lur+39jwPAPLJzOY556paX6cnKUfa8lN1qptmy/1fEg3NSOmPBamrb1BdfYL5Qjl0yTOT9ZN5M6Ltn4+9WE8OHtmu10w3mTvZpo1S/LBNpkMz6YaAEvVKmZIfQaIkX0t3npoUnh6Vts4tYl4RgDAhJOVAW1fspLtpZtID1J49i9pj9Duv6vZH/i/avnfY4fr9Yb+ULMnkpxZ6ditT3YaGpEFn3YaGlJ9fqvkr25SXaeTEWTkdAmp5Y6+tq0969EhLpQk+h3TzbsK0Uqs9c4uYVwQgLAhJOdDWn6rT3VAyuRkXWr/P1uilm34Sba/tXqFvjbtFGzpn1gNikmouOUyD0mwdUN/QqAsf9CaUt/4MU+3P9OWmzdHes2RhtXWvX+sJ6tKWgSVyY0829NZaoiNZUtWdbpK6nxL1kjK3CEBHwLEkOZDup+pkx4+kuqEELSB1atysaXdfGBeQDj/jeu13zr8yDkiSd+htqqNUWmp0LuHxKYmOZzBJ3cpKtpig3vrYikRHtDwyr1YnjKhs19EjrVUm+PON2r13wseeduAAvThhtC8BKd3ROMmOtBm1e2+OyABQ9AhJOZDqTK5EN5kLpszXwAlPaMOmzSor2XJYpqK8LFAB6RcvP6h3/jpWwz/wwsZvDz9XA3/7uJb2GZT1a0WCT7LA0Fqis7lanksW4SRtSLLnUstgk6zXb/bStXpxwmi9O/Go6ITrbINtRLKwMHvp2oSPT3Y93zI50y/V55XpmXYAEFYMt7XB9JpaXTZjcXRYp1tZicpKLa4XI3KjTLYnjuTNvUmQkSSl2KSxgKpWLdbD9/422n5yt6/r7LEXy1n7snXkJpvpnzGy6WXreUbV732acJuC1loGm0zm0iSaYxbZH2rdhoa0vXzZ9kK17HEs5ITmTIaJ0x2HQygCUMwISVmaXlO7xe7VGxqaVGKxCcktb3AXTJmf8vWaEtxt870iLZ2eG9ar5vpTo+0mmUac+y+t67ZNzt5jdV29rj1pWMYH5kbmv7ScZ3T/KyvTPq91r04mc2kShYeW+0OlCkiVFeVJ90cqMUs6V8mPs+YyCYzMPQLQkTHclqVJM5dtcbyH5IWdbp07RYdrWu78HBbmmnTLI1fEBaQTTr1aO//2sZwGJEmq6FaW0ZL4RCK9HYkCR2ute3USzWdqHaQynXfUuhMw3WaViepN1eOYaKgxl1INE0dk8nkBQLGiJymN1kMgqVY2JRo2qehWprISSxisguSU+U/qqpn/iLYnfut03XzgiXl5r7JS0xcbN7drOHF1Xb1Kk/TMRFSUl7XpENp0f88RkQ090w2PpQqDJ4yoTNnj2Jaz5jKVya7k7GsEoCMjJKWQaAgk1XyUEjMNnPBE3GPWbWhQWWn6vYP8ssea5frPHedF269V7qlTTvmzNpfm559GqZm6d+7U7iHFim5lOmqfvinnJCXbsindXJpRu/fOaK5TuqNTIlIFnUfm1apqp219GdbK9jzA1sfhAECxIySlcPlji5NOuk4k0qvR+jGpzk3zS/evNuj5yWep14b10WsHnn2nPuzRK2/vWVZqmnTiUJ2fZp5WJjY2NOqJNz5I+Zi6NvZUZbLaLJshp1Q9U5EhtWwPPM6VZIHRjzlSABA0hKQkptfUphwOKi8rUX2SJeeB5pz+PPMf+sGCmdFLp594qZ7bZb+8v3VDo8tJQJKk+oamtJ9/Nr0wLXtN0kXabDd+TBSAWoqsFJOCM6zV1g1SAaCYEJKSSDVhNtXBpkF2xNL/6qZHJ0bbt+w3VleO/qmPFeVPNr0wmRw82/p1swkKkcde+OCCpKvbIo8LSgBpz7EjAFAsCElJpLoZjB8zOGc9IoUwYN0HemHyWdH2uz376vAz/qGvyrr4WFV+demU+cLNbFbZtbU3JfJ4P4bU2oKl/wBASEoq2U0ismIqWa9AkHTe3KDH7vqVBn8cm4Q8+qc3a/l2/X2sqm3MJOe8XrwNm9KvjKurb9D4hxfoshmLtb6+IeXwVba9I23tTQnakFoqfs2RAoAgISQlML2mVhs2bd7ienlZqS47di9JiQ8wDZLfvHC3znn5wWj7vGN+oxl7HuJfQe3knFRWYtGbdCY9eQ2NLu1ht1LmS/5bPr6tgjSklkqYAh0A5Iu5PNzsq6qqXHV1dc5ftxAymZ8ShCNDkhm5Yr7unfKHaPuRvUbpwqN+nXw9fMiYpGtPGhZ3LEw2Ei3bz3ZO0gkjKjV76VrCAwAUCTOb55yran09bU+Smd0u6WhJa5xze+ejuCDJZH5KEANS7y8+1Ws3/Cja/rxzuUaefYc+67qVj1XlnpM3r+eEEZUZ7WXUWusz2lpu+tmlU4nW1zeooluZvti4eYsNQHs27830yLxalsYDQAeQyezWOyUdnuc6AiNsK9ZKmhp13/2/iwtIx/zoWg254KGiC0gRkQNyK8rLsn5uZKgs0ntU27zkf92GBn21uUnXnjRMNZccpknfGxp3wv11zddnL11b8ONDAAD+SNuT5Jx7wcwGFqCWQEh31EWQ/OS1R3XJrFui7csOHac7q471saLCqa2rV0V5mcpKLePNOltOPE63D1DruUPTa2o1cuKspCGapfEAUHxyNnHbzMZJGidJAwYMyNXL5kzrIxaSzSMJQ0AaunqZHr3nwmj7hYHDdfr3LlNTSWmKZxVORXmZvtrc1KbDa7ORbk5SWal3BEqi1W3Z7AOUyZwllsYDQPHJWUhyzk2WNFnyJm7n6nVzIdMjFqbX1Aa6J6nHxi/0yg0/Vvnmr6LXqs65Rx9375m394ycQ5fNZPX19Q269qRhmjRzWUGHL0sklXcu1ZebvL/n7p076bJj90oYhrPZByjdPDWWxgNAccp8x70QSzW0EhEJUoEMSM7p7zMm6Y2/nxwNSKecfKUG/vbxvAYkSTr1wAGqrCjP6hy0fhXlGju8UuPHDFa3stz8EyvNYHVekxQNSJLX03Tx1IWaXlO7xWPHjxms8rL4nrdkYSfVUFplRbmuOn4Ik7YBoAh1iH2SMhlaSXSYbRB8d9EsXfvENdH23w86Rdd+89SCvX+2K8hMXgCZXlOr8Q8vyMnhvmUlpknfa9vBuMl2yM5mH6BkvU6JthMAABSPTLYAuF/SIZJ6mdkqSZc6527Ld2G5lG5oJd1htn7Y5eOVeva2s6PtxX121nd/+Ddt6pT9iq5COvXAARo7vFIjJ87KSUCS5CUvtX1/qmQhOdONHdl9GgA6pkxWt51SiELyKdVNbnpNrS58cIGP1cXr2rBRz9z6C/X/bE302jd+dqtWVezgY1Xp9exWpkuP2SvtxOi2aGh0uvDBBTrlgB015bWVWYev9k6qZvdpAOiYOsRwW+Rm1nKX5vqGxsAdUnvJM5P1k3kzou2fffd3mrnbQT5WlBmTVHPJYXHX0h31UWLSNuVlqtvQoEwiT6NzemRerU7ab0fNXro24wnhuerxCctxIgCA3OkQE7cjvvxqy/PYgmD0O69qxV+Ojgake4YfqYEXPRaKgCRJFd22HAIcP2awykqTT7YuNdOlx+yldycelfH7RDaRfHHCaK2YeFTSzSRLzaKbQDKpGgDQVh2iJ0nyhkpaHzPht36frdFLN/0k2v5oq2016qx/akPncO25k2hBYCSYXP7Y4oTziBqaXHRCdTZzjVoO41127F4Jh1EJRgCAXCj6nqR0OyX7oVPjZk2/+9dxAWnMT/6hA355d+gCkuQttR85cdYWS+3HDq9UzSWHKVl/UiTwHLVP34zfq+X8orHDK3XV8UPijg8hIAEAciXUPUnpdtHO5nT3QvnlS1M0fs490fZFh5+nB4celuIZ4VBbV6/xD3sT4FuHlGTzk0rMNGjCEypJsgdSZCPLiETzi5grBADIF3N52DyxqqrKVVdX5/x1W0oUgFoPtQSpB2m/lYv00H0Tou3/7HaQfjF2gpwVV2de986lqujWOS64SmpzWK2sKGdFGQAgr8xsnnOuaovrYQ1JyQJQyw3+Bk14IqOVU/m07Yb1ev362OaPm61EVef+S3XlPXysqnAiwVWKLaEvyfDoFzZrBAAUQrKQFNrhtkx20U63DD2fzDXplkeu0Lf/91r02vGnTtLr/ffwpZ72qigvS3ugbCKRHa9fnDA62gs0aMITaZ/HZo0AAL+Fdqwn2QaBLa+P2r13ocqJ84P5/9G7Vx8bDUgTv3W6Bv728dAGJEky844HaYvWgTbZ3x1L9wEAQRLanqR0R0VMr6nVI/O2PNg0n/b8aLn+fed50fZrlXvq5B9cpcaS0hTPCoe6DQ269qRhcRtyZqp1KEr2d0cwAgAESWhDUrqjIgp5YG33rzZozj9/qm3rP4teO/DsO/Vhj14Fef9c6dm8KWSiPYv6VZRHV5INzGC4rKVEK9IkjvkAAARbaEOStOXy74LvieScJj55vU5+46nopdNPvFTP7bJfYd4/xyK9RekOcy3NcOK15M1lShR+WLoPAAi6UIeklgq9J9KRS/+rGx+dGG1P3u+7+vPoMwvy3vkS6S2SUvfyZBqQystKddmxe+WlVgAA8q1oQtKkmcsKEpAGrPtAL0w+K9pe3rOfjjjjen1V1iXv752pyuZgk+oA37JSU0NjLOy07C1K18tTmWTVYEV5mbp36cQQGgCgKBRNSMr3EFvnzQ167K5fafDH70evjf7pzVq+Xf+8vm9bRPYWmjRzWdK9pMaPGdzmOUHJJl5fduxehCIAQNEoipA0vaZ2iyMscmn883fpl3MfirbPO2a8Zuz5rTy9W/uNnDhL48cMTrkCsD1zgph4DQDoCEK743ZL+Zqs/Y13a/SvB/8YbT+896H6zZHne5sGBVxZiWnS94ZKIswAAJBK0e24LcUOuM11QOrz+Sd69cYfR9ufdemukWffrs+7dM/p++RTQ5PTZTMWa/6lhxGKAABog9CGpHysZitpatS/pvxRB73/RvTa0T++Tot2+FrO3qOQ2nKMCAAA8IQ2JOV6NduZr03XH2fdGm1f8u2f6e4Rx+Ts9fMl2UozAADQPqENSckOuM3WmLde0j+n/Tnafn7QvjrjxEvVFIKjRCoryvXihNEa/n9PJdwlO7KDNgAAyF5oQ1K/dvag9P7iU712w4/irlWdc48+7t6zvaUVRMt9jS49Zi+Nf3hB3L5HZaWmS49hI0cAANoqdCGp3ZO1ndM7k45TJ9cUvTT+iPP00D6H5ajC/KsoL4vbk4gl+QAA5F6oQlJ7J2v/ftatOuu16dH2KzvurZN+MDH5E3xSVmqS81aotdSzW5kuPSbxho2chQYAQG6FKiS1dbL2/isX6cH7JsRdG/zrRwJ1lEhkM8zIbtgSPUMAAPgpVCEp28naW3/1pRZed1LctaNO/7sWb79LLsvKSuR8s9q6epWaqdG5aDBqHYIIRQAA+CdUISmbydrP3vIz7fJpbbR99cE/0o1f/36+SstIWalxvhkAACFR4ncB2YgMQ6Vy1itTteIvR0cD0qoevTXwosd8D0iSNOnEoQQkAABCIlQ9SansvuZdPXnHuXHXhp53v9aXb5339245oTrZOXKVFeUEJAAAQiRUIWnSzGVbXOuyeZOW/e34uGunnHylXt5paN7rMUmnHjhAfxo7JHpt/JjBW6zAa7mnEQAACIdQhaTWPTS/fGmKxs+5J9q+c9+jddl3fp7XGiorylOuOGPPIgAAikOoQlJkNdiw1cs0/Z4Lo9dXb91LI8++Xc7yO8UqcgxIOuxZBABA+IUqJDU6b3PFy565WZLUUFKq/c65R3XlPfL+3gyZAQDQsWQUkszscEl/l1Qq6VbnnC/bVEdOvP/pCZeoy+YG1W7TJy/vc9qBA1S107YJh8wix6IwlAYAQHEz51zqB5iVSnpL0nckrZL0mqRTnHNLkj2nqqrKVVdX57JOSd6xJBdMma/UFbdfsmG1RMeilJeV6qrjhxCUAAAIKTOb55yran09k0k8+0t6xzm33Dm3SdIDko7LdYGZGDu8Mu8BSUq+s3eiY1HqGxoTrroDAADhlklIqpS0skV7VfO1OGY2zsyqzax67dq1uapvy2IqyvP22hH9krxHsvCU7XEpAAAg+DIJSZbg2hYdOs65yc65KudcVe/evdtfWRLjxwxOWFCupJqgnSw8JbsOAADCK5OQtErSji3a/SWtzk856Y0dXqlTDxzQpueavEnZKyYepetOGhbtlSo1L3ZVVpSnnF80fsxglZeVxl1j1RsAAMUpk4nbneRN3D5UUq28ids/cM4tTvacfE3cbml6Ta1+N/UNbWhoyujxp7XaGbs978vqNgAAikeyidtpQ1Lzk4+UdJ28LQBud85dmerxhQhJAAAAuZAsJGW0T5Jz7t+S/p3zqgAAAAIqv+d4AAAAhBQhCQAAIAFCEgAAQAKEJAAAgAQISQAAAAkQkgAAABIgJAEAACRASAIAAEiAkAQAAJBARseSZP2iZmslvZejl+sl6eMcvVax4jNKjc8nPT6j9PiMUuPzSY/PKD2/PqOdnHO9W1/MS0jKJTOrTnSeCmL4jFLj80mPzyg9PqPU+HzS4zNKL2ifEcNtAAAACRCSAAAAEghDSJrsdwEhwGeUGp9PenxG6fEZpcbnkx6fUXqB+owCPycJAADAD2HoSQIAACi4wIYkMzvczJaZ2TtmNsHveoLIzG43szVmtsjvWoLIzHY0s9lm9qaZLTazX/ldU9CYWVcze9XMFjR/Rpf7XVMQmVmpmdWY2eN+1xJEZrbCzBaa2Xwzq/a7niAyswoze9jMljZ/T/q63zUFhZkNbv63E/nvMzM73++6pIAOt5lZqaS3JH1H0ipJr0k6xTm3xNfCAsbMDpb0haS7nXN7+11P0JhZX0l9nXOvm9nWkuZJGsu/oxgzM0ndnXNfmFmZpP9K+pVzbq7PpQWKmf1aUpWkHs65o/2uJ2jMbIWkKuccewAlYWZ3SZrjnLvVzDpL6uacq/O5rMBpvv/XSjrAOZer/RbbLKg9SftLesc5t9w5t0nSA5KO87mmwHHOvSDpU7/rCCrn3AfOudebf/+5pDclVfpbVbA4zxfNzbLm/4L3k5OPzKy/pKMk3ep3LQgnM+sh6WBJt0mSc24TASmpQyX9LwgBSQpuSKqUtLJFe5W4uaEdzGygpOGSXvG5lMBpHkqaL2mNpKedc3xG8a6TdJGkJp/rCDIn6Skzm2dm4/wuJoB2lrRW0h3Nw7a3mll3v4sKqJMl3e93ERFBDUmW4Bo/3aJNzGwrSY9IOt8595nf9QSNc67ROTdMUn9J+5sZQ7fNzOxoSWucc/P8riXgRjrn9pV0hKRfNk8FQEwnSftKusk5N1zSl5KYa9tK8zDksZIe8ruWiKCGpFWSdmzR7i9ptU+1IMSa59k8Iule59xUv+sJsubu/+ckHe5vJYEyUtKxzXNuHpA02sz+5W9JweOcW9386xpJ0+RNmUDMKkmrWvTSPiwvNCHeEZJed8595HchEUENSa9J2tXMBjUny5MlzfC5JoRM86Tk2yS96Zy7xu96gsjMeptZRfPvyyV9W9JSX4sKEOfcxc65/s65gfK+D81yzp3mc1mBYmbdmxdGqHkI6TBJrLhtwTn3oaSVZja4+dKhklhAsqVTFKChNsnrAgwc59xmMztH0kxJpZJud84t9rmswDGz+yUdIqmXma2SdKlz7jZ/qwqUkZJ+KGlh85wbSfqdc+7f/pUUOH0l3dW8oqRE0oPOOZa5IxvbS5rm/UyiTpLuc8496W9JgXSupHubf/BfLukMn+sJFDPrJm9F+8/8rqWlQG4BAAAA4LegDrcBAAD4ipAEAACQACEJAAAgAUISAABAAoQkAAAQStke9G5m3zezJc0Het+X9vGsbgMAAGGUzUHvZrarpAcljXbOrTOzPs0boCZFTxIAAAilRAe9m9kuZvZk81mCc8xs9+YvnSXpBufcuubnpgxIEiEJAAAUl8mSznXOjZD0G0k3Nl/fTdJuZvaimc01s7RHMAVyx20AAIBsNR9ofpCkh5p3gZekLs2/dpK0q7yTKvpLmmNmezefW5kQIQkAABSLEkl1zrlhCb62StJc51yDpHfNbJm80PRaqhcDAAAIPefcZ/IC0Pck76BzMxva/OXpkkY1X+8lb/htearXIyQBAIBQaj7o/WVJg81slZmdKelUSWea2QJJiyUd1/zwmZI+MbMlkmZLGu+c+yTl67MFAAAAwJboSQIAAEiAkAQAAJAAIQkAACABQhIAAEAChCQAAIAECEkAAAAJEJIAAAASICQBAAAk8P8BUVNTMwIRi5wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot shows that the there are outliers that does not follow the y_test line. Our scatter points are closely aligned with the linear line up to around 2e-6 to 3e-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just for fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is more unit better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I did not understand fully on choosing number of unit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 426317283328.0000 - val_loss: 439965351936.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 426055663616.0000 - val_loss: 439371169792.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 424948924416.0000 - val_loss: 437579284480.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 422383681536.0000 - val_loss: 434027560960.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 417844723712.0000 - val_loss: 428205572096.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 410888601600.0000 - val_loss: 419721609216.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 401218011136.0000 - val_loss: 408355667968.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 388654268416.0000 - val_loss: 393984966656.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 373230993408.0000 - val_loss: 376750145536.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 355105767424.0000 - val_loss: 356924522496.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 334597881856.0000 - val_loss: 334835154944.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 312194695168.0000 - val_loss: 311088971776.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 288482689024.0000 - val_loss: 286343430144.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 264123252736.0000 - val_loss: 261361876992.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 239850127360.0000 - val_loss: 236586844160.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 216410308608.0000 - val_loss: 213137604608.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 194462089216.0000 - val_loss: 191498600448.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 174594375680.0000 - val_loss: 172121948160.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 157307600896.0000 - val_loss: 155596423168.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 142799454208.0000 - val_loss: 141921501184.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 131155124224.0000 - val_loss: 131186843648.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 122262798336.0000 - val_loss: 123103166464.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 115785867264.0000 - val_loss: 117314748416.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 111304130560.0000 - val_loss: 113315315712.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 108353912832.0000 - val_loss: 110730805248.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 106499440640.0000 - val_loss: 109061505024.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 105335922688.0000 - val_loss: 107984486400.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 104600920064.0000 - val_loss: 107267219456.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 104105615360.0000 - val_loss: 106726121472.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 103730282496.0000 - val_loss: 106321207296.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 103414325248.0000 - val_loss: 105954041856.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 103115833344.0000 - val_loss: 105618898944.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102813368320.0000 - val_loss: 105272844288.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 102507184128.0000 - val_loss: 104938897408.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102198222848.0000 - val_loss: 104585461760.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 101874188288.0000 - val_loss: 104231329792.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 101548892160.0000 - val_loss: 103869865984.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 101206556672.0000 - val_loss: 103503175680.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 100855521280.0000 - val_loss: 103120404480.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 100499587072.0000 - val_loss: 102753214464.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 100124278784.0000 - val_loss: 102325108736.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 99743588352.0000 - val_loss: 101906530304.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 99362529280.0000 - val_loss: 101500846080.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98978430976.0000 - val_loss: 101077565440.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 98578251776.0000 - val_loss: 100639064064.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 98168291328.0000 - val_loss: 100201193472.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 97750228992.0000 - val_loss: 99761381376.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 97326342144.0000 - val_loss: 99292856320.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96892461056.0000 - val_loss: 98828001280.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96452280320.0000 - val_loss: 98365341696.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96013377536.0000 - val_loss: 97873420288.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 95550382080.0000 - val_loss: 97371955200.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 95090262016.0000 - val_loss: 96874151936.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 94621270016.0000 - val_loss: 96374497280.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94151450624.0000 - val_loss: 95866249216.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93663543296.0000 - val_loss: 95361441792.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93182066688.0000 - val_loss: 94827888640.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92685991936.0000 - val_loss: 94290067456.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92183019520.0000 - val_loss: 93772398592.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91666022400.0000 - val_loss: 93202849792.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91159519232.0000 - val_loss: 92652806144.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90624974848.0000 - val_loss: 92095062016.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90105094144.0000 - val_loss: 91481669632.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 89565888512.0000 - val_loss: 90927128576.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89012641792.0000 - val_loss: 90347716608.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88458084352.0000 - val_loss: 89757917184.0000\n",
      "Epoch 67/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 87909982208.0000 - val_loss: 89157828608.0000\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 87347576832.0000 - val_loss: 88560975872.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 86789079040.0000 - val_loss: 87946993664.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 86219513856.0000 - val_loss: 87330709504.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 85640986624.0000 - val_loss: 86731751424.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 80408010752.000 - 0s 1ms/step - loss: 85065121792.0000 - val_loss: 86113755136.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 84485488640.0000 - val_loss: 85491122176.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 83895410688.0000 - val_loss: 84845142016.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 83303145472.0000 - val_loss: 84235755520.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 82706063360.0000 - val_loss: 83581337600.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 82111766528.0000 - val_loss: 82941116416.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 81510400000.0000 - val_loss: 82283765760.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 80906338304.0000 - val_loss: 81645895680.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 80304447488.0000 - val_loss: 81022361600.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 79689048064.0000 - val_loss: 80351150080.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 79080218624.0000 - val_loss: 79711772672.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 78450081792.0000 - val_loss: 79007768576.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 77828644864.0000 - val_loss: 78345551872.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 77203136512.0000 - val_loss: 77692813312.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 76584615936.0000 - val_loss: 77035741184.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 75962425344.0000 - val_loss: 76345573376.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 75325956096.0000 - val_loss: 75654635520.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 74684604416.0000 - val_loss: 74965458944.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 74044948480.0000 - val_loss: 74256605184.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 73392504832.0000 - val_loss: 73587884032.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 72753209344.0000 - val_loss: 72895488000.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 72111611904.0000 - val_loss: 72191254528.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 71462838272.0000 - val_loss: 71511318528.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 70818643968.0000 - val_loss: 70818865152.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 70182772736.0000 - val_loss: 70151479296.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 69553340416.0000 - val_loss: 69461385216.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 68911439872.0000 - val_loss: 68783423488.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 68283969536.0000 - val_loss: 68104601600.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 67657093120.0000 - val_loss: 67420180480.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 67036950528.0000 - val_loss: 66760368128.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 66442506240.0000 - val_loss: 66091020288.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 65825513472.0000 - val_loss: 65470439424.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 65232650240.0000 - val_loss: 64824500224.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 64648253440.0000 - val_loss: 64188817408.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 64082333696.0000 - val_loss: 63567261696.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 63511396352.0000 - val_loss: 62974693376.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 62954057728.0000 - val_loss: 62370979840.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 62419185664.0000 - val_loss: 61789814784.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 61903802368.0000 - val_loss: 61211291648.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 61369880576.0000 - val_loss: 60673191936.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 60872470528.0000 - val_loss: 60113653760.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 60382011392.0000 - val_loss: 59589386240.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 59905687552.0000 - val_loss: 59078569984.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 59449094144.0000 - val_loss: 58574872576.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 59006611456.0000 - val_loss: 58110201856.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 58585612288.0000 - val_loss: 57624129536.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 58174623744.0000 - val_loss: 57213906944.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 57779789824.0000 - val_loss: 56753504256.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 57415069696.0000 - val_loss: 56344535040.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 57045655552.0000 - val_loss: 55971053568.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 56703946752.0000 - val_loss: 55587147776.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 56377352192.0000 - val_loss: 55218614272.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 56062398464.0000 - val_loss: 54905995264.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 55767195648.0000 - val_loss: 54537273344.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 55473844224.0000 - val_loss: 54264729600.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 55206178816.0000 - val_loss: 53925474304.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54953213952.0000 - val_loss: 53645201408.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54714851328.0000 - val_loss: 53372444672.0000\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54492012544.0000 - val_loss: 53119070208.0000\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54271602688.0000 - val_loss: 52880666624.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 54066327552.0000 - val_loss: 52666167296.0000\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 53881892864.0000 - val_loss: 52440125440.0000\n",
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53693231104.0000 - val_loss: 52231503872.0000\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53519831040.0000 - val_loss: 52029870080.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53348958208.0000 - val_loss: 51837972480.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53189939200.0000 - val_loss: 51657207808.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 53030031360.0000 - val_loss: 51470336000.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52886876160.0000 - val_loss: 51313917952.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52749066240.0000 - val_loss: 51145183232.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52623880192.0000 - val_loss: 51011776512.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52490502144.0000 - val_loss: 50846072832.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52378501120.0000 - val_loss: 50711535616.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52253110272.0000 - val_loss: 50564988928.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52150566912.0000 - val_loss: 50442653696.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 52024381440.0000 - val_loss: 50316095488.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51917901824.0000 - val_loss: 50181267456.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51830329344.0000 - val_loss: 50064678912.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51720376320.0000 - val_loss: 49949339648.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51630714880.0000 - val_loss: 49842470912.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51535548416.0000 - val_loss: 49749753856.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51454320640.0000 - val_loss: 49630420992.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51354742784.0000 - val_loss: 49524162560.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51272896512.0000 - val_loss: 49441038336.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51186954240.0000 - val_loss: 49327255552.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51104919552.0000 - val_loss: 49230839808.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 51027267584.0000 - val_loss: 49146564608.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50948952064.0000 - val_loss: 49050382336.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50870554624.0000 - val_loss: 48954097664.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50799525888.0000 - val_loss: 48864833536.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50718945280.0000 - val_loss: 48791158784.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50650607616.0000 - val_loss: 48697651200.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50577199104.0000 - val_loss: 48617193472.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50514718720.0000 - val_loss: 48540504064.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50455642112.0000 - val_loss: 48455434240.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50385817600.0000 - val_loss: 48392814592.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50317512704.0000 - val_loss: 48322523136.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50258448384.0000 - val_loss: 48253251584.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50203467776.0000 - val_loss: 48173924352.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50138832896.0000 - val_loss: 48117899264.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50086432768.0000 - val_loss: 48050384896.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50044235776.0000 - val_loss: 47991316480.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49980399616.0000 - val_loss: 47929880576.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49932648448.0000 - val_loss: 47860568064.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49888169984.0000 - val_loss: 47819456512.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49826766848.0000 - val_loss: 47750664192.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49781444608.0000 - val_loss: 47687680000.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49733701632.0000 - val_loss: 47635329024.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49682870272.0000 - val_loss: 47598022656.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49638887424.0000 - val_loss: 47527772160.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49594179584.0000 - val_loss: 47469596672.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49552359424.0000 - val_loss: 47425183744.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49500872704.0000 - val_loss: 47376326656.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49460817920.0000 - val_loss: 47316430848.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 49430355968.0000 - val_loss: 47270715392.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49360601088.0000 - val_loss: 47208837120.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49334063104.0000 - val_loss: 47154556928.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49272700928.0000 - val_loss: 47118909440.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49236119552.0000 - val_loss: 47065255936.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49187758080.0000 - val_loss: 47010480128.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49146089472.0000 - val_loss: 46972395520.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49102602240.0000 - val_loss: 46909878272.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49063473152.0000 - val_loss: 46863007744.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 49011474432.0000 - val_loss: 46814330880.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48967606272.0000 - val_loss: 46765813760.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48927809536.0000 - val_loss: 46719877120.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48881197056.0000 - val_loss: 46669529088.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48834789376.0000 - val_loss: 46621585408.0000\n",
      "Epoch 199/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 48788328448.0000 - val_loss: 46563323904.0000\n",
      "Epoch 200/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48738848768.0000 - val_loss: 46516060160.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48695074816.0000 - val_loss: 46466924544.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48644268032.0000 - val_loss: 46414127104.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48594092032.0000 - val_loss: 46345687040.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 48543870976.0000 - val_loss: 46295212032.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48489852928.0000 - val_loss: 46239395840.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48439889920.0000 - val_loss: 46173360128.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48384536576.0000 - val_loss: 46122635264.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48313073664.0000 - val_loss: 46047338496.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48264404992.0000 - val_loss: 46001922048.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 48179470336.0000 - val_loss: 45900800000.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 48118317056.0000 - val_loss: 45833748480.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 48045289472.0000 - val_loss: 45766176768.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47964749824.0000 - val_loss: 45660364800.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47882657792.0000 - val_loss: 45575852032.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47794716672.0000 - val_loss: 45488123904.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47699906560.0000 - val_loss: 45387468800.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47604273152.0000 - val_loss: 45287981056.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47506567168.0000 - val_loss: 45198745600.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47403229184.0000 - val_loss: 45075742720.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47306522624.0000 - val_loss: 44964192256.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47203078144.0000 - val_loss: 44859551744.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47091933184.0000 - val_loss: 44771909632.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47001481216.0000 - val_loss: 44649435136.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46888816640.0000 - val_loss: 44557123584.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46781497344.0000 - val_loss: 44435218432.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46687469568.0000 - val_loss: 44332158976.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46590951424.0000 - val_loss: 44238503936.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46500360192.0000 - val_loss: 44148588544.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46430220288.0000 - val_loss: 44063903744.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46326853632.0000 - val_loss: 43965689856.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46247563264.0000 - val_loss: 43879653376.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46172667904.0000 - val_loss: 43824943104.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46098444288.0000 - val_loss: 43736469504.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 46037635072.0000 - val_loss: 43654717440.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45962362880.0000 - val_loss: 43584679936.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45910994944.0000 - val_loss: 43513896960.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45835386880.0000 - val_loss: 43448832000.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45778841600.0000 - val_loss: 43384598528.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45728358400.0000 - val_loss: 43318263808.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45673586688.0000 - val_loss: 43262386176.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45609119744.0000 - val_loss: 43197644800.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45552848896.0000 - val_loss: 43136065536.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45497499648.0000 - val_loss: 43064012800.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45448536064.0000 - val_loss: 43010334720.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45390614528.0000 - val_loss: 42956263424.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45339893760.0000 - val_loss: 42884575232.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45282230272.0000 - val_loss: 42837762048.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45229682688.0000 - val_loss: 42770849792.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45173018624.0000 - val_loss: 42708054016.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45119205376.0000 - val_loss: 42651168768.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45071896576.0000 - val_loss: 42581762048.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 45005258752.0000 - val_loss: 42528964608.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44957433856.0000 - val_loss: 42479116288.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 44895776768.0000 - val_loss: 42401693696.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44839460864.0000 - val_loss: 42356596736.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44780191744.0000 - val_loss: 42284957696.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44717256704.0000 - val_loss: 42209361920.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44657364992.0000 - val_loss: 42155008000.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44601880576.0000 - val_loss: 42083368960.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44532645888.0000 - val_loss: 42015944704.0000\n",
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44463448064.0000 - val_loss: 41955414016.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44405882880.0000 - val_loss: 41887166464.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44342009856.0000 - val_loss: 41817882624.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44289859584.0000 - val_loss: 41759256576.0000\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 44212379648.0000 - val_loss: 41682198528.0000\n",
      "Epoch 266/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44160528384.0000 - val_loss: 41627172864.0000\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44084391936.0000 - val_loss: 41557839872.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 44026015744.0000 - val_loss: 41500303360.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43957743616.0000 - val_loss: 41421967360.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43905884160.0000 - val_loss: 41371009024.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43838578688.0000 - val_loss: 41300058112.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43785842688.0000 - val_loss: 41235800064.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43717611520.0000 - val_loss: 41175203840.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43663278080.0000 - val_loss: 41121009664.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43604815872.0000 - val_loss: 41053614080.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43554930688.0000 - val_loss: 40994074624.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43500064768.0000 - val_loss: 40928317440.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43445596160.0000 - val_loss: 40873152512.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43387359232.0000 - val_loss: 40824655872.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43332796416.0000 - val_loss: 40756109312.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43273637888.0000 - val_loss: 40695091200.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43212664832.0000 - val_loss: 40657694720.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43164991488.0000 - val_loss: 40584400896.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 43112296448.0000 - val_loss: 40530481152.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43055288320.0000 - val_loss: 40464859136.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42995920896.0000 - val_loss: 40432611328.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42967269376.0000 - val_loss: 40387923968.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42891390976.0000 - val_loss: 40299950080.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42840436736.0000 - val_loss: 40247697408.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42793132032.0000 - val_loss: 40190296064.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42735353856.0000 - val_loss: 40148238336.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42683760640.0000 - val_loss: 40085610496.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42638995456.0000 - val_loss: 40039743488.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42584154112.0000 - val_loss: 39992561664.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42538008576.0000 - val_loss: 39952379904.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42492313600.0000 - val_loss: 39880220672.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42430169088.0000 - val_loss: 39825924096.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42387820544.0000 - val_loss: 39783567360.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42337771520.0000 - val_loss: 39722967040.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42289012736.0000 - val_loss: 39676563456.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42235785216.0000 - val_loss: 39614382080.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42189053952.0000 - val_loss: 39570018304.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42138394624.0000 - val_loss: 39526682624.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42090405888.0000 - val_loss: 39466885120.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42041765888.0000 - val_loss: 39411310592.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41992396800.0000 - val_loss: 39370625024.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41937608704.0000 - val_loss: 39318994944.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41908047872.0000 - val_loss: 39268708352.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41847783424.0000 - val_loss: 39220277248.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41796448256.0000 - val_loss: 39166795776.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41744920576.0000 - val_loss: 39115382784.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41713577984.0000 - val_loss: 39062806528.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41659023360.0000 - val_loss: 39020769280.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41621831680.0000 - val_loss: 38986158080.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41568546816.0000 - val_loss: 38931329024.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41538260992.0000 - val_loss: 38884732928.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41479933952.0000 - val_loss: 38851887104.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41451343872.0000 - val_loss: 38814449664.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41417957376.0000 - val_loss: 38747332608.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41356808192.0000 - val_loss: 38713647104.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41339490304.0000 - val_loss: 38673960960.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41287086080.0000 - val_loss: 38630440960.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41236811776.0000 - val_loss: 38594228224.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41200242688.0000 - val_loss: 38552559616.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41176444928.0000 - val_loss: 38525145088.0000\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41132978176.0000 - val_loss: 38473490432.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41094348800.0000 - val_loss: 38443552768.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41068445696.0000 - val_loss: 38403571712.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 41021964288.0000 - val_loss: 38371209216.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40996290560.0000 - val_loss: 38343061504.0000\n",
      "Epoch 331/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - ETA: 0s - loss: 42197131264.000 - 0s 2ms/step - loss: 40968691712.0000 - val_loss: 38303092736.0000\n",
      "Epoch 332/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40926601216.0000 - val_loss: 38274244608.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40889876480.0000 - val_loss: 38228652032.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40862375936.0000 - val_loss: 38203572224.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40827084800.0000 - val_loss: 38154371072.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40797794304.0000 - val_loss: 38132629504.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40763113472.0000 - val_loss: 38094094336.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40731373568.0000 - val_loss: 38059974656.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40698490880.0000 - val_loss: 38026178560.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40669704192.0000 - val_loss: 38000222208.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40641720320.0000 - val_loss: 37965819904.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40604831744.0000 - val_loss: 37933015040.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40578347008.0000 - val_loss: 37911318528.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40551202816.0000 - val_loss: 37875417088.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40523431936.0000 - val_loss: 37841698816.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40483721216.0000 - val_loss: 37809016832.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40457678848.0000 - val_loss: 37776883712.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40432558080.0000 - val_loss: 37744631808.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40411684864.0000 - val_loss: 37728178176.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40375566336.0000 - val_loss: 37685374976.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40348127232.0000 - val_loss: 37657739264.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40318849024.0000 - val_loss: 37630586880.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40294719488.0000 - val_loss: 37600403456.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40258183168.0000 - val_loss: 37569314816.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40233476096.0000 - val_loss: 37542064128.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40220090368.0000 - val_loss: 37520539648.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40174821376.0000 - val_loss: 37487226880.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40153669632.0000 - val_loss: 37468475392.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40124805120.0000 - val_loss: 37435322368.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40097755136.0000 - val_loss: 37409984512.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40072040448.0000 - val_loss: 37382201344.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40047480832.0000 - val_loss: 37355569152.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40036245504.0000 - val_loss: 37326143488.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40008548352.0000 - val_loss: 37306515456.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39968468992.0000 - val_loss: 37276741632.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39944429568.0000 - val_loss: 37249036288.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39927267328.0000 - val_loss: 37220237312.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39892062208.0000 - val_loss: 37196546048.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39866392576.0000 - val_loss: 37184512000.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39850680320.0000 - val_loss: 37156810752.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39820881920.0000 - val_loss: 37123444736.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39790641152.0000 - val_loss: 37103464448.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39766487040.0000 - val_loss: 37081956352.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39741820928.0000 - val_loss: 37058572288.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39722201088.0000 - val_loss: 37024796672.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39696199680.0000 - val_loss: 36992217088.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39661645824.0000 - val_loss: 36969799680.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39650496512.0000 - val_loss: 36947628032.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 38344466432.000 - 0s 2ms/step - loss: 39626362880.0000 - val_loss: 36920401920.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39590244352.0000 - val_loss: 36896165888.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39568879616.0000 - val_loss: 36881379328.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39539916800.0000 - val_loss: 36846608384.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39516819456.0000 - val_loss: 36824723456.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39494606848.0000 - val_loss: 36800229376.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39465447424.0000 - val_loss: 36774088704.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39445970944.0000 - val_loss: 36753833984.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39417294848.0000 - val_loss: 36724318208.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39393636352.0000 - val_loss: 36701134848.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39374626816.0000 - val_loss: 36681273344.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39354785792.0000 - val_loss: 36660944896.0000\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39335591936.0000 - val_loss: 36643495936.0000\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39304507392.0000 - val_loss: 36614434816.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39279357952.0000 - val_loss: 36587933696.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39257133056.0000 - val_loss: 36567498752.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39241678848.0000 - val_loss: 36547616768.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39214796800.0000 - val_loss: 36523790336.0000\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 39197376512.0000 - val_loss: 36502228992.0000\n",
      "Epoch 398/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39184019456.0000 - val_loss: 36481327104.0000\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39154761728.0000 - val_loss: 36465946624.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39133458432.0000 - val_loss: 36440649728.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39117852672.0000 - val_loss: 36423675904.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39089987584.0000 - val_loss: 36405350400.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39078744064.0000 - val_loss: 36385280000.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39053619200.0000 - val_loss: 36362817536.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39041110016.0000 - val_loss: 36348239872.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39010045952.0000 - val_loss: 36326699008.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 39007899648.0000 - val_loss: 36312514560.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38994169856.0000 - val_loss: 36293705728.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38966706176.0000 - val_loss: 36271710208.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38942720000.0000 - val_loss: 36259852288.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38925492224.0000 - val_loss: 36233564160.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38909480960.0000 - val_loss: 36217667584.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38891048960.0000 - val_loss: 36197449728.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38875361280.0000 - val_loss: 36180414464.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38870560768.0000 - val_loss: 36166164480.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38833565696.0000 - val_loss: 36144586752.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38822060032.0000 - val_loss: 36128595968.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38799093760.0000 - val_loss: 36110974976.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38789890048.0000 - val_loss: 36091801600.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38763061248.0000 - val_loss: 36076539904.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38759567360.0000 - val_loss: 36059766784.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38746038272.0000 - val_loss: 36042866688.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38719909888.0000 - val_loss: 36026810368.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38712610816.0000 - val_loss: 36011515904.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38691631104.0000 - val_loss: 35993051136.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38671953920.0000 - val_loss: 35976667136.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38675410944.0000 - val_loss: 35962417152.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38656770048.0000 - val_loss: 35951800320.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38630989824.0000 - val_loss: 35927633920.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38612221952.0000 - val_loss: 35911344128.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38586777600.0000 - val_loss: 35899449344.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38575169536.0000 - val_loss: 35883380736.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38573785088.0000 - val_loss: 35865305088.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38555152384.0000 - val_loss: 35855454208.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38532026368.0000 - val_loss: 35834138624.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38513807360.0000 - val_loss: 35821985792.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38510391296.0000 - val_loss: 35804459008.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38490087424.0000 - val_loss: 35789967360.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38467899392.0000 - val_loss: 35775918080.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38461603840.0000 - val_loss: 35759976448.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38444380160.0000 - val_loss: 35745386496.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38432362496.0000 - val_loss: 35732799488.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38420705280.0000 - val_loss: 35715612672.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38406184960.0000 - val_loss: 35703873536.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38387171328.0000 - val_loss: 35686690816.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38372847616.0000 - val_loss: 35673452544.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38367817728.0000 - val_loss: 35660632064.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38354939904.0000 - val_loss: 35650183168.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38333693952.0000 - val_loss: 35631722496.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38315864064.0000 - val_loss: 35620831232.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38300405760.0000 - val_loss: 35603996672.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38287314944.0000 - val_loss: 35588583424.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38270058496.0000 - val_loss: 35574640640.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38263910400.0000 - val_loss: 35565428736.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38246944768.0000 - val_loss: 35548536832.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38233481216.0000 - val_loss: 35534671872.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38222753792.0000 - val_loss: 35523674112.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38210162688.0000 - val_loss: 35507810304.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38196191232.0000 - val_loss: 35494682624.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38182207488.0000 - val_loss: 35481391104.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38175162368.0000 - val_loss: 35470913536.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38165381120.0000 - val_loss: 35456036864.0000\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 38150979584.0000 - val_loss: 35449294848.0000\n",
      "Epoch 464/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38153682944.0000 - val_loss: 35430412288.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38122594304.0000 - val_loss: 35417264128.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38108803072.0000 - val_loss: 35404574720.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38104895488.0000 - val_loss: 35393380352.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38089060352.0000 - val_loss: 35382898688.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38070915072.0000 - val_loss: 35368718336.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38071160832.0000 - val_loss: 35359637504.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38063038464.0000 - val_loss: 35347746816.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38034898944.0000 - val_loss: 35333476352.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38025887744.0000 - val_loss: 35323318272.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 38026194944.0000 - val_loss: 35311992832.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38009528320.0000 - val_loss: 35298631680.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37998694400.0000 - val_loss: 35285651456.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37992275968.0000 - val_loss: 35276713984.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37977616384.0000 - val_loss: 35263463424.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37967085568.0000 - val_loss: 35252060160.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37949136896.0000 - val_loss: 35243544576.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37945286656.0000 - val_loss: 35229691904.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37927854080.0000 - val_loss: 35218497536.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37927620608.0000 - val_loss: 35210846208.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37910867968.0000 - val_loss: 35198066688.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37903540224.0000 - val_loss: 35186704384.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37902577664.0000 - val_loss: 35176955904.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37875134464.0000 - val_loss: 35165626368.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37878071296.0000 - val_loss: 35160936448.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37860499456.0000 - val_loss: 35144011776.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37844705280.0000 - val_loss: 35137220608.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37839876096.0000 - val_loss: 35124445184.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37822701568.0000 - val_loss: 35114561536.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37812592640.0000 - val_loss: 35101974528.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37797072896.0000 - val_loss: 35102294016.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37796786176.0000 - val_loss: 35085611008.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37785636864.0000 - val_loss: 35075518464.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37775917056.0000 - val_loss: 35061186560.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37756248064.0000 - val_loss: 35055611904.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37755281408.0000 - val_loss: 35042500608.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37738885120.0000 - val_loss: 35031486464.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x216296b4d90>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7072701058735303"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21627e4e490>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 426291068928.0000 - val_loss: 439847190528.0000\n",
      "Epoch 2/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 425537470464.0000 - val_loss: 438127919104.0000\n",
      "Epoch 3/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 422272663552.0000 - val_loss: 432801021952.0000\n",
      "Epoch 4/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 414616059904.0000 - val_loss: 422158041088.0000\n",
      "Epoch 5/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 401143595008.0000 - val_loss: 405032468480.0000\n",
      "Epoch 6/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381140467712.0000 - val_loss: 381070180352.0000\n",
      "Epoch 7/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354580725760.0000 - val_loss: 350822957056.0000\n",
      "Epoch 8/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322375942144.0000 - val_loss: 315475034112.0000\n",
      "Epoch 9/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286349230080.0000 - val_loss: 277177237504.0000\n",
      "Epoch 10/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 248940150784.0000 - val_loss: 238979252224.0000\n",
      "Epoch 11/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 212701609984.0000 - val_loss: 203059609600.0000\n",
      "Epoch 12/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 180225736704.0000 - val_loss: 172358778880.0000\n",
      "Epoch 13/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 153537544192.0000 - val_loss: 148138770432.0000\n",
      "Epoch 14/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 133551366144.0000 - val_loss: 130706259968.0000\n",
      "Epoch 15/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 120154701824.0000 - val_loss: 119467909120.0000\n",
      "Epoch 16/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 112125411328.0000 - val_loss: 113166934016.0000\n",
      "Epoch 17/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 107779842048.0000 - val_loss: 109738196992.0000\n",
      "Epoch 18/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 105601687552.0000 - val_loss: 107998027776.0000\n",
      "Epoch 19/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 104511791104.0000 - val_loss: 107036966912.0000\n",
      "Epoch 20/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103881089024.0000 - val_loss: 106425769984.0000\n",
      "Epoch 21/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 103407591424.0000 - val_loss: 105904472064.0000\n",
      "Epoch 22/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102986932224.0000 - val_loss: 105428467712.0000\n",
      "Epoch 23/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102570393600.0000 - val_loss: 104956534784.0000\n",
      "Epoch 24/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 102143418368.0000 - val_loss: 104469979136.0000\n",
      "Epoch 25/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101706022912.0000 - val_loss: 103986855936.0000\n",
      "Epoch 26/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 101253292032.0000 - val_loss: 103511072768.0000\n",
      "Epoch 27/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 100783710208.0000 - val_loss: 102972522496.0000\n",
      "Epoch 28/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 100298113024.0000 - val_loss: 102453264384.0000\n",
      "Epoch 29/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99802947584.0000 - val_loss: 101914591232.0000\n",
      "Epoch 30/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 99292078080.0000 - val_loss: 101382307840.0000\n",
      "Epoch 31/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98763227136.0000 - val_loss: 100798529536.0000\n",
      "Epoch 32/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 98230616064.0000 - val_loss: 100192231424.0000\n",
      "Epoch 33/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 97666539520.0000 - val_loss: 99586400256.0000\n",
      "Epoch 34/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 97093263360.0000 - val_loss: 98960867328.0000\n",
      "Epoch 35/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 96512589824.0000 - val_loss: 98328256512.0000\n",
      "Epoch 36/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 95905062912.0000 - val_loss: 97669267456.0000\n",
      "Epoch 37/500\n",
      "114/114 [==============================] - 0s 993us/step - loss: 95290302464.0000 - val_loss: 97009786880.0000\n",
      "Epoch 38/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94665768960.0000 - val_loss: 96337420288.0000\n",
      "Epoch 39/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 94020214784.0000 - val_loss: 95651143680.0000\n",
      "Epoch 40/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 93378527232.0000 - val_loss: 94920400896.0000\n",
      "Epoch 41/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92704186368.0000 - val_loss: 94224343040.0000\n",
      "Epoch 42/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 92018442240.0000 - val_loss: 93478199296.0000\n",
      "Epoch 43/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 91335172096.0000 - val_loss: 92709773312.0000\n",
      "Epoch 44/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 90627702784.0000 - val_loss: 91950784512.0000\n",
      "Epoch 45/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89909035008.0000 - val_loss: 91190108160.0000\n",
      "Epoch 46/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 89166372864.0000 - val_loss: 90379788288.0000\n",
      "Epoch 47/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 88417083392.0000 - val_loss: 89568264192.0000\n",
      "Epoch 48/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 87640326144.0000 - val_loss: 88762966016.0000\n",
      "Epoch 49/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 86872440832.0000 - val_loss: 87897743360.0000\n",
      "Epoch 50/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 86075031552.0000 - val_loss: 87081320448.0000\n",
      "Epoch 51/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 85278392320.0000 - val_loss: 86234701824.0000\n",
      "Epoch 52/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 84480122880.0000 - val_loss: 85344256000.0000\n",
      "Epoch 53/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 83671252992.0000 - val_loss: 84455800832.0000\n",
      "Epoch 54/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 82834538496.0000 - val_loss: 83584573440.0000\n",
      "Epoch 55/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 82004992000.0000 - val_loss: 82670141440.0000\n",
      "Epoch 56/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 81152212992.0000 - val_loss: 81782423552.0000\n",
      "Epoch 57/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 80279093248.0000 - val_loss: 80831594496.0000\n",
      "Epoch 58/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 79400878080.0000 - val_loss: 79901794304.0000\n",
      "Epoch 59/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 78514929664.0000 - val_loss: 78941618176.0000\n",
      "Epoch 60/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 77613727744.0000 - val_loss: 77965246464.0000\n",
      "Epoch 61/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 76707995648.0000 - val_loss: 76992831488.0000\n",
      "Epoch 62/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 75797020672.0000 - val_loss: 76018188288.0000\n",
      "Epoch 63/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 74872381440.0000 - val_loss: 75043741696.0000\n",
      "Epoch 64/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 73965395968.0000 - val_loss: 74043875328.0000\n",
      "Epoch 65/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 73040650240.0000 - val_loss: 73074499584.0000\n",
      "Epoch 66/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 72128053248.0000 - val_loss: 72072839168.0000\n",
      "Epoch 67/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 71212310528.0000 - val_loss: 71120437248.0000\n",
      "Epoch 68/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 70308110336.0000 - val_loss: 70147047424.0000\n",
      "Epoch 69/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 69420015616.0000 - val_loss: 69199634432.0000\n",
      "Epoch 70/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 68529758208.0000 - val_loss: 68211859456.0000\n",
      "Epoch 71/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 67624697856.0000 - val_loss: 67265843200.0000\n",
      "Epoch 72/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 66752962560.0000 - val_loss: 66311544832.0000\n",
      "Epoch 73/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 65886752768.0000 - val_loss: 65382793216.0000\n",
      "Epoch 74/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 65029103616.0000 - val_loss: 64483856384.0000\n",
      "Epoch 75/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 64197058560.0000 - val_loss: 63590580224.0000\n",
      "Epoch 76/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 63378411520.0000 - val_loss: 62702206976.0000\n",
      "Epoch 77/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 62586007552.0000 - val_loss: 61834113024.0000\n",
      "Epoch 78/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 61817819136.0000 - val_loss: 61034524672.0000\n",
      "Epoch 79/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 61092110336.0000 - val_loss: 60246261760.0000\n",
      "Epoch 80/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 60385480704.0000 - val_loss: 59465547776.0000\n",
      "Epoch 81/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 59708911616.0000 - val_loss: 58739568640.0000\n",
      "Epoch 82/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 59061854208.0000 - val_loss: 58064424960.0000\n",
      "Epoch 83/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 58469625856.0000 - val_loss: 57398050816.0000\n",
      "Epoch 84/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57880592384.0000 - val_loss: 56793096192.0000\n",
      "Epoch 85/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 57334333440.0000 - val_loss: 56204718080.0000\n",
      "Epoch 86/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56815919104.0000 - val_loss: 55627259904.0000\n",
      "Epoch 87/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 56346763264.0000 - val_loss: 55112826880.0000\n",
      "Epoch 88/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55901786112.0000 - val_loss: 54653915136.0000\n",
      "Epoch 89/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 55489122304.0000 - val_loss: 54163222528.0000\n",
      "Epoch 90/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 55101460480.0000 - val_loss: 53731467264.0000\n",
      "Epoch 91/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54739243008.0000 - val_loss: 53387132928.0000\n",
      "Epoch 92/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54402924544.0000 - val_loss: 52999225344.0000\n",
      "Epoch 93/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 54113345536.0000 - val_loss: 52645470208.0000\n",
      "Epoch 94/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53818810368.0000 - val_loss: 52305973248.0000\n",
      "Epoch 95/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53560332288.0000 - val_loss: 52044853248.0000\n",
      "Epoch 96/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53314605056.0000 - val_loss: 51754033152.0000\n",
      "Epoch 97/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 53086117888.0000 - val_loss: 51495456768.0000\n",
      "Epoch 98/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52872343552.0000 - val_loss: 51258060800.0000\n",
      "Epoch 99/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52715618304.0000 - val_loss: 51041808384.0000\n",
      "Epoch 100/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52504141824.0000 - val_loss: 50833752064.0000\n",
      "Epoch 101/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52337557504.0000 - val_loss: 50648965120.0000\n",
      "Epoch 102/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52175761408.0000 - val_loss: 50444161024.0000\n",
      "Epoch 103/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 52034338816.0000 - val_loss: 50299015168.0000\n",
      "Epoch 104/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 51902394368.0000 - val_loss: 50119372800.0000\n",
      "Epoch 105/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51769786368.0000 - val_loss: 49969446912.0000\n",
      "Epoch 106/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51674251264.0000 - val_loss: 49821638656.0000\n",
      "Epoch 107/500\n",
      "114/114 [==============================] - 0s 993us/step - loss: 51535937536.0000 - val_loss: 49685270528.0000\n",
      "Epoch 108/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51438628864.0000 - val_loss: 49563844608.0000\n",
      "Epoch 109/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51317846016.0000 - val_loss: 49441337344.0000\n",
      "Epoch 110/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 51220500480.0000 - val_loss: 49372262400.0000\n",
      "Epoch 111/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51124482048.0000 - val_loss: 49213501440.0000\n",
      "Epoch 112/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 51038654464.0000 - val_loss: 49123995648.0000\n",
      "Epoch 113/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50961002496.0000 - val_loss: 49001086976.0000\n",
      "Epoch 114/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50854744064.0000 - val_loss: 48901804032.0000\n",
      "Epoch 115/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 50759294976.0000 - val_loss: 48782778368.0000\n",
      "Epoch 116/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50681683968.0000 - val_loss: 48676220928.0000\n",
      "Epoch 117/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50591571968.0000 - val_loss: 48570507264.0000\n",
      "Epoch 118/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50486767616.0000 - val_loss: 48481144832.0000\n",
      "Epoch 119/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50392412160.0000 - val_loss: 48359780352.0000\n",
      "Epoch 120/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50302304256.0000 - val_loss: 48250388480.0000\n",
      "Epoch 121/500\n",
      "114/114 [==============================] - 0s 993us/step - loss: 50217107456.0000 - val_loss: 48144498688.0000\n",
      "Epoch 122/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50147606528.0000 - val_loss: 48049213440.0000\n",
      "Epoch 123/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 50035433472.0000 - val_loss: 47975763968.0000\n",
      "Epoch 124/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49944072192.0000 - val_loss: 47847133184.0000\n",
      "Epoch 125/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49854795776.0000 - val_loss: 47742849024.0000\n",
      "Epoch 126/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49761878016.0000 - val_loss: 47651102720.0000\n",
      "Epoch 127/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49669758976.0000 - val_loss: 47562600448.0000\n",
      "Epoch 128/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49589346304.0000 - val_loss: 47454371840.0000\n",
      "Epoch 129/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49512263680.0000 - val_loss: 47364628480.0000\n",
      "Epoch 130/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49431625728.0000 - val_loss: 47272517632.0000\n",
      "Epoch 131/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49348673536.0000 - val_loss: 47211974656.0000\n",
      "Epoch 132/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 49266388992.0000 - val_loss: 47081594880.0000\n",
      "Epoch 133/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 49178963968.0000 - val_loss: 47001452544.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 49092612096.0000 - val_loss: 46906060800.0000\n",
      "Epoch 135/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 49010655232.0000 - val_loss: 46797639680.0000\n",
      "Epoch 136/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 48913948672.0000 - val_loss: 46710358016.0000\n",
      "Epoch 137/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48819699712.0000 - val_loss: 46613139456.0000\n",
      "Epoch 138/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48720187392.0000 - val_loss: 46507155456.0000\n",
      "Epoch 139/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48617795584.0000 - val_loss: 46383206400.0000\n",
      "Epoch 140/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48510730240.0000 - val_loss: 46259068928.0000\n",
      "Epoch 141/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 48413425664.0000 - val_loss: 46137704448.0000\n",
      "Epoch 142/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48282505216.0000 - val_loss: 46037282816.0000\n",
      "Epoch 143/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48174112768.0000 - val_loss: 45899722752.0000\n",
      "Epoch 144/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 48056545280.0000 - val_loss: 45783920640.0000\n",
      "Epoch 145/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47942676480.0000 - val_loss: 45665525760.0000\n",
      "Epoch 146/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47814250496.0000 - val_loss: 45538484224.0000\n",
      "Epoch 147/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 47701807104.0000 - val_loss: 45404823552.0000\n",
      "Epoch 148/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47597060096.0000 - val_loss: 45267943424.0000\n",
      "Epoch 149/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47477862400.0000 - val_loss: 45170536448.0000\n",
      "Epoch 150/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47360704512.0000 - val_loss: 45042036736.0000\n",
      "Epoch 151/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47262875648.0000 - val_loss: 44921462784.0000\n",
      "Epoch 152/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 47153307648.0000 - val_loss: 44840288256.0000\n",
      "Epoch 153/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 47055568896.0000 - val_loss: 44710322176.0000\n",
      "Epoch 154/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46968926208.0000 - val_loss: 44630241280.0000\n",
      "Epoch 155/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 46876860416.0000 - val_loss: 44518486016.0000\n",
      "Epoch 156/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46775054336.0000 - val_loss: 44412948480.0000\n",
      "Epoch 157/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46684430336.0000 - val_loss: 44322369536.0000\n",
      "Epoch 158/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46591848448.0000 - val_loss: 44206510080.0000\n",
      "Epoch 159/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 46504079360.0000 - val_loss: 44108521472.0000\n",
      "Epoch 160/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 46404485120.0000 - val_loss: 44031967232.0000\n",
      "Epoch 161/500\n",
      "114/114 [==============================] - 0s 984us/step - loss: 46320496640.0000 - val_loss: 43915235328.0000\n",
      "Epoch 162/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46228094976.0000 - val_loss: 43818897408.0000\n",
      "Epoch 163/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 46138245120.0000 - val_loss: 43723612160.0000\n",
      "Epoch 164/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 46038151168.0000 - val_loss: 43585867776.0000\n",
      "Epoch 165/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 45935714304.0000 - val_loss: 43495919616.0000\n",
      "Epoch 166/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45843841024.0000 - val_loss: 43429744640.0000\n",
      "Epoch 167/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 45745364992.0000 - val_loss: 43295412224.0000\n",
      "Epoch 168/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45644267520.0000 - val_loss: 43191279616.0000\n",
      "Epoch 169/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45542137856.0000 - val_loss: 43095318528.0000\n",
      "Epoch 170/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45440745472.0000 - val_loss: 42982211584.0000\n",
      "Epoch 171/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45353312256.0000 - val_loss: 42866606080.0000\n",
      "Epoch 172/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45241716736.0000 - val_loss: 42785820672.0000\n",
      "Epoch 173/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45147987968.0000 - val_loss: 42669674496.0000\n",
      "Epoch 174/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 45063528448.0000 - val_loss: 42562236416.0000\n",
      "Epoch 175/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44964958208.0000 - val_loss: 42471505920.0000\n",
      "Epoch 176/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44877783040.0000 - val_loss: 42362253312.0000\n",
      "Epoch 177/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44784558080.0000 - val_loss: 42307170304.0000\n",
      "Epoch 178/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44687876096.0000 - val_loss: 42165899264.0000\n",
      "Epoch 179/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44594216960.0000 - val_loss: 42068410368.0000\n",
      "Epoch 180/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44506390528.0000 - val_loss: 41985232896.0000\n",
      "Epoch 181/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44425969664.0000 - val_loss: 41887559680.0000\n",
      "Epoch 182/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44327116800.0000 - val_loss: 41807568896.0000\n",
      "Epoch 183/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44250619904.0000 - val_loss: 41697595392.0000\n",
      "Epoch 184/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44151209984.0000 - val_loss: 41610293248.0000\n",
      "Epoch 185/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 44077981696.0000 - val_loss: 41522167808.0000\n",
      "Epoch 186/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43979575296.0000 - val_loss: 41429946368.0000\n",
      "Epoch 187/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43894484992.0000 - val_loss: 41325473792.0000\n",
      "Epoch 188/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43808309248.0000 - val_loss: 41240870912.0000\n",
      "Epoch 189/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43722645504.0000 - val_loss: 41153720320.0000\n",
      "Epoch 190/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43641094144.0000 - val_loss: 41069903872.0000\n",
      "Epoch 191/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43548270592.0000 - val_loss: 40984276992.0000\n",
      "Epoch 192/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43479531520.0000 - val_loss: 40894799872.0000\n",
      "Epoch 193/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43389972480.0000 - val_loss: 40828076032.0000\n",
      "Epoch 194/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43298615296.0000 - val_loss: 40734752768.0000\n",
      "Epoch 195/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43209060352.0000 - val_loss: 40617836544.0000\n",
      "Epoch 196/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43125035008.0000 - val_loss: 40530149376.0000\n",
      "Epoch 197/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 43047878656.0000 - val_loss: 40441171968.0000\n",
      "Epoch 198/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42961891328.0000 - val_loss: 40352698368.0000\n",
      "Epoch 199/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42873425920.0000 - val_loss: 40261890048.0000\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 42784342016.0000 - val_loss: 40188694528.0000\n",
      "Epoch 201/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42690572288.0000 - val_loss: 40107347968.0000\n",
      "Epoch 202/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42613772288.0000 - val_loss: 40017584128.0000\n",
      "Epoch 203/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42524651520.0000 - val_loss: 39903768576.0000\n",
      "Epoch 204/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42449502208.0000 - val_loss: 39823147008.0000\n",
      "Epoch 205/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42355703808.0000 - val_loss: 39740817408.0000\n",
      "Epoch 206/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 42270416896.0000 - val_loss: 39638061056.0000\n",
      "Epoch 207/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42179608576.0000 - val_loss: 39577501696.0000\n",
      "Epoch 208/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42104180736.0000 - val_loss: 39480897536.0000\n",
      "Epoch 209/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 42033958912.0000 - val_loss: 39389110272.0000\n",
      "Epoch 210/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 41957691392.0000 - val_loss: 39318405120.0000\n",
      "Epoch 211/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41887023104.0000 - val_loss: 39243563008.0000\n",
      "Epoch 212/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41819938816.0000 - val_loss: 39182163968.0000\n",
      "Epoch 213/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41721503744.0000 - val_loss: 39085666304.0000\n",
      "Epoch 214/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 41649184768.0000 - val_loss: 39012769792.0000\n",
      "Epoch 215/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41573978112.0000 - val_loss: 38938009600.0000\n",
      "Epoch 216/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41506844672.0000 - val_loss: 38862655488.0000\n",
      "Epoch 217/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 41441607680.0000 - val_loss: 38804934656.0000\n",
      "Epoch 218/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41378328576.0000 - val_loss: 38742667264.0000\n",
      "Epoch 219/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41312378880.0000 - val_loss: 38657654784.0000\n",
      "Epoch 220/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41263276032.0000 - val_loss: 38596362240.0000\n",
      "Epoch 221/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41184747520.0000 - val_loss: 38525509632.0000\n",
      "Epoch 222/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41120862208.0000 - val_loss: 38465110016.0000\n",
      "Epoch 223/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41068617728.0000 - val_loss: 38402768896.0000\n",
      "Epoch 224/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 41010589696.0000 - val_loss: 38336258048.0000\n",
      "Epoch 225/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40940679168.0000 - val_loss: 38284034048.0000\n",
      "Epoch 226/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40885489664.0000 - val_loss: 38231617536.0000\n",
      "Epoch 227/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40853409792.0000 - val_loss: 38159695872.0000\n",
      "Epoch 228/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40775069696.0000 - val_loss: 38103715840.0000\n",
      "Epoch 229/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 40722210816.0000 - val_loss: 38064431104.0000\n",
      "Epoch 230/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40671862784.0000 - val_loss: 37998718976.0000\n",
      "Epoch 231/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40623538176.0000 - val_loss: 37951971328.0000\n",
      "Epoch 232/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40587902976.0000 - val_loss: 37900599296.0000\n",
      "Epoch 233/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40520380416.0000 - val_loss: 37847658496.0000\n",
      "Epoch 234/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40483463168.0000 - val_loss: 37797478400.0000\n",
      "Epoch 235/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40432615424.0000 - val_loss: 37755752448.0000\n",
      "Epoch 236/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40383909888.0000 - val_loss: 37696847872.0000\n",
      "Epoch 237/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40337870848.0000 - val_loss: 37651349504.0000\n",
      "Epoch 238/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40294256640.0000 - val_loss: 37601955840.0000\n",
      "Epoch 239/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40252317696.0000 - val_loss: 37560037376.0000\n",
      "Epoch 240/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 40203005952.0000 - val_loss: 37516668928.0000\n",
      "Epoch 241/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 40175452160.0000 - val_loss: 37473587200.0000\n",
      "Epoch 242/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40123670528.0000 - val_loss: 37426790400.0000\n",
      "Epoch 243/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40072982528.0000 - val_loss: 37396860928.0000\n",
      "Epoch 244/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 40047706112.0000 - val_loss: 37343784960.0000\n",
      "Epoch 245/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39996043264.0000 - val_loss: 37303721984.0000\n",
      "Epoch 246/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39960080384.0000 - val_loss: 37282439168.0000\n",
      "Epoch 247/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39919976448.0000 - val_loss: 37224656896.0000\n",
      "Epoch 248/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39878807552.0000 - val_loss: 37189996544.0000\n",
      "Epoch 249/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39850315776.0000 - val_loss: 37149147136.0000\n",
      "Epoch 250/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39829106688.0000 - val_loss: 37110054912.0000\n",
      "Epoch 251/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39770349568.0000 - val_loss: 37086400512.0000\n",
      "Epoch 252/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39738990592.0000 - val_loss: 37046525952.0000\n",
      "Epoch 253/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39702568960.0000 - val_loss: 37018292224.0000\n",
      "Epoch 254/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39676047360.0000 - val_loss: 36970979328.0000\n",
      "Epoch 255/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39661203456.0000 - val_loss: 36934103040.0000\n",
      "Epoch 256/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39618396160.0000 - val_loss: 36920442880.0000\n",
      "Epoch 257/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39571324928.0000 - val_loss: 36867035136.0000\n",
      "Epoch 258/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39539322880.0000 - val_loss: 36835237888.0000\n",
      "Epoch 259/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39533604864.0000 - val_loss: 36802658304.0000\n",
      "Epoch 260/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39478235136.0000 - val_loss: 36772265984.0000\n",
      "Epoch 261/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39451627520.0000 - val_loss: 36746620928.0000\n",
      "Epoch 262/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39412576256.0000 - val_loss: 36707889152.0000\n",
      "Epoch 263/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39379681280.0000 - val_loss: 36683223040.0000\n",
      "Epoch 264/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39358550016.0000 - val_loss: 36650352640.0000\n",
      "Epoch 265/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39324479488.0000 - val_loss: 36619091968.0000\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 39300816896.0000 - val_loss: 36584214528.0000\n",
      "Epoch 267/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 39271530496.0000 - val_loss: 36556001280.0000\n",
      "Epoch 268/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 39232032768.0000 - val_loss: 36529049600.0000\n",
      "Epoch 269/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 39203913728.0000 - val_loss: 36496510976.0000\n",
      "Epoch 270/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 39170424832.0000 - val_loss: 36468252672.0000\n",
      "Epoch 271/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39155675136.0000 - val_loss: 36440715264.0000\n",
      "Epoch 272/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39141064704.0000 - val_loss: 36412977152.0000\n",
      "Epoch 273/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39102853120.0000 - val_loss: 36385652736.0000\n",
      "Epoch 274/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39085748224.0000 - val_loss: 36367335424.0000\n",
      "Epoch 275/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 39061946368.0000 - val_loss: 36337045504.0000\n",
      "Epoch 276/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 39015833600.0000 - val_loss: 36304523264.0000\n",
      "Epoch 277/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38994771968.0000 - val_loss: 36272836608.0000\n",
      "Epoch 278/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38962868224.0000 - val_loss: 36250357760.0000\n",
      "Epoch 279/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38941093888.0000 - val_loss: 36229742592.0000\n",
      "Epoch 280/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38919426048.0000 - val_loss: 36207067136.0000\n",
      "Epoch 281/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38882070528.0000 - val_loss: 36173955072.0000\n",
      "Epoch 282/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38875979776.0000 - val_loss: 36145491968.0000\n",
      "Epoch 283/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38848049152.0000 - val_loss: 36119044096.0000\n",
      "Epoch 284/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38815334400.0000 - val_loss: 36093394944.0000\n",
      "Epoch 285/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38783037440.0000 - val_loss: 36070158336.0000\n",
      "Epoch 286/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38771220480.0000 - val_loss: 36047007744.0000\n",
      "Epoch 287/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38765776896.0000 - val_loss: 36037070848.0000\n",
      "Epoch 288/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38728966144.0000 - val_loss: 35996950528.0000\n",
      "Epoch 289/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38707662848.0000 - val_loss: 36002258944.0000\n",
      "Epoch 290/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38688759808.0000 - val_loss: 35958120448.0000\n",
      "Epoch 291/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38680420352.0000 - val_loss: 35931148288.0000\n",
      "Epoch 292/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38644285440.0000 - val_loss: 35906945024.0000\n",
      "Epoch 293/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38608539648.0000 - val_loss: 35883376640.0000\n",
      "Epoch 294/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38592180224.0000 - val_loss: 35867598848.0000\n",
      "Epoch 295/500\n",
      "114/114 [==============================] - 0s 975us/step - loss: 38566113280.0000 - val_loss: 35840630784.0000\n",
      "Epoch 296/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38541885440.0000 - val_loss: 35818098688.0000\n",
      "Epoch 297/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38520446976.0000 - val_loss: 35796422656.0000\n",
      "Epoch 298/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38521593856.0000 - val_loss: 35774742528.0000\n",
      "Epoch 299/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38485712896.0000 - val_loss: 35755585536.0000\n",
      "Epoch 300/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38465507328.0000 - val_loss: 35734544384.0000\n",
      "Epoch 301/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38455414784.0000 - val_loss: 35714363392.0000\n",
      "Epoch 302/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38422274048.0000 - val_loss: 35728023552.0000\n",
      "Epoch 303/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38403739648.0000 - val_loss: 35671183360.0000\n",
      "Epoch 304/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38383083520.0000 - val_loss: 35649966080.0000\n",
      "Epoch 305/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38360518656.0000 - val_loss: 35629981696.0000\n",
      "Epoch 306/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38348591104.0000 - val_loss: 35615993856.0000\n",
      "Epoch 307/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38333227008.0000 - val_loss: 35591102464.0000\n",
      "Epoch 308/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38309883904.0000 - val_loss: 35585200128.0000\n",
      "Epoch 309/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38285307904.0000 - val_loss: 35551952896.0000\n",
      "Epoch 310/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38265376768.0000 - val_loss: 35530653696.0000\n",
      "Epoch 311/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38243291136.0000 - val_loss: 35509825536.0000\n",
      "Epoch 312/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38224994304.0000 - val_loss: 35494457344.0000\n",
      "Epoch 313/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38206894080.0000 - val_loss: 35470688256.0000\n",
      "Epoch 314/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 38190653440.0000 - val_loss: 35452006400.0000\n",
      "Epoch 315/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38166781952.0000 - val_loss: 35434971136.0000\n",
      "Epoch 316/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38157471744.0000 - val_loss: 35414519808.0000\n",
      "Epoch 317/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38140755968.0000 - val_loss: 35400515584.0000\n",
      "Epoch 318/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38126759936.0000 - val_loss: 35375312896.0000\n",
      "Epoch 319/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38104965120.0000 - val_loss: 35379957760.0000\n",
      "Epoch 320/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38090129408.0000 - val_loss: 35342307328.0000\n",
      "Epoch 321/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38058860544.0000 - val_loss: 35323142144.0000\n",
      "Epoch 322/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38039003136.0000 - val_loss: 35305959424.0000\n",
      "Epoch 323/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38045663232.0000 - val_loss: 35287113728.0000\n",
      "Epoch 324/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 38010982400.0000 - val_loss: 35276345344.0000\n",
      "Epoch 325/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37998964736.0000 - val_loss: 35252322304.0000\n",
      "Epoch 326/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37981294592.0000 - val_loss: 35236962304.0000\n",
      "Epoch 327/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37968117760.0000 - val_loss: 35220099072.0000\n",
      "Epoch 328/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37935382528.0000 - val_loss: 35200102400.0000\n",
      "Epoch 329/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37934329856.0000 - val_loss: 35181957120.0000\n",
      "Epoch 330/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37904338944.0000 - val_loss: 35179892736.0000\n",
      "Epoch 331/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37901381632.0000 - val_loss: 35147767808.0000\n",
      "Epoch 332/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 37876305920.0000 - val_loss: 35128311808.0000\n",
      "Epoch 333/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 37854814208.0000 - val_loss: 35113852928.0000\n",
      "Epoch 334/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37840674816.0000 - val_loss: 35101052928.0000\n",
      "Epoch 335/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37824307200.0000 - val_loss: 35087179776.0000\n",
      "Epoch 336/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37812613120.0000 - val_loss: 35064225792.0000\n",
      "Epoch 337/500\n",
      "114/114 [==============================] - 0s 993us/step - loss: 37787353088.0000 - val_loss: 35048423424.0000\n",
      "Epoch 338/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37788991488.0000 - val_loss: 35055005696.0000\n",
      "Epoch 339/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37777461248.0000 - val_loss: 35022376960.0000\n",
      "Epoch 340/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37738610688.0000 - val_loss: 35001651200.0000\n",
      "Epoch 341/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37725380608.0000 - val_loss: 34985476096.0000\n",
      "Epoch 342/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37699076096.0000 - val_loss: 34968727552.0000\n",
      "Epoch 343/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37692067840.0000 - val_loss: 34953043968.0000\n",
      "Epoch 344/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37673869312.0000 - val_loss: 34937655296.0000\n",
      "Epoch 345/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37654560768.0000 - val_loss: 34923413504.0000\n",
      "Epoch 346/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37642530816.0000 - val_loss: 34911125504.0000\n",
      "Epoch 347/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37631660032.0000 - val_loss: 34892460032.0000\n",
      "Epoch 348/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 37608964096.0000 - val_loss: 34875838464.0000\n",
      "Epoch 349/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37591629824.0000 - val_loss: 34866151424.0000\n",
      "Epoch 350/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37591805952.0000 - val_loss: 34850086912.0000\n",
      "Epoch 351/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37565665280.0000 - val_loss: 34834362368.0000\n",
      "Epoch 352/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37546119168.0000 - val_loss: 34820509696.0000\n",
      "Epoch 353/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37531627520.0000 - val_loss: 34805411840.0000\n",
      "Epoch 354/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37533544448.0000 - val_loss: 34795548672.0000\n",
      "Epoch 355/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37519204352.0000 - val_loss: 34779078656.0000\n",
      "Epoch 356/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37487853568.0000 - val_loss: 34765885440.0000\n",
      "Epoch 357/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37501792256.0000 - val_loss: 34764632064.0000\n",
      "Epoch 358/500\n",
      "114/114 [==============================] - 0s 993us/step - loss: 37462798336.0000 - val_loss: 34737213440.0000\n",
      "Epoch 359/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37447180288.0000 - val_loss: 34723684352.0000\n",
      "Epoch 360/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37429436416.0000 - val_loss: 34720694272.0000\n",
      "Epoch 361/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37429018624.0000 - val_loss: 34700050432.0000\n",
      "Epoch 362/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37424504832.0000 - val_loss: 34688536576.0000\n",
      "Epoch 363/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37389991936.0000 - val_loss: 34668707840.0000\n",
      "Epoch 364/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37375213568.0000 - val_loss: 34656407552.0000\n",
      "Epoch 365/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37369901056.0000 - val_loss: 34654547968.0000\n",
      "Epoch 366/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37349879808.0000 - val_loss: 34656509952.0000\n",
      "Epoch 367/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37343854592.0000 - val_loss: 34623021056.0000\n",
      "Epoch 368/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37315543040.0000 - val_loss: 34611376128.0000\n",
      "Epoch 369/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37305102336.0000 - val_loss: 34593542144.0000\n",
      "Epoch 370/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37296701440.0000 - val_loss: 34581446656.0000\n",
      "Epoch 371/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37283663872.0000 - val_loss: 34579509248.0000\n",
      "Epoch 372/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37275148288.0000 - val_loss: 34563465216.0000\n",
      "Epoch 373/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37254389760.0000 - val_loss: 34543116288.0000\n",
      "Epoch 374/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37248708608.0000 - val_loss: 34533613568.0000\n",
      "Epoch 375/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37242744832.0000 - val_loss: 34522660864.0000\n",
      "Epoch 376/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37224321024.0000 - val_loss: 34512596992.0000\n",
      "Epoch 377/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37209038848.0000 - val_loss: 34497835008.0000\n",
      "Epoch 378/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37189238784.0000 - val_loss: 34484899840.0000\n",
      "Epoch 379/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37179981824.0000 - val_loss: 34473902080.0000\n",
      "Epoch 380/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37177749504.0000 - val_loss: 34461863936.0000\n",
      "Epoch 381/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37162004480.0000 - val_loss: 34452369408.0000\n",
      "Epoch 382/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 37139812352.0000 - val_loss: 34438303744.0000\n",
      "Epoch 383/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37126942720.0000 - val_loss: 34428080128.0000\n",
      "Epoch 384/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 37114920960.0000 - val_loss: 34417946624.0000\n",
      "Epoch 385/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37109907456.0000 - val_loss: 34412634112.0000\n",
      "Epoch 386/500\n",
      "114/114 [==============================] - 0s 993us/step - loss: 37094854656.0000 - val_loss: 34402295808.0000\n",
      "Epoch 387/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37097881600.0000 - val_loss: 34378960896.0000\n",
      "Epoch 388/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37067026432.0000 - val_loss: 34371051520.0000\n",
      "Epoch 389/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37061206016.0000 - val_loss: 34360467456.0000\n",
      "Epoch 390/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37056806912.0000 - val_loss: 34346145792.0000\n",
      "Epoch 391/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37039882240.0000 - val_loss: 34338617344.0000\n",
      "Epoch 392/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37035778048.0000 - val_loss: 34323179520.0000\n",
      "Epoch 393/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 37013929984.0000 - val_loss: 34311014400.0000\n",
      "Epoch 394/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 37002727424.0000 - val_loss: 34299713536.0000\n",
      "Epoch 395/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36992135168.0000 - val_loss: 34291310592.0000\n",
      "Epoch 396/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36993921024.0000 - val_loss: 34286333952.0000\n",
      "Epoch 397/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36960292864.0000 - val_loss: 34266023936.0000\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 36949487616.0000 - val_loss: 34259703808.0000\n",
      "Epoch 399/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36937117696.0000 - val_loss: 34244931584.0000\n",
      "Epoch 400/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36928315392.0000 - val_loss: 34250852352.0000\n",
      "Epoch 401/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 36921536512.0000 - val_loss: 34227421184.0000\n",
      "Epoch 402/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 36912558080.0000 - val_loss: 34211549184.0000\n",
      "Epoch 403/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36888219648.0000 - val_loss: 34199345152.0000\n",
      "Epoch 404/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36895358976.0000 - val_loss: 34188707840.0000\n",
      "Epoch 405/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36872458240.0000 - val_loss: 34180638720.0000\n",
      "Epoch 406/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36860821504.0000 - val_loss: 34172375040.0000\n",
      "Epoch 407/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36856061952.0000 - val_loss: 34162352128.0000\n",
      "Epoch 408/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36840091648.0000 - val_loss: 34147284992.0000\n",
      "Epoch 409/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36845510656.0000 - val_loss: 34137085952.0000\n",
      "Epoch 410/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36817715200.0000 - val_loss: 34127601664.0000\n",
      "Epoch 411/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36813975552.0000 - val_loss: 34121744384.0000\n",
      "Epoch 412/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36805439488.0000 - val_loss: 34106677248.0000\n",
      "Epoch 413/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36782641152.0000 - val_loss: 34095630336.0000\n",
      "Epoch 414/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36775743488.0000 - val_loss: 34090379264.0000\n",
      "Epoch 415/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36772446208.0000 - val_loss: 34078287872.0000\n",
      "Epoch 416/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36772945920.0000 - val_loss: 34064803840.0000\n",
      "Epoch 417/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36745605120.0000 - val_loss: 34055968768.0000\n",
      "Epoch 418/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36738023424.0000 - val_loss: 34043537408.0000\n",
      "Epoch 419/500\n",
      "114/114 [==============================] - 0s 983us/step - loss: 36729573376.0000 - val_loss: 34035183616.0000\n",
      "Epoch 420/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36713938944.0000 - val_loss: 34024599552.0000\n",
      "Epoch 421/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36709769216.0000 - val_loss: 34019577856.0000\n",
      "Epoch 422/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36715298816.0000 - val_loss: 34004570112.0000\n",
      "Epoch 423/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36680986624.0000 - val_loss: 33994260480.0000\n",
      "Epoch 424/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 36679540736.0000 - val_loss: 33984927744.0000\n",
      "Epoch 425/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36678209536.0000 - val_loss: 33974650880.0000\n",
      "Epoch 426/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36657516544.0000 - val_loss: 33966551040.0000\n",
      "Epoch 427/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36647419904.0000 - val_loss: 33954426880.0000\n",
      "Epoch 428/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36637089792.0000 - val_loss: 33942880256.0000\n",
      "Epoch 429/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36629778432.0000 - val_loss: 33934514176.0000\n",
      "Epoch 430/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36616089600.0000 - val_loss: 33922183168.0000\n",
      "Epoch 431/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36621942784.0000 - val_loss: 33913978880.0000\n",
      "Epoch 432/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36592910336.0000 - val_loss: 33904044032.0000\n",
      "Epoch 433/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36581896192.0000 - val_loss: 33894311936.0000\n",
      "Epoch 434/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36578275328.0000 - val_loss: 33888014336.0000\n",
      "Epoch 435/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36563038208.0000 - val_loss: 33872152576.0000\n",
      "Epoch 436/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 36560891904.0000 - val_loss: 33866246144.0000\n",
      "Epoch 437/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36560158720.0000 - val_loss: 33852809216.0000\n",
      "Epoch 438/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36534124544.0000 - val_loss: 33842886656.0000\n",
      "Epoch 439/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36521295872.0000 - val_loss: 33836728320.0000\n",
      "Epoch 440/500\n",
      "114/114 [==============================] - ETA: 0s - loss: 36642955264.000 - 0s 1ms/step - loss: 36510289920.0000 - val_loss: 33823784960.0000\n",
      "Epoch 441/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36510138368.0000 - val_loss: 33838260224.0000\n",
      "Epoch 442/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36526030848.0000 - val_loss: 33806931968.0000\n",
      "Epoch 443/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36498161664.0000 - val_loss: 33796935680.0000\n",
      "Epoch 444/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36500033536.0000 - val_loss: 33786423296.0000\n",
      "Epoch 445/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36465324032.0000 - val_loss: 33778829312.0000\n",
      "Epoch 446/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36461305856.0000 - val_loss: 33768894464.0000\n",
      "Epoch 447/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36442988544.0000 - val_loss: 33763627008.0000\n",
      "Epoch 448/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36456632320.0000 - val_loss: 33757333504.0000\n",
      "Epoch 449/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36426493952.0000 - val_loss: 33749452800.0000\n",
      "Epoch 450/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36437553152.0000 - val_loss: 33731422208.0000\n",
      "Epoch 451/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36409942016.0000 - val_loss: 33724610560.0000\n",
      "Epoch 452/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36402966528.0000 - val_loss: 33729980416.0000\n",
      "Epoch 453/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36419510272.0000 - val_loss: 33720340480.0000\n",
      "Epoch 454/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36394119168.0000 - val_loss: 33708699648.0000\n",
      "Epoch 455/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36359790592.0000 - val_loss: 33711042560.0000\n",
      "Epoch 456/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36379848704.0000 - val_loss: 33678917632.0000\n",
      "Epoch 457/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36356673536.0000 - val_loss: 33669632000.0000\n",
      "Epoch 458/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36352032768.0000 - val_loss: 33664565248.0000\n",
      "Epoch 459/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36354002944.0000 - val_loss: 33654276096.0000\n",
      "Epoch 460/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36333834240.0000 - val_loss: 33647562752.0000\n",
      "Epoch 461/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36326457344.0000 - val_loss: 33644347392.0000\n",
      "Epoch 462/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36314972160.0000 - val_loss: 33630812160.0000\n",
      "Epoch 463/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36323266560.0000 - val_loss: 33621690368.0000\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 36301852672.0000 - val_loss: 33609015296.0000\n",
      "Epoch 465/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36292050944.0000 - val_loss: 33604984832.0000\n",
      "Epoch 466/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36274769920.0000 - val_loss: 33592291328.0000\n",
      "Epoch 467/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36271505408.0000 - val_loss: 33596223488.0000\n",
      "Epoch 468/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36280188928.0000 - val_loss: 33576724480.0000\n",
      "Epoch 469/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 36254982144.0000 - val_loss: 33592174592.0000\n",
      "Epoch 470/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36260589568.0000 - val_loss: 33566228480.0000\n",
      "Epoch 471/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36240125952.0000 - val_loss: 33549258752.0000\n",
      "Epoch 472/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36230025216.0000 - val_loss: 33540442112.0000\n",
      "Epoch 473/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36229148672.0000 - val_loss: 33533190144.0000\n",
      "Epoch 474/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36224237568.0000 - val_loss: 33536403456.0000\n",
      "Epoch 475/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36235141120.0000 - val_loss: 33517002752.0000\n",
      "Epoch 476/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36202930176.0000 - val_loss: 33507983360.0000\n",
      "Epoch 477/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36190449664.0000 - val_loss: 33500950528.0000\n",
      "Epoch 478/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36182970368.0000 - val_loss: 33498626048.0000\n",
      "Epoch 479/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 36172640256.0000 - val_loss: 33486118912.0000\n",
      "Epoch 480/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36177829888.0000 - val_loss: 33479161856.0000\n",
      "Epoch 481/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36164825088.0000 - val_loss: 33468827648.0000\n",
      "Epoch 482/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36152188928.0000 - val_loss: 33461078016.0000\n",
      "Epoch 483/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36142673920.0000 - val_loss: 33460156416.0000\n",
      "Epoch 484/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36132847616.0000 - val_loss: 33445513216.0000\n",
      "Epoch 485/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36126498816.0000 - val_loss: 33437648896.0000\n",
      "Epoch 486/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36107882496.0000 - val_loss: 33433188352.0000\n",
      "Epoch 487/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36107923456.0000 - val_loss: 33423314944.0000\n",
      "Epoch 488/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36106215424.0000 - val_loss: 33414680576.0000\n",
      "Epoch 489/500\n",
      "114/114 [==============================] - 0s 992us/step - loss: 36112257024.0000 - val_loss: 33402900480.0000\n",
      "Epoch 490/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36092948480.0000 - val_loss: 33406322688.0000\n",
      "Epoch 491/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36099280896.0000 - val_loss: 33395982336.0000\n",
      "Epoch 492/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36070322176.0000 - val_loss: 33380704256.0000\n",
      "Epoch 493/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36072316928.0000 - val_loss: 33372991488.0000\n",
      "Epoch 494/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36055400448.0000 - val_loss: 33366102016.0000\n",
      "Epoch 495/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36053950464.0000 - val_loss: 33361657856.0000\n",
      "Epoch 496/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36039045120.0000 - val_loss: 33352976384.0000\n",
      "Epoch 497/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36039479296.0000 - val_loss: 33347846144.0000\n",
      "Epoch 498/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36019589120.0000 - val_loss: 33347536896.0000\n",
      "Epoch 499/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36021727232.0000 - val_loss: 33331343360.0000\n",
      "Epoch 500/500\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 36011679744.0000 - val_loss: 33330069504.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2162304f1c0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape = (16,))) \n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(1))             \n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train, y_train.values,\n",
    "          validation_data=(X_val,y_val.values),\n",
    "          epochs=500, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.720103093795707"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = model.predict(X_test) \n",
    "r2_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x216230ec1c0>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(y_test, test_pred)\n",
    "ax.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result shows that as the number of unit increases the r2 score increases and the scatter points are more aligned with the y_test line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
